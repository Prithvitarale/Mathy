BalancingSharedAutonomywithHuman-RobotCommunicationRosarioScalise,YonatanBisk,MaxwellForbes,DaqingYi,YejinChoi,andSiddharthaSrinivasaPaulG.AllenSchoolofComputerScienceandEngineering,UniversityofWashington{rosario,ybisk,mbforbes,dqyi,(AMT)withparticipantswhohadnopreviousknowledgeofrobotics.Weconstraintheexperimentstoasimpletableclearingtask[3]butfeeltheseresultsgeneralizetootherdomainsandroboticplatforms.Wefirstdescribeinstructionsintoanexplicitorderingoversubtaskscorre-spondingtoeachobjectonthetable.Here,theyaremakingconcretetheirownassumptionsabouthowtocompletethetask.WepasstheseorderingstotheB.SubjectAllocationBothExperimentsIandIIweredeployedviaAMT.Werecruitedatotalofn=50participantsforeach,ensuringthatparticipantswhohadseenExperimentIwerenoteligibletodoExperimentII.WerequiredthateachparticipantwasanativeEnglishspeakerandwasnotcolorblind.Wealsosurveyedparticipantsontheirpastexperiencewithrobotsattheendofeachstudy.V.EXPERIMENTITheresultsofthepreliminarystudycorroborateourintu-itionthatresearchinghumanrobotcollaborationindecisionmakingfallswithintheframeworkandgoalsofsharedautonomy.Specifically,wenotedthathumansaregoodathigh-levelreasoningandcanspecifyanefficientorderingoversubtasksinahigh-levelplanningtask.However,thisshiftsthecognitiveworkloadtothehumanwhichtheyarereluctanttoaccommodate.Incontrast,robotsareunlikelytohavecontextspecificheuristicsabouttheenvironmentandthereforehavemoredifficultyfindingagoodorderingsoversubtasks,buttheyareverygoodatlow-levelpath-planningforgeneratingmotiontrajectoriesforindividualsubtasksandarehighlycapableassistants.Thisasymmetrybetweenhumansandrobotscanbegeneralizedtoawiderangeofsharedautonomysystems.Bothagentswillalwayshavedifferentcapabilitiesorspecialties,andshiftingthecognitiveloadrequiredbythehumanbiasesthesysteminonedirectiononthespectrumoffull-autonomytofullteleoperation.Understandingthebreadthoflanguagepeopletendtouseintheseinteractionshelpsto1)designlanguageunderstandingalgorithmsandlan-guagecommunicationschemestosupporthuman-robotcommunication;2)enablearobottointerpretthecurrentintentofahumaninsharingtheworkload;and3)allowarobottoactivelygeneratelanguageinordertoshiftitscontributionontheautonomyspectrumtooptimizetheteamperformance.Ourfirstexperimentisdesignedtotesttwohypotheses:H1Humanstendtoprovide“natural”expressionswhentheytrustintherobot’scapabilities(theyassumehighrobotautonomybeforeanyinformationisgiven),whichrequireslesswork(mental+temporaldemands).H2Humanstendtoprovide“programmatic”expressionswhentheyareawareofarobot’slimitations,despiteitincreasingtheiruntrainedRtrainedR+Ctrained050100150OccurrencesExperimentIuntrainedRtrainedR+Ctrained020406080100OccurrencesExperimentIIHigh-levelLanguageused:GroupingAbsoluteuntrainedRtrainedR+C123456789101112Task12345LikertratinguntrainedRtrainedR+CtrainedExperimentIMentaldemandSatisfactionTimespent12356791011Task12345LikertratinguntrainedRtrainedR+CtrainedExperimentIIMentaldemandSatisfactionTimespentFig.6:Mentaldemand,satisfaction,andtimeratingsforbothexperiments.Difficultyincreasesafterrobottrainingandlanguagetraining,butappearstoleveloffasusersacclimatetothetask.absoluteorderingsisanartifactofpeople’sdesiretominimizetheirowncognitiveloadandthereforeanartifactofsimpleenvironments.Specifically,weexpectconstraintandsetbasedlanguagetobemostcommonincomplexenvironments.A.StudyDesignOurdesignmirrorsExperimentIbutusesanewsetofstimuliwhichfocusesonscalingthenumberofobjectsinascene.Theseweredividedintotwoscenetypeswith24objectsinspecifiedlocations.Inthefirst,eachofthe24objectswasuniquelyidentifiablebyacolorwithacommonname.Inthesecond,eachofthe24objectswasrandomlyassignedavalueforeachattribute(bottle/cup,blue/red,small/large).Again,wedisallowanyuseroverlapfromthepreviousexperiment,soallparticipantsarenewtothetaskanduntrained.B.ResultsWhiletheplannerwillnowbetooslowtocompareasapossiblebaseline,westillwanttoinvestigatehowlanguageandmentalexhaustionscaletomorerealisticscenarios.1)LanguageAnalysis:Wheresimpleenvironmentsoc-casionallyelicitedexplicitorderinglanguageevenbeforetraining,thesearenotseenasnaturalorviableapproachesinthericherenvironment.Figure4(top)showsadramaticpreferenceforhigh-levellanguage,andcorrespondingly,weseeveryhightype/tokenratios(bottom).Thesearetrulynaturalanddiverseinstructions.Moreimportantly,andinter-estingly,weseearemarkablereluctancetochangeevenaftertraining.Whereknowledgeofrobotcapabilitiespreviouslyledparticipantstousetheveryhelpful(thoughtaxing)absoluteorderings,nowuserschoosetoonlyprovidepartialorderingsorset-basedlanguage.Itisonlyafterweexplicitlytellthemofthetypesoflanguagewewantthatabsoluteorderingsbecomemorecommon.Eventhen,theyarehalfascommonasinthesimplersetting.Again,thelowesttype-tokenratiosinthisexperimentarehigheronaveragethanExperimentI.NeitherFeaturesColor-only020406080100Preference(%)ExperimentINeitherFeaturesColor-only020406080100Preference(%)ExperimentIIFig.7:PreferenceratingsacrosstaskconfigurationsforExperimentsIandII.InExperimentI,userspreferredusingsimplereferringexpressionstolocaterecentworkonunderstandinggroups/rows/setsshouldcoverpartialorderings,buthigh-levellanguageappearstobemuchlesshomogeneousinnature.Specifically,inExperimentIIthemajorityofuserstriedtobehelpfulbyprovidinguswithtechniques,strategies,andintuitionfortheproblem.Theseexampledifferfromgoal-languageastheyareclosertopseudocodeforthecorrectsearchprocedure.Inourexperiments,HERB’sabilitiesnicelyparallelahuman’sarmandsotheusermightbedescribinghowtheywouldreasonaboutthetask.Equallyimportantforfutureworkistoincludedetailssubtlewaystherobotdiffersfromtheirexpectations(e.g.HERB’slongarmsmightmakeclosegraspsdifficult),andthencomparethealgorithms/heuristicsgeneratedbytheuser.Moretechnically,weareunawareofanyliteraturethatworkstointerpretandconvertthesetypesofhintsintoplanneractionsorconstraints.Finally,ourparticipantsalltriedtobehelpfultoHERB.Whenwecomparedthemostcommonplan(theonesusedforcomputingmotionplansinourplots)toallothersproducedwithinthepilot,wesawonverysmalldifferencesinplantimesincenobodystrategicallyinstructedHERBtoperforminfeasibleactions.Thismaynotbetrueingeneralfordeployedrobotics,hintingatanewresearchquestion:Howdowedetectwhenauserisbeingmalicious?VIII.CONCLUSIONThisworkdiscussestheinteractionbetweenhumansandrobotsfromalanguagecommunicationperspective.Itin-vestigatestheimportanceoflanguageinshiftingautonomybetweenthehumanandrobot,andwhenorwhyahumanmightchoosetobehelpfulorabdicateresponsibility.Weonlydiscussedthelanguagefromhumantorobotinthiswork,whichallowsthehumantodecidehowmuchautonomytheywanttherobottoexhibit.Understandingthevariablesweintroducedhelpsuscalibratethesharedloadahumanteammateexpects.Analysisandcategorizationoflanguagealsoprovidesinsightintohowmuchoftheworkloadthehumanteammateiswillingtotake-onorhowhardtheyareworkingonagiventask.Anaturalextensionistoinquirehowarobotshouldrespond(verbally)iftheywanttostrategicallyaskforhelporincreasetheuser’sparticipationtoredistributeoroptimizethecognitiveload.Humansworkverywellwitheachotherinteamsbycommunicatinggoals,plans,heuristics,andaskingforhelp.WhilesemanticparsersandNaturalLanguageProcessing(NLP)systemsmaynotyetbeequippedtohandlealloftheparsingnecessaryforthelanguagewehavepresented,ifrobotsaretoserveashelpfulteammembers,wewillneedtobridgethisgapbetweenhumanlanguagepreferencesandrobotunderstandingability.Thisisstillayoungareaofresearch,andlanguagecommunicationinsharedautonomyprovidesanexcitingandeffectiveinterfacetoenhanceexistingslidingautonomysystems[24]intocomplextaskcoordination,where-intask-planninglibrariescanbeextendedtobeinteractivetask-planninglibrariesthatelicitlanguageinteraction.Webelievetheseresearchresultswillhelpustobetterdesignagentswithbidirectionalcommunicationbetweenhumansandrobots,especiallyinmanipulationtasks,wherearobotneedsto:(1)preciselyunderstandwhatahumanwants,(2)dynamicallymonitortheworkloaddistribution,and(3)modelthehuman’scharacteristicbehaviorsforoptimizingreactions.REFERENCES[1]S.Javdani,S.S.Srinivasa,andJ.A.Bagnell,“Sharedautonomyviahindsightoptimization,”arXivpreprintarXiv:1503.07619,2015.[2]R.Frederking,“Gricesmaxims:dotherightthing,”Frederking,RE,1996.[3]S.Srinivasa,G.Johnson,A.andLee,M.Koval,S.Choudhury,J.King,C.Dellin,M.Harding,D.Butterworth,P.Velagapudi,andA.Thackston,“Asystemformulti-stepmobilemanipulation:Archi-tecture,algorithms,andexperiments,”inInternationalSymposiumonExperimentalRobotics,2016.[4]S.Tellex,T.Kollar,S.Dickerson,M.R.Walter,A.G.Banerjee,S.J.Teller,andN.Roy,“Understandingnaturallanguagecommandsforroboticnavigationandmobilemanipulation.”inAAAI,2011.[5]S.Hemachandra,F.Duvallet,T.M.Howard,N.Roy,A.Stentz,andM.R.Walter,“Learningmodelsforfollowingnaturallanguagedirectionsinunknownenvironments,”inRoboticsandAutomation(ICRA),2015IEEEInternationalConferenceon.IEEE,2015,pp.5608–5615.[6]D.Yi,T.M.Howard,M.A.Goodrich,andK.D.Seppi,“Expressinghomotopicrequirementsformobilerobotnavigationthroughnaturallanguageinstructions,”inIntelligentRobotsandSystems(IROS),2016IEEE/RSJInternationalConferenceon.IEEE,2016,pp.1462–1468.[7]C.Matuszek,E.Herbst,L.Zettlemoyer,andD.Fox,“Learningtoparsenaturallanguagecommandstoarobotcontrolsystem,”inExperimentalRobotics.Springer,2013,pp.403–415.[8]Y.ArtziandL.Zettlemoyer,“Weaklysupervisedlearningofsemanticparsersformappinginstructionstoactions,”TransactionsoftheAssociationforComputationalLinguistics,vol.1,pp.49–62,2013.[9]T.M.Howard,S.Tellex,andN.Roy,“Anaturallanguageplannerin-terfaceformobilemanipulators,”inRoboticsandAutomation(ICRA),2014IEEEInternationalConferenceon.IEEE,2014,pp.6652–6659.[10]J.S.Park,B.Jia,M.Bansal,andD.Manocha,“Generatingreal-timemotionplansfromcomplexnaturallanguagecommandsusingdynamicgroundinggraphs,”arXivpreprintarXiv:1707.02387,2017.[11]A.D.Dragan,K.C.Lee,andS.S.Srinivasa,“Legibilityandpredictabilityofrobotmotion,”inHuman-RobotInteraction(HRI),20138thACM/IEEEInternationalConferenceon.IEEE,2013,pp.301–308.[12]Y.Okada,K.Nagatani,K.Yoshida,S.Tadokoro,T.Yoshida,andE.Koyanagi,“Sharedautonomysystemfortrackedvehiclesonroughterrainbasedoncontinuousthree-dimensionalterrainscanning,”JournalofFieldRobotics,vol.28,no.6,pp.875–893,2011.[13]N.R.Ahmed,E.M.Sample,andM.Campbell,“Bayesianmul-ticategoricalsoftdatafusionforhuman–robotcollaboration,”IEEETransactionsonRobotics,vol.29,no.1,pp.189–206,2013.[14]S.C.DaqingYiandS.Srinivasa,“Incorporatingqualitativein-formationintoquantitativeestimationviasequentiallyconstrainedhamiltonianmontecarlosampling,”inIntelligentRobotsandSystems(IROS),2017IEEE/RSJInternationalConferenceon.IEEE,2017.[15]T.Kollar,J.Krishnamurthy,andG.P.Strimel,“Towardinteractivegroundedlanguageacqusition.”inRobotics:Scienceandsystems,2013.[16]C.Matuszek,N.FitzGerald,L.Zettlemoyer,L.Bo,andD.Fox,“Ajointmodeloflanguageandperceptionforgroundedattributelearning,”arXivpreprintarXiv:1206.6423,2012.[17]T.SatoandS.Hirai,“Language-aidedroboticteleoperationsystem(larts)foradvancedteleoperation,”IEEEJournalonRoboticsandAutomation,vol.3,no.5,pp.476–481,1987.[18]S.Lauria,G.Bugmann,T.Kyriacou,andE.Klein,“Mobilerobotprogrammingusingnaturallanguage,”RoboticsandAutonomousSystems,vol.38,no.3-4,pp.171–181,2002.[19]M.Forbes,R.P.Rao,L.Zettlemoyer,andM.Cakmak,“Robotpro-grammingby[20]R.Fang,M.Doering,andJ.Y.Chai,“Embodiedcollaborativere-ferringexpressiongenerationinsituatedhuman-robotinteraction,”inProceedingsoftheTenthAnnualACM/IEEEInternationalConferenceonHuman-RobotInteraction.ACM,2015,pp.271–278.