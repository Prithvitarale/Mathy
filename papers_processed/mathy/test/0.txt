JMLR: Workshop and Conference Proceedings vol 49:1‚Äì21, 2016
Learning Simple Auctions
Jamie Morgenstern
Tim Roughgarden
Abstract
We present a general framework for proving polynomial sample complexity bounds for the problem of
learning from samples the best auction in a class of ‚Äúsimple‚Äù auctions. Our framework captures the most
prominent examples of ‚Äúsimple‚Äù auctions, including anonymous and non-anonymous item and bundle pric-
ings, with either a single or multiple buyers. The first step of the framework is to show that the set of auction
allocation rules have a low-dimensional representation. The second step shows that, across the subset of
auctions that share the same allocations on a given set of samples, the auction revenue varies in a low-
dimensional way. Our results imply that in typical scenarios where it is possible to compute a near-optimal
simple auction with a known prior, it is also possible to compute such an auction with an unknown prior,
given a polynomial number of samples.
1. Introduction
We consider multi-item (or ‚Äúcombinatorial‚Äù) auctions, where a set of goods is sold to a set of n bidders.
Such an auction accepts bids as input and decides who gets what and who pays what. The mapping from
bids to an assignment of the goods to the bidders is called the allocation rule of the auction. The mapping
from bids to payments is called the payment rule of the auction. The sum of the payments is the revenue of
the auction.
We consider the problem of choosing an auction to maximize the seller‚Äôs revenue. To reason about
the outcome of an auction, we need a (standard) model of how bidders behave. We assume that each
bidder i has a valuation vi specifying her willingness to pay for each subset (or ‚Äúbundle‚Äù) of goods, and
strives to maximize her ‚Äúquasilinear utility,‚Äù meaning her valuation for the items obtained minus the total
price paid. The valuation vi is known to bidder i but not to the seller (or the other buyers). We focus
on ‚Äútruthful‚Äù or ‚Äúdominant-strategy incentive-compatible‚Äù auctions, where every bidder can maximize her
utility by reporting her true valuation to the seller (no matter what the other bidders do). For example,
a second-price auction for a single item (e.g., eBay) is truthful, while a first-price single-item auction is
not (since bidders have an incentive to underbid). Because we confine attention to truthful auctions, we
henceforth use bids and valuations interchangeably.
The standard economic approach to designing revenue-maximizing auctions assumes that all informa-
tion unknown to the designer is drawn from some prior distribution, about which the designer has perfect
information. With this ‚Äúperfect‚Äù prior in hand, the designer fine-tunes an auction to optimize for her ex-
pected revenue with respect to the unknown information. Three related difficulties arise when trying to use
this design pattern in practice. First, for any particular setting, it is unlikely that the designer can actually
formulate a perfect prior over the market‚Äôs hidden information. Second, if the market designer has an im-
perfect prior, it is possible that her optimal auction has overfit to this prior and will have poor revenue when
run on the (similar) true prior. Finally, the optimal auction for a particular prior can be quite complicated
and unintuitive.
c 2016 .
These obstacles can be addressed in a principled manner by designing auctions as a function of several
samples (for us, bidders‚Äô valuations) drawn from an unknown distribution, with the goal of earning high
expected revenue on a fresh draw from the same distribution. It is reasonable to expect that experienced
sellers have previous records of the bids made by previous participants in the market.
How many samples are necessary to determine an auction with a revenue guarantee that generalizes, in
the sense that the auction is guaranteed to perform as well on future draws from a distribution as it does on
past samples? The answer depends upon the complexity of the set of auctions available to the seller. The
more complex the class of auctions, the lower the class‚Äôs ‚Äúrepresentation error‚Äù (the higher the revenue the
seller might be able to extract using an auction in the class); on the other hand, a more complex class of
auctions will have higher ‚Äúgeneralization error‚Äù (the loss in revenue from optimizing over the sample rather
than the true prior) for a fixed sample size.
The idea of choosing an auction from samples dovetails nicely with an ongoing research agenda in the
auction and mechanism design community, where ‚Äúsimplicity‚Äù is often taken as a design goal for its own
sake, in both ‚Äúsingle-parameter‚Äù (Hartline and Roughgarden, 2009) and ‚Äúmulti-parameter‚Äù (Chawla et al.,
2007, 2010; Babaioff et al., 2014; Rubinstein and Weinberg, 2015) auctions.1 Recent work (Morgenstern
and Roughgarden, 2015) proposed the use of a class‚Äôs pseudo-dimension as a formal notion of simplicity
for single-parameter auctions, and proves for general single-parameter settings there exist classes of auc-
tions with small representation error (the class always contains a nearly-optimal auction) and small pseudo-
dimension or generalization error (a polynomial-sized sample suffices to learn a nearly-optimal auction from
that class).
In this work, we give a general framework for bounding the pseudo-dimension of classes of multi-
parameter auctions. Our results imply polynomial sample complexity bounds for revenue maximization for
all of the aforementioned classes of ‚Äúsimple‚Äù auctions.
For instance, one concrete example of a class of well-studied ‚Äúsimple‚Äù multi-parameter auctions comes
from Babaioff et al. (2014). Consider a single bidder whose valuation is additive over k items: there is
a vector v ‚àà Rk such that the bidder‚Äôs valuation for a bundle B ‚äÜ [k] is
P
j‚ààB vj. An item pricing is
defined by a vector p ‚àà Rk, and offers the agent each bundle B for the price
P
j‚ààB pj. A grand bundle
pricing is defined by a single real number q ‚àà R and offers only the bundle B = [k] for the price q. When
a single additive buyer‚Äôs valuation v ‚àº D1 √ó ¬∑ ¬∑ ¬∑ √ó Dk is drawn from a product distribution, either the
best item pricing or the best grand-bundle pricing will earn expected revenue at least 1/6 times that of an
optimal (arbitrarily complex) auction. Babaioff et al. (2014) assume that the Dj‚Äôs are known a priori and
choose item and bundle prices as a function of the distributions. Can we instead learn from samples the best
auction from the class consisting of all item and bundle prices? The main result in Babaioff et al. (2014)
effectively provides a bound on the representation error of this class; our work provides a bound on the
sample complexity and therefore on generalization error (for this and many other classes).
Our Main Results We present a general framework for bounding the sample complexity for ‚Äúsimple‚Äù
multi-item auctions, when considering auctions as functions from valuations to revenue. Formally, we study
the following question, and provide a technique for answering it in many interesting cases:
Given a class of truthful multiparameter auctions C : Vn ‚Üí R (each auction maps n-tuples
of valuations to the revenue achieved by the auction with those valuations), how large must
1. A canonical ‚Äúsingle-parameter‚Äù problem is a single-item auction ‚Äî each bidder either ‚Äúwins‚Äù or ‚Äúloses‚Äù. A canonical ‚Äúmulti-
parameter‚Äù problem is a multi-item auction ‚Äî with k items, each bidder faces 2k
different possibilities. Multi-parameter
problems are well known to be much more ill-behaved than single-parameter problems. For example, there is no general
multi-parameter analog of Myerson‚Äôs (single-parameter) theory of revenue-maximizing auctions (Myerson, 1981).
2
m be such that the empirical revenue maximizer in C over m independently drawn samples
of valuation n-tuples v1, . . . , vm ‚àº D earns expected revenue at least OPT(C) ‚àí  on fresh
sample drawn from D? (Here OPT(C) denotes the maximum expected revenue achieved by
an auction in C for the distribution D.)
We note that we have formulated this question as an unsupervised learning problem, where the samples
given to the learning algorithm are unlabeled. This is the natural model of bidding data from comparable
past transactions.
Our main technical contributions are first to show a general way to measure the sample complexity of
single-buyer auctions, which are interesting in their own right, and second to show a reduction from bound-
ing the sample complexity for multi-buyer auctions to bounding the sample complexity of single-buyer
auctions. Even single-buyer auctions exhibit significant discontinuities in their parameter space which make
this endeavor nontrivial. Furthermore, understanding the behavior of a bidder as a function of these param-
eters is difficult without making assumptions beyond quasilinearity about the structure of their valuation
function.
Our framework is flexible enough to bound the sample complexity for most of the simple auction classes
that have been studied in the literature. For example, we bound the pseudo-dimension of item pricings, grand
bundle pricings, and second-price item or bundle auctions with reserves. The following table summarizes
our results, as well as the known approximation guarantees these auctions provide. We note that Theorem 21
is proven using a direct argument rather than our general framework.
Summary of Simple Auction Properties
Class Valuations PD anon, nonanon Rev APX anonymous Rev APX nonanonymous
Grand bundle
pricing
General O(1), O(n)
Corollary 13
Item Pricing General OÃÉ(k2
), OÃÉ(k2
n),
Corollary 14
3 (1 unit-demand bidder)
(Chawla et al., 2007)
10.7 (n unit-demand bidders)
(Chawla et al., 2010)
Item and Grand
Bundle Pricing
General OÃÉ(k2
), OÃÉ(k2
n) 6 (1 additive bidder)
(Babaioff et al., 2014)
312 (1 subadditive bidder)
(Rubinstein and Weinberg,
2015)
Additive OÃÉ(k), OÃÉ(kn),
Theorem 21
These results imply that a polynomial-sized sample suffices to learn a nearly-optimal auction from these
classes of simple auctions. Equivalently, our results can be thought of as the sample complexity of learning
the parameters (e.g., prices) which define each mechanism belonging to one of these classes. Thus, when
combined with the ‚Äúrepresentation error‚Äù bounds from the literature, it is possible to learn auctions that earn
a constant-factor of the maximum-possible expected revenue for a single additive (Babaioff et al., 2014) or
subadditive bidder (Rubinstein and Weinberg, 2015), and n unit-demand bidders (Chawla et al., 2010).2
Many of our sample complexity bounds do not rely on any structural assumptions about buyers‚Äô valu-
ations ‚Äî only that their utilities are quasilinear and that they act to maximize their own utility. We point
to this flexibility as a key feature of our techniques: for bidders with general valuation functions, it can be
quite complicated to reason about bidders‚Äô behavior directly. We also formally describe the allocations of
these auction classes as coming from sequential allocation procedures all drawn from the same class, and
show that any class which has allocations which can be described in this way also has a provably simple
2. Our framework also applies to learning simple auctions with good welfare guarantees, as in Feldman et al. (2015); all that
changes is the real-valued function associated with an auction. Welfare guarantees are simpler than revenue guarantees (since
the objective function value depends on the allocation only) so we concentrate on the latter.
3
class of allocation functions. This reduction may be of independent interest for proving that other classes of
auctions have small sample complexity.
1.1. Related Work
There has been a recent explosion of work on learning near-optimal single-parameter auctions3 from sam-
ples (Elkind, 2007; Balcan et al., 2007, 2008a; Cole and Roughgarden, 2014; Huang et al., 2015; Medina
and Mohri, 2014; Roughgarden and Schrijvers, 2015; Morgenstern and Roughgarden, 2015; Devanur et al.,
2015); we focus here on the problem of designing auctions from samples for multi-parameter settings. Op-
timal auctions for combinatorial settings are substantially more complex than for single-parameter settings,
even before introducing questions of sample complexity. Dughmi et al. (2014) show that when items‚Äô values
are allowed to be correlated, for a single unit-demand bidder, the sample complexity required to compute
a constant-factor approximation to the optimal auction is necessarily exponential (in m). Sandholm and
Likhodedov (2015) consider the computational problem of computing a near-optimal combinatorial auction
from samples, but do not address sample complexity.
Item pricings in particular have been the subject of much study with respect to their constant approx-
imations when buyers‚Äô values for items are independent, for welfare (Kelso Jr and Crawford, 1982; Feld-
man et al., 2015) and revenue in the worst-case for a single (Chawla et al., 2007) and n unit-demand bid-
ders (Chawla et al., 2010), a single (Babaioff et al., 2014) additive buyer, and a single subadditive buyer (Ru-
binstein and Weinberg, 2015).4 For the additive and subadditive buyer results, the theorems state that the
better of the best item pricing and best grand bundle pricing achieve a constant factor of optimal revenue.
The n-buyer results for revenue rely on the use of nonanonymous item and grand bundle pricings. These
results can be thought of as bounding the representation error of using these classes of auctions for rev-
enue maximization; our work can be thought of as complementing these results by bounding the classes‚Äô
generalization error.
Item pricings are also sufficiently simple that the sample complexity of choosing welfare-optimal (Feld-
man et al., 2015; Hsu et al., 2016) and revenue-optimal (Balcan et al., 2008a) item pricings has been ex-
plored. Balcan et al. (2008a) study the sample complexity of anonymous item pricing for combinatorial
auctions with unlimited supply and employ one technique which bears some resemblance to our framework.
Fixing a sample of size m, they bound the number of distinct allocation labelings L of that sample by anony-
mous item pricing using a geometric interpretation of anonymous pricings. Such an argument seems difficult
to extend to other classes of auctions (for example, nonanonymous item pricings). We ultimately suggest
the use of linear separability as a tool to bound L, an argument which applies to many distinct classes of
auctions with finite supply, and doesn‚Äôt rely on the particular geometry of anonymous item pricings.
We use the concept of linear separability (Crammer and Singer, 2002) to prove bounds on the pseudo-
dimension of many classes of auctions; this tool was also used by Balcan et al. (2014) in studying the
sample complexity of learning the valuation function of a single buyer when goods are divisible and the
valuation functions are either additive, Leontief, or separable and piecewise-linear concave; our results apply
to multiple bidders, when items are indivisible, and most of them to arbitrary valuation classes (including
superadditive valuations). Hsu et al. (2016) also used linear separability to bound the pseudo-dimension of
welfare maximization for item pricings as well as the concentration of demand for any particular good.
3. A generalization of single-item auctions, where each buyer can be described by a single real number representing her value for
being selected as a winner.
4. For more general valuation profiles and without item-wise independence, it is known that item pricings can also achieve
somewhat weaker revenue approximations, see Balcan et al. (2008b); Chakraborty et al. (2013).
4
2. Preliminaries
Bayesian Mechanism Design Preliminaries In this section, we provide the definitions and main results
regarding simple multi-parameter mechanism design necessary for proving our main results. We consider
the problem of selling k heterogeneous items to n bidders. Each bidder i ‚àà [n] can be described by a
combinatorial valuation function vi ‚àà V ‚äÜ (2k ‚Üí R), and is assumed to be quasilinear in money, meaning
that her utility for a bundle B with price p(B) is exactly ui(B, p) = vi(B) ‚àí p(B). We will assume all
valuation functions are monotone, v(B) ‚â§ v(B0) for all B ‚äÜ B0. An auction A comprises of an allocation
rule A1 : Vn ‚Üí [n]k and a payment rule A2 : Vn ‚Üí Rn. We will only consider truthful mechanisms,
for which it is the best response for any buyer to reveal vi to the mechanism. The valuation function vi is
assumed to be known to agent i but not to the designer of the auction, who must choose an auction A before
observing v1, . . . , vn.
We will assume that bidder i‚Äôs valuation is drawn independently from some distribution Di over val-
uation profiles. We assume the support of the distribution D = D1 √ó . . . √ó Dn is in [0, H]n. We will
refer to the revenue of an auction A on a particular instance v = (v1, . . . , vn) as
P
i A2(v)i, and the (ex-
pected) revenue of A as REV(A, D) = Ev‚àºD[
P
i A2(v)i]. When a bidder‚Äôs valuation vi can be represented
as vi1, . . . , vik such that vi(B) =
P
j‚ààB vij, we say that i is additive; when vi can be represented as k
numbers vi1, . . . , vik such that vi(B) = maxj‚ààB vij, we say that i is unit-demand. If, for all B, B0 ‚äÜ [k],
vi(B) + vi(B0) ‚â• vi(B ‚à™ B0), we say vi is subadditive.
Several particular kinds of auctions are of particular use when (approximately) optimizing for revenue
in multi-parameter settings. In what follows, when a player chooses a bundle B to maximize her quasilinear
utility and B‚Äôs price is pi(B), we mean that A1(v)i = B and A2(v)i = pi(B), i.e., that the allocation and
payment rules reflect this choice of B.
An auction is an item pricing with ordering œÉ if it sets price pij for each j ‚àà [k], i ‚àà [n], and in order
œÉ(1), . . . , œÉ(n) visits buyers, offering to buyer œÉ(i) any bundle B ‚äÜ [k]\‚à™œÉ(i0):i0<iBi0 at price
P
j‚ààB pœÉ(i)j,
and buyer œÉ(i) purchases a quasilinear utility-maximizing bundle BœÉ(i) ‚àà argmaxB‚äÜ[m]\‚à™œÉ(i0):i0<iBi0
vi(B)‚àí
P
j‚ààB pœÉ(i)j. A grand bundle pricing with order œÉ sets a single price pi for the ‚Äúgrand‚Äù bundle [k] of all
items, and visits buyers in order œÉ(1), . . . , œÉ(n), offering to buyer œÉ(i) the bundle [k] for price pi if no
other œÉ(i0) : i0 < i purchased [k], and œÉ(i) purchases [k] if and only if vi([k]) ‚â• pi. If these prices do
not depend on the identity of the bidders (i.e. pij = pi0j for all i, i0, j, or pi = pi0 for all i, i0), we say
these prices are anonymous, otherwise that they are nonanonymous pricings. Throughout the paper, we will
assume some œÉ is fixed (namely, not a parameter of the design space), and so we rename bidders according
to their location in this fixed ordering. When buyers are additive, we will consider two types of auctions.
First, we consider the second-price item auction, which sells each item to the highest bidder for that item at
the second-highest bid for that item. Finally, we will consider the second-price item (grand-bundle) auction
with both anonymous and non-anonymous item reserves, which sell to the highest bidder for that item at
the maximum of the second-highest bid and the item‚Äôs reserve (for that bidder), or to no one if the highest
bidder‚Äôs bid is below her reserve. These auction classes achieve constant-factor approximations for revenue
in many special cases: for one (Chawla et al., 2007) and n (Chawla et al., 2010) unit-demand bidders,
for one additive (Babaioff et al., 2014) and one subadditive bidder (Rubinstein and Weinberg, 2015) (see
Section C, where we have included the formal theorem statements for completeness). In the full version of
this paper, we consider an additional class of auctions necessary to achieve a constant factor approximation
for n additive bidders as in Yao (2015). In all of these cases, we consider some class of auctions (e.g., item
pricings, grand bundle pricings, VCG with (second-price) reserves, or entrance mechanisms), and bound the
sample complexity of each class, which analogously can be thought of as the sample complexity of learning
the parameters (e.g., prices) which define each mechanism.
5
Learning Theory Preliminaries In this section, we provide definitions and useful tools for bounding the
sample complexity of learning real-valued functions. We omit discussion of binary-labeled learning and the
definitions of uniform versus PAC learning for reasons of space (see Section B for further details).
Real-Valued Labels In order to learn real-valued functions (for example, to guarantee convergence of the
revenue of various auctions), we use a real-valued analog of VC dimension. This gives a sufficient but not
always necessary condition for uniform convergence. We will work with the pseudo-dimension (Pollard,
1984), one standard generalization. Formally, let c : V ‚Üí [0, H] be a real-valued function over V, and F
be the class of functions that we are learning over. Let S be a sample drawn from D, |N| = m, labeled
according to c. Let errN (cÃÇ) = (
P
v‚ààN |c(v) ‚àí cÃÇ(v)|)/|N| denote the empirical error of cÃÇ on N, and let
err(cÃÇ) = Ev‚àºD[|c(v) ‚àí cÃÇ(v)|] denote the true expected error of cÃÇ with respect to D. Let (r1, . . . , rm) ‚àà
[0, H]m be a set of targets for N. We say (r1, . . . , rm) witnesses the shattering of N by F if, for each
T ‚äÜ N, there exists some cT ‚àà F such that cT (vq) ‚â• rq for all vq ‚àà T and cT (vq) < rq for all vq /
‚àà T. If
there exists some r witnessing the shattering of N, we say N is shatterable by F. The pseudo-dimension
of F, denoted PD(F), is the size of the largest set S which is shatterable by F. We will derive sample
complexity upper bounds from the following theorem, which connects the sample complexity of uniform
learning over a class of real-valued functions to the pseudo-dimension of the class.
Theorem 1 (E.g. Anthony and Bartlett (1999)) Suppose F is a class of real-valued functions with range
in [0, H] and pseudo-dimension PD(F). For every  > 0, Œ¥ ‚àà [0, 1], the sample complexity of (, Œ¥)-
uniformly learning the class F is
n = O

H

2 
PD(F) ln
H

+ ln
1
Œ¥
!
.
Theorem 1 suggests a simple learning algorithm: simply output the function c ‚àà F with the largest empirical
revenue on the sample. We call such algorithms empirical revenue maximizers.
Multiclass Learning The main goal of our work is to bound the sample complexity of revenue maximiza-
tion for multi-parameter classes of auctions (via bounding these classes‚Äô pseudo-dimension); our proofs first
bound the number of labelings of purchased bundles which these auctions can induce on a sample of size
m. Then, we argue about the behavior of the revenue of all auctions which agree on the purchased bundles
for every sample to bound the pseudo-dimension. Since bundles are neither binary nor real-valued, we now
briefly mention several tools which we use for learning in the so-called multi-label setting.
The first of these tools is that of compression schemes for a class of functions.
Definition 2 A compression scheme for F : V ‚Üí Y, of size d consists of
‚Ä¢ a compression function
compress : (V √ó Y)m
‚Üí (V √ó Y)d
,
where compress(N) ‚äÜ N and d ‚â§ m; and
‚Ä¢ a decompression function
decompress : (V √ó Y)d
‚Üí F.
For any f ‚àà F and any sample (v1, f(v1)), . . . , (vm, f(vm)), the functions satisfy
decompress ‚ó¶ compress((v1, f(v1)), . . . , (vm, f(vm))) = f0
‚àà F
where f0(vq) = f(vq) for each q ‚àà [m].
6
Intuitively, a compression function selects a subset of d ‚Äúmost relevant‚Äù points from a sample, and based
on these points, the decompression scheme selects a hypothesis. When such a scheme exists, the learning
algorithm decompress ‚ó¶ compress is an empirical risk minimizer. Furthermore, this compression-based
learning algorithm has sample complexity bounded by a function of d, which plays a role analogous to VC
dimension in the sample complexity guarantees.
Theorem 3 (Littlestone and Warmuth (1986)) Suppose F has a compression scheme of size d. Then, the
PAC sample complexity of F is at most m = O

d ln 1

+ln 1
Œ¥


.
While compression schemes imply useful sample complexity bounds, it can be hard to show that a
particular hypothesis class admits a compression scheme. One general technique is to show that the class is
linearly separable in a higher-dimensional space.
Definition 4 A class F is d-dimensionally linearly separable over labels Y if there exists a function œà :
V √ó Y ‚Üí Rd and for any f ‚àà F, there exists some wf ‚àà Rd with f(v) ‚àà argmaxyhwf , œà(v, y)i and
|argmaxyhwf , œà(v, y)i| = 1.
It is known that a d-dimensional linearly separable class admits a compression scheme of size d.
Theorem 5 (Theorem 5 of Daniely and Shalev-Shwartz (2014)) Suppose F is d-dimensionally linearly
separable. Then, there exists a compression scheme for F of size d.
If a class is linearly separable, this greatly restricts the number of labelings it can induce on a sample of size
m, a trick used in Hsu et al. (2016) and also in the next section of this paper.
We also briefly mention that if a class F is linearly separable, then post-processing the class with a fixed
function also yields a compression scheme over the resulting label space.
Observation 1 Suppose F is d-dimensionally linearly separable over Y. Fix some q : Y ‚Üí Y0. Then,
there exists a compression scheme for q ‚ó¶ F = {q ‚ó¶ f|f ‚àà F} of size d over Y0.
With these tools in hand, our roadmap is as follows: for a class of auctions, we first prove that the class
(which labels valuations by utility-maximizing bundles purchased) is linearly separable, which then implies
an upper bound on how many distinct bundle labelings one can have for a fixed sample. Then, we argue
about the pseudo-dimension of the class (which labels a valuation by the revenue achieved when that agent
buys her utility-maximizing bundle) by considering only those auctions which all have the same bundle
labeling of m samples and arguing about the behavior of the revenue of those auctions.
3. A Framework for Bounding Pseudo-dimension Via Intermediate Discrete Labels
We now propose a new framework for bounding the pseudo-dimension of many well-structured classes
of real-valued functions. Suppose F is some set of real-valued functions whose pseudo-dimension we
wish to bound. Suppose that, for each f ‚àà F, f can be ‚Äúfactored‚Äù into a pair of functions (f1, f2) such
that f2(f1(x), x) = f(x) for any x. There are always ‚Äútrivial‚Äù factorings, where the function f2 = f or
f1(x) = x, but the interesting case arises when both f1(x) and f2 (fixing f1(x)) depend in a very limited way
upon x. In particular, if the set of functions {f1} are very structured, and fixing f1(x) the set of functions
{f2} only depend upon x in some very mild way, this will imply that F itself has small pseudo-dimension.
7
Intuitively, this will allow us to ‚Äúbucket‚Äù functions by their values according to f1 on some sample, and
bound the pseudo-dimension of each of those buckets separately.
Our particular technique for showing such a property is first to show that the set of functions {f1} are
linearly separable in a dimensions, then to fix some sample S of size m and some f1, and to upper-bound
by b the pseudo-dimension of the set of functions f2 whose associated f0
1 agrees with the labeling of f1 on
S. The following definition captures precisely what we mean when we say that the function class F factors
into these two other classes of functions. If f1(x) reveals too much about x, it will be difficult to prove
linear separability; similarly, if f2 depends too heavily on x, it will be difficult to prove a bucket has small
pseudo-dimension.
Definition 6 ((a, b)-factorable class over Q) Consider some F = {f : X ‚Üí R}. Define for each f ‚àà F a
decomposition, in the form of two functions f1 : X ‚Üí Y and f2 : Y√óX ‚Üí R such that f2(f1(x), x) = f(x)
for every x ‚àà X. Let
F1 = {f1 : (f1, f2) is a decomposition of some f ‚àà F}
and
F2 = {f2 : (f1, f2) is a decomposition of some f ‚àà F}.
The set F (a, b)-factors over Q if:
(1) F1 is a-dimensionally linearly separable over Q ‚äÜ Y.
(2) For every f1 ‚àà F1 and sample S ‚äÇ X, the set
F2|f1(S) = {f0
2 : S ‚Üí R, f0
2(x) = f2(f0
1(x), x)|f1(x) = f0
1(x)‚àÄx ‚àà S
and (f0
1, f2) is a decomposition of some f ‚àà F}
has pseudo-dimension at most b.
We now give an example of a simple class which satisfies this definition. One could easily bound the
pseudo-dimension of this example class using a direct shattering argument, but it will be instructive to work
through our definition of (a, b)-separability.
Example 1 Fix some set G = {g1, . . . , gk} ‚äÇ Rk. Suppose F = {f : f(x) = maxg‚ààGf ‚äÜG g ¬∑ x} is the
set of all functions which take the maximum of at most k common linear functions in a fixed set G. We will
show that F (kd, OÃÉ(kd))-factors over [k], where each j ‚àà [k] will represent which of the k linear functions
is maximizing for a particular input. That is, for some f, Gf ‚äÜ G, let f1(x) = argmaxt:gt‚ààGf
gt ¬∑ x and
f2(t, x) = gt ¬∑ x. Thus, we have a valid factoring:
f2(f1(x), x) = f2(argmaxt:gt‚ààGf
gt ¬∑ x, x) = gargmaxt:gt‚ààGf
gt¬∑x ¬∑ x = max
gt‚ààGf
gt ¬∑ x = f(x).
It remains to show that F1 is d-dimensionally linearly separable and to bound the pseudo-dimension of F2|f1
.
We start with the former. Let Œ®(x, t)t0j = I[t0 = t] ¬∑ xj for t0 ‚àà [k], j ‚àà [d]. Then, let wf
tj = I[gt ‚àà Gf ] ¬∑ gtj.
The dot product will then be
Œ®(x, t) ¬∑ wf
=
X
t0
I[t0
= t] ¬∑ I[gt0 ‚àà Gf ]gt0 ¬∑ x
8
which will be maximized when t = argmaxt0:gt0 ‚ààGf
gt0 ¬∑ x, or when t = f1(x). So, F1 is linearly separable
in kd dimensions over [k].
Now, fix f1 ‚àà F1; we will show the pseudo-dimension of F2|f1
is at most OÃÉ(kd). For any fixed sample
S = (x1, . . . , xm), f1(xt) is fixed for all t ‚àà [m], implying that the input to all f2 ‚àà F2|f1
, (f1(xt), xt), is
fixed. Finally, by definition of f0
2,
f0
2(xt
) = f2(f1(xt
), xt
) = gf1(xt) ¬∑ xt
.
Thus, for each j ‚àà [k], the subset Sj ‚äÜ S for which f1(xt) = j for all xt ‚àà Sj, f0
2 is just a linear function in
d dimensions of xt with coefficients gj, Thus, since linear functions in d dimensions have pseudo-dimension
at most d + 1, there are at most md+1 labelings which can be induced on Sj, and at most mk(d+1) labelings
of all of S. This implies PD(F2|f1
) is at most OÃÉ(kd).
We now present the main theorem about the pseudo-dimension of classes that are (a, b)-factorable. The
proof of this theorem first exploits the fact that linearly separable classes have a ‚Äúsmall‚Äù number of possible
outputs for a sample of size m. Then, fixing the output of the linearly separable function, the second set of
functions‚Äô pseudo-dimension is small. The proof of the theorem is relegated to the appendix due to space
considerations.
Theorem 7 Suppose F is (a, b)-factorable over Q. Then,
PD(F) = O (max ((a + b) ln(a + b), a ln |Q|)) .
Intuitively, when F1 is linearly separable in a dimensions, it can induce at most ma|Q|a many labelings
of m samples, and fixing such a sample and its labeling, because F2 has pseudo-dimension at most b, it can
induce at most mb labelings of m samples with respect to their thresholds.
While the range of F1 might be all of Q, it will regularly be helpful to only need to prove linear sepa-
rability of F1 only over ‚Äúrealizable‚Äù labels for particular inputs. If F1 has the property that for every input
x, every f1 ‚àà F1 labels x with one of a smaller set of labels Qx ( Q, then it suffices to prove linear sepa-
rability for x over Qx.5 The following remark makes this claim formal; its proof can be found in Section E.
So, we will be able to focus on proving linear separability of F1 over a label space which depends upon the
inputs x. This will be particularly useful when describing auctions in the next section, whose allocations
are in certain cases highly restricted by their inputs. For example, when considering auctions which only
ever sell item j to the highest bidder for j, while any possible allocation might occur, we can restrict our
attention to those allocations for a sample which only allocate j too the highest bidder for j.
Remark 8 Suppose for each x ‚àà X, there exists some Qx ‚äÜ Q such that f1(x) ‚àà Qx ‚äÜ Q for all
f1 ‚àà F1, and that for each x, F1 is linearly separable in a dimensions for that x over Qx. Assume there is
a subset of dimension T+ ‚äÜ [a] for which wf
t‚ààT+ ‚â• 0 and
P
t‚ààT+ wf
t > 0 for all f. Suppose that for all
x ‚àà X, f ‚àà F1, maxy‚ààQx Œ®(x, y) ¬∑ wf ‚â• 0. Then, F1 is linearly separable over Q in a dimensions as well.
We also briefly mention a version of Theorem 7 holds if F1 needs to be post-processed. If F has a
decomposition into some g ‚ó¶ F1, F2, for some fixed, known g : Q ‚Üí Q0, and F1 is a-dimensionally linearly
separable over Q and F2|f1(S) has pseudo-d imension at most b, we will say that F (a, b, g)-factors over the
label space Q0.
Remark 9 Suppose F (a, b, g)-factors over the label space Q0. Then
PD(F) = O max (a + b) ln(a + b), a ln |Q0
|

.
5. The function-specific weight vectors wf
should be defined independently of x, as usual.
9
4. Consequences for Learning Simple Auctions
4.1. Overview
We now present applications of the framework provided by Theorem 7 to prove bounds on the pseudo-
dimension for many classes of ‚Äúsimple‚Äù multi-item auctions. The implication is that these classes, which
have been shown in many special cases to have small representation error, also have small generalization
error when auctions are chosen after observing a polynomially sized sample. We now describe how one
can translate a class of auctions into a class of functions which has an obvious and useful factorization.
An auction A : Vn ‚Üí [n]k √ó [0, H]n has two components, its allocation function A1 : Vn ‚Üí [n]k and
its revenue function A2 : Vn ‚Üí [0, H]n. We will abuse notation and refer to A2(v) =
P
i A(v)2i as
the revenue function for an auction. Our goal is to bound the sample complexity of picking some high-
revenue function from a class. All omitted proofs are found in Section E. For the remainder of this section
we use F to represent a class of auctions, f ‚àà F to represent a particular auction, and F1, F2 to be the
corresponding allocation functions and revenue functions which result from this decomposition. When F1
is linearly separable, this implies there can only be so many distinct allocations possible for a fixed set of
valuation profiles S, and when F2 (fixing some allocation for S) has small pseudo-dimension, the class of
auctions itself has small pseudo-dimension. We assume for the remainder of the paper that there are no ties,
(that is, there are no menus or bidders for which |argmaxBu(B)| > 1).6
This ‚Äútrivial‚Äù decomposition of an auction‚Äôs revenue function describes its revenue function as a function
of both the allocation chosen by f1 ‚àà F1 for v and the valuation profile v. Since A2 is a function only of v,
there is clearly enough information in (f1(v), v) to compute A2(v) (one can simply ignore f1(v) and output
f2(f1(v), v) = A2(v)). The reason we consider this decomposition is that fixing an allocation, revenue
functions of simple auctions are generally very simple to describe as a function of the input valuation profile
v. If one fixes the allocation choice for a sample S of m valuations, many auctions‚Äô classes of revenue
functions are either constant functions on S which do not depend upon v at all (for example, a posted price
auction for a single item offered to a single bidder earns its posted price if the item sells and 0 when the item
doesn‚Äôt sell, both of which are constants when the allocation is fixed) or depends only in a very mild way
(for example, a second-price single-item auction with a reserve earns the maximum of its reserve and the
second-highest bid when the item sells and 0 when it doesn‚Äôt).
4.2. Item Prices for a Single Buyer
For our first example, we employ our framework to show that single-buyer item pricings have small pseu-
dodimension, regardless of the buyer‚Äôs valuation type (e.g., additive, unit-demand, submodular, subadditive,
or arbitrary).
Theorem 10 Let F represent the class of item pricings for a single buyer and k goods. Then, PD(F2) ‚â§
O(k2 ln(k)).
Proof We will first show F1 is k + 1-dimensionally linearly separable with respect to the label set {B :
B‚äÜ{1, 2, . . . , k}}, and then that F2|f1(S) has pseudo-dimension O(k). Then, Theorem 7 will imply the
pseudodimension bound.
We start by showing F1 is k + 1-dimensionally linearly separable. Let
Œ®(v, B) = (v(B), I [1 ‚àà B] , . . . , I [k ‚àà B])
6. We elide further discussion on this technical point, though we note it is possible to encode a tie-breaking rule over utility-
maximizing bundles in a way which is linearly separable (see Hsu et al. (2016) for more details).
10
and
wfp
1 = (1, ‚àíp1, . . . , ‚àípk)
for any item pricing fp
1 ‚àà F1, p ‚àà Rk. Then, the dot product
hŒ®(v, B), wfp
1 i = v(B) ‚àí
X
i‚ààB
pi = u(B)
encodes a quasilinear buyer‚Äôs utility for a bundle B; thus, the bundle label which maximizes this dot product
is the bundle that maximizes the buyer‚Äôs utility. Since a buyer acts to maximize her quasilinear utility,
fp
1 (v) = B = argmaxB0 hŒ®(v, B0), wfp
1 i, as desired.
Finally, we show that F2|f1(S) has pseudo-dimension O(k). For S = (v1, . . . , vm), fp
2 (fp
1 (vt), vt) =
P
i‚ààfp
1 (vt) pi: revenue is simply a linear function of the k prices of the auction. Since k-dimensional linear
functions have pseudo-dimension at most O(k), this proves the claim.
4.3. Multiple-Buyer Mechanisms
We now show that our framework is general enough to handle mechanisms with multiple buyers. Most of the
‚Äúsimple‚Äù auctions with multiple buyers and items that have been considered are anonymous or nonanony-
mous auctions which interact with buyers ‚Äúone at a time‚Äù: first, bidder 1 is offered a ‚Äúmenu‚Äù of several
possible allocations at different prices, and she chooses some bundle; then bidder 2 is offered one of several
allocations of the remaining items at different prices, and so on. (Of course, any auction in a single-buyer
scenario is trivially of this form.) These auctions are simple enough that they can actually be run in practice,
and yet expressive enough that in many cases can earn a constant fraction of the optimal revenue.
We next work toward a general reduction, from bounding the sample complexity of nonanonymous auc-
tions (with multiple buyers) to that of single-buyer auctions. The following definition captures two particu-
larly common forms of these auctions. The first definition captures the setting where the function selecting
the menu to bidder i may depend upon i‚Äôs identity; the second refers to when the menu is anonymous: what
may be offered to bidder i can be different than what is offered to bidder i0, but only due to the differences
in bids vi, vi0 and the remaining available items Xi(v), Xi0 (v).
For example, consider a single item for sale. Suppose n buyers are approached in some fixed order and
bidder i is offered the item at price pi if no earlier buyer has purchased the item. If pi = pi0 for all i, i0 ‚àà [n],
then the auction applied to each buyer is the same, and we say this auction applies an n-wise repeated
allocation associated with a single posted price. If pi 6= pi0 for some i, i0 ‚àà [n], then the allocation function
applied to each bidder is an allocation rule associated with some single posted price, though the particular
posted price and therefore the allocation function varies from bidder to bidder; this auction‚Äôs allocation is
therefore an n-wise sequential allocation drawn from the class of posted prices.
For a slightly more complex example, consider a set of k heterogeneous items [k] for sale to n bidders.
Consider an auction which sets a price pij for each item j ‚àà [k] and each bidder i ‚àà [n], and serves bidders
in some fixed order. Bidder i is offered any bundle B for which no item has been selected by some previous
bidder at price pi(B) =
P
j‚ààB pij. This allocation is reached by applying a posted item pricing allocation
to each buyer in turn, so these allocations are n-wise sequential allocations drawn from posted item pricing
allocations. If pij = pi0j for all j ‚àà [k] and all i, i0 ‚àà [n], then the same allocation rule is being applied to
all bidders, and the overall allocation is therefore an n-wise repeated allocation rule.
Definition 11 (n-wise repeated and sequential allocations) Let H be some class with h : V √ó {0, 1}k ‚Üí
Q for all h ‚àà H and some Q ‚äÜ {0, 1}k. For some n functions h1, . . . , hn ‚àà H and every v ‚àà Vn,
11
inductively define X1(v) = [k], Xi(v) = Xi‚àí1(v) \ hi‚àí1(vi‚àí1, Xi‚àí1(v)). Then, define the n-wise product
function
Q
(h1,...,hn) to be
Y
(h1,...,hn)
(v) = (h1(v1, X1(v)), h2(v2, X2(v)), . . . hn(vn, Xn(v))).
Then, we call any such function an n-wise sequential allocation drawn from H. If h1 = h2 = . . . = hn, we
call
Q
h1,...,hn
an n-wise repeated allocation drawn from H.
The sets X1, . . . , Xn correspond to the sets of remaining available items for each bidder after the pre-
vious bidders have purchased their bundles according to their allocation functions: what is remaining for
bidder i is whatever bidder i‚àí1 had available less whatever was allocated to bidder i‚àí1. The two previous
examples fit into this scenario perfectly. The per-bidder allocation functions are fixed up-front: the alloca-
tion rules brought about by an (anonymous) price for a single item or (anonymous) prices for each item. In
some fixed order, the bidders are allocated according to their allocation rule run on their valuation and the
remaining items, and whatever items they didn‚Äôt purchase are available for the next bidder and her alloca-
tion rule. When the prices don‚Äôt depend on the index i, the allocation function for each bidder is the same,
so those cases correspond to n-wise repeated allocation rules, which are a subset of the n-wise sequential
allocation rules which might apply a different allocation rule to each bidder.
In the event that some class of auctions‚Äô allocation functions F1 are made up of n-wise sequential
allocations from a class H which is linearly separable, the linear separability is imparted upon F1. This
intuition is made formal by the following theorem.
Theorem 12 Suppose F is a class of auctions, and let F1 : Vn ‚Üí Q ‚äÜ [n]k be their (feasible) allocation
function. Suppose F1 is a set of n-wise sequential allocations from some H which is a-dimensionally linearly
separable, whose dot products are upper-bounded by H. Then F1 is an-dimensionally linearly separable.
Similarly, if F1 is a set of n-wise repeated allocations drawn from H which is a-dimensionally linearly
separable, then F1 is also a-dimensionally linearly separable.
Roughly speaking, this proof takes the maps guaranteed by linear separability of H and concatenates them
n times, ‚Äúblowing up‚Äù the relative importance of the earlier bidders with large coefficients.
We now present the three main corollaries of Theorems 7 and 12 which bound the pseudo-dimension of
several auction classes of interest to the mechanism design community. In particular, we focus on ‚Äúgrand
bundle‚Äù pricings (Corollary 13), where each bidder in turn is offered the entire set of items [k] at some
price, and ‚Äúitem pricings‚Äù (Corollary 14), where each bidder in turn is offered all remaining items and each
item j has some price for purchasing it. Both of these auctions have two versions: the anonymous version,
where the relevant design parameters are the same for all bidders, and the non-anonymous version, where
those parameters can be bidder-specific. As one would suspect, anonymous pricings have fewer degrees of
freedom, and have lower pseudo-dimension. More formally, the allocations which come from anonymous
pricings can be formulated as n-wise anonymous allocations, while we formulate non-anonymous pricings‚Äô
allocations as n-wise sequential allocations (which, by Theorem 12 loses a factor of n in the upper bound
on these classes‚Äô pseudo-dimensions). In each case, F1 will represent allocation functions: f1 ‚àà F1 corre-
sponds to the allocation function which the auction will implement for quasilinear bidders. For every class
F, we define for every auction f ‚àà F the function f2 to be the revenue function, which as a function of an
allocation and the valuation profile outputs the revenue for that auction with that allocation for that valua-
tion profile. The decomposition of F into F1, F2 is trivial; the work comes in showing that F1 is linearly
separable and F2|f1
has small pseudo-dimensions.
12
Our first two results use the framework to that grand bundle pricings and item pricings have small
pseudo-dimension. The second case requires a more delicate treatment of the valuation profiles (buyers are
now choosing arbitrary subsets of items, and will choose utility-maximizing bundles based on the per-item
prices). It also requires us to consider a larger set of intermediate labels (the set of all possible allocations
grows to [n]k from [n]).
Corollary 13 Let F be the class of anonymous grand bundle pricings. Then,
PD(F) = O(1).
If F is the class of non-anonymous grand bundle pricings, then
PD(F) = O(n log n).
Corollary 14 Let F be the class of anonymous item pricings. Then,
PD(F) = O k2

.
If F is the class of nonanonymous item pricings, then
PD(F) = O nk2
ln(n)

.
References
Martin Anthony and Peter L. Bartlett. Neural Network Learning: Theoretical Foundations. Cambridge University Press, NY, NY,
USA, 1999.
Moshe Babaioff, Nicole Immorlica, Brendan Lucier, and S. Matthew Weinberg. A simple and approximately optimal mechanism
for an additive buyer. In Symposium on Foundations of Computer Science (FOCS 2014). IEEE ‚Äì Institute of Electrical and
Electronics Engineers, October 2014.
Maria-Florina Balcan, Avrim Blum, and Yishay Mansour. Single price mechanisms for revenue maximization in unlimited supply
combinatorial auctions. Technical report, Carnegie Mellon University, 2007.
Maria-Florina Balcan, Avrim Blum, Jason D Hartline, and Yishay Mansour. Reducing mechanism design to algorithm design via
machine learning. Jour. of Comp. and System Sciences, 74(8):1245‚Äì1270, 2008a.
Maria-Florina Balcan, Avrim Blum, and Yishay Mansour. Item pricing for revenue maximization. In Proceedings of the 9th ACM
conference on Electronic commerce, pages 50‚Äì59. ACM, 2008b.
Maria-Florina Balcan, Amit Daniely, Ruta Mehta, Ruth Urner, and Vijay V Vazirani. Learning economic parameters from revealed
preferences. In Web and Internet Economics, pages 338‚Äì353. Springer, 2014.
Tanmoy Chakraborty, Zhiyi Huang, and Sanjeev Khanna. Dynamic and nonuniform pricing strategies for revenue maximization.
SIAM Journal on Computing, 42(6):2424‚Äì2451, 2013.
Shuchi Chawla, Jason Hartline, and Robert Kleinberg. Algorithmic pricing via virtual valuations. In Proceedings of the 8th ACM
Conf. on Electronic Commerce, pages 243‚Äì251, NY, NY, USA, 2007. ACM.
Shuchi Chawla, Jason D. Hartline, David L. Malec, and Balasubramanian Sivan. Multi-parameter mechanism design and sequential
posted pricing. In Proceedings of the Forty-second ACM Symposium on Theory of Computing, pages 311‚Äì320, NY, NY, USA,
2010. ACM.
Richard Cole and Tim Roughgarden. The sample complexity of revenue maximization. In Proceedings of the 46th Annual ACM
Symposium on Theory of Computing, pages 243‚Äì252, NY, NY, USA, 2014. SIAM.
13
Koby Crammer and Yoram Singer. On the algorithmic implementation of multiclass kernel-based vector machines. The Journal of
Machine Learning Research, 2:265‚Äì292, 2002.
Amit Daniely and Shai Shalev-Shwartz. Optimal learners for multiclass problems. In COLT 2014, pages 287‚Äì316, 2014. URL
http://arxiv.org/abs/1405.2420.
Nikhil R. Devanur, Zhiyi Huang, and Christos-Alexandros Psomas. The sample complexity of auctions with side information.
CoRR, abs/1511.02296, 2015. URL http://arxiv.org/abs/1511.02296.
Shaddin Dughmi, Li Han, and Noam Nisan. Sampling and representation complexity of revenue maximization. In Web and Internet
Economics, volume 8877 of Lecture Notes in Computer Science, pages 277‚Äì291. Springer Intl. Publishing, Beijing, China, 2014.
Andrzej Ehrenfeucht, David Haussler, Michael Kearns, and Leslie Valiant. A general lower bound on the number of exam-
ples needed for learning. Information and Computation, 82(3):247‚Äì261, 1989. URL https://www.cis.upenn.edu/
Àúmkearns/papers/lower.pdf.
Edith Elkind. Designing and learning optimal finite support auctions. In Proceedings of the eighteenth annual ACM-SIAM sympo-
sium on Discrete algorithms, pages 736‚Äì745. SIAM, 2007.
Michal Feldman, Nick Gravin, and Brendan Lucier. Combinatorial auctions via posted prices. In Proceedings of the Twenty-Sixth
Annual ACM-SIAM Symposium on Discrete Algorithms, pages 123‚Äì135. SIAM, 2015.
Steve Hanneke. The optimal sample complexity of PAC learning. CoRR, abs/1507.00473, 2015. URL http://arxiv.org/
abs/1507.00473.
Jason D. Hartline and Tim Roughgarden. Simple versus optimal mechanisms. In ACM Conf. on Electronic Commerce, Stanford,
CA, USA., 2009. ACM.
Justin Hsu, Jamie Morgenstern, Ryan Rogers, Aaron Roth, and Rakesh Vohra. Do prices coordinate markets? In STOC, page
Forthcoming, 1 2016.
Zhiyi Huang, Yishay Mansour, and Tim Roughgarden. Making the most of your samples. In Proceedings of the Sixteenth ACM
Conference on Economics and Computation, EC ‚Äô15, page forthcoming, New York, NY, USA, 2015. ACM.
Alexander S Kelso Jr and Vincent P Crawford. Job matching, coalition formation, and gross substitutes. Econometrica: Journal of
the Econometric Society, pages 1483‚Äì1504, 1982.
Nick Littlestone and Manfred Warmuth. Relating data compression and learnability. Technical report, University of California,
Santa Cruz, 1986. URL https://users.soe.ucsc.edu/Àúmanfred/pubs/lrnk-olivier.pdf.
Andres Munoz Medina and Mehryar Mohri. Learning theory and algorithms for revenue optimization in second price auctions with
reserve. In Proceedings of The 31st Intl. Conf. on Machine Learning, pages 262‚Äì270, 2014.
Jamie H Morgenstern and Tim Roughgarden. On the pseudo-dimension of nearly optimal auctions. In Advances in Neural Infor-
mation Processing Systems, pages 136‚Äì144, 2015.
Roger B Myerson. Optimal auction design. Mathematics of operations research, 6(1):58‚Äì73, 1981.
David Pollard. Convergence of stochastic processes. David Pollard, New Haven, Connecticut, 1984.
T. Roughgarden and O. Schrijvers. Ironing in the dark. Submitted, 2015.
Aviad Rubinstein and S. Matthew Weinberg. Simple mechanisms for a subadditive buyer and applications to revenue monotonicity.
In Proceedings of the Sixteenth ACM Conference on Economics and Computation, EC ‚Äô15, pages 377‚Äì394, New York, NY,
USA, 2015. ACM.
Tuomas Sandholm and Anton Likhodedov. Automated design of revenue-maximizing combinatorial auctions. Operations Re-
search, 63(5):1000‚Äì1025, 2015.
Vladimir N Vapnik and A Ya Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities.
Theory of Probability & Its Applications, 16(2):264‚Äì280, 1971.
14
Vladimir Naumovich Vapnik and Samuel Kotz. Estimation of dependences based on empirical data. Springer, 1982.
Andrew Chi-Chih Yao. An n-to-1 bidder reduction for multi-item auctions and its applications. In Proceedings of the Twenty-Sixth
Annual ACM-SIAM Symposium on Discrete Algorithms, pages 92‚Äì109. SIAM, 2015.
Appendix A. Open Problems
We propose the following open problems resulting from our work.
1. Is it possible to construct ‚Äúcompression-style‚Äù arguments which bound the pseudo-dimension of the
revenue of the class of item pricings for additive bidders which are tight (giving a bound of k and nk,
as in Theorem 21, rather than k2 and nk2)?
2. For general or even subadditive valuations, do item pricings have pseudo-dimension O(nk) or strictly
larger?
3. Is it possible to frame the allocations which result from item pricings with item-specific reserves as
n-fold sequential allocation rules from some simple class, for general valuation functions? We were
able to show it for additive valuations, which allowed us to use the ‚Äútrick‚Äù where the highest bidder
for an item is willing to pay anything less than her bid for that item (independent of other prices);
thus, if she‚Äôs willing to pay the reserve, by virtue of being the highest bidder for the item she‚Äôs willing
to pay the second-highest bid as well. For more general valuations, she may or may not optimize her
utility by paying some combination of item prices and second-highest bids for a bundle which was
utility-optimal if she were only paying item prices.
4. Relatedly, what is the pseudo-dimension of second-price item auctions with item-specific reserves
when bidders have valuations which are more general than additive or unit-demand? One can use a
proof similar to the proof of Theorem 21 to achieve a bound for unit-demand bidders, but what about
for submodular or subadditive bidders? It isn‚Äôt clear that the relative ordering of a small number of
‚Äúrelevant‚Äù parameters (such as per-item price and per-bidder single-item values) of the auction and
sample are sufficient to fix the most-preferred bundle for each agent from a sample.
Appendix B. Binary Labeled Learning
Suppose there is some domain V, and let c be some unknown target function c : V ‚Üí {0, 1}, and some
unknown distribution D over V. We wish to understand how many labeled samples (v, c(v)), with v ‚àº
D, are necessary and sufficient to be able to compute a cÃÇ which agrees with c almost everywhere with
respect to D. The distribution-independent sample complexity of learning c depends fundamentally on the
‚Äúcomplexity‚Äù of the set of binary functions F from which we are choosing cÃÇ. We review two standard
complexity measures next.
Let N be a set of m samples from V. The set N is said to be shattered by F if, for every subset T ‚äÜ N,
there is some cT ‚àà F such that cT (v) = 1 if v ‚àà T and cT (v0) = 0 if v0 /
‚àà T. That is, ranging over all
c ‚àà F induces all 2|N| possible projections onto N. The VC dimension of F, denoted VC(F), is the size of
the largest set S that can be shattered by F.
Let errN (cÃÇ) = (
P
v‚ààN |c(v) ‚àí cÃÇ(v)|)/|N| denote the empirical error of cÃÇ on N, and let err(cÃÇ) =
Ev‚àºD[|c(v)‚àícÃÇ(v)|] denote the true expected error of cÃÇ with respect to D. We say F is (, Œ¥)-PAC learnable
with sample complexity m if there exists an algorithm A such that, for all distributions D and all target
functions c ‚àà F, when A is given a sample S of size m, it produces some cÃÇ ‚àà F such that err(cÃÇ) < , with
15
probability 1‚àíŒ¥ over the choice of the sample. The PAC sample complexity of a class F can be bounded as
a polynomial function of VC(F), , and ln 1
Œ¥ (Vapnik and Chervonenkis, 1971); furthermore, any algorithm
which (, Œ¥)-PAC learns F over all distributions D must use nearly as many samples to do so. The following
theorem states this well-known result formally.7
Theorem 15 (Upper bound (Hanneke, 2015), Lower bound, Corollary 5 of (Ehrenfeucht et al., 1989))
Suppose F is a class of binary functions. Then, F can be (, Œ¥)-PAC learned with a sample of size
m = O
VC(F) + ln 1
Œ¥

!
.
Furthermore, any (, Œ¥)-PAC learning algorithm for F must have sample complexity
m = ‚Ñ¶
VC(F) + ln 1
Œ¥

!
.
There is a stronger sense in which a class F can be learned, called uniform learnability. This property
implies that, with a sufficiently large sample, the error of every c ‚àà F on the sample is close to the true
error of c. We say F is (, Œ¥)-uniformly learnable with sample complexity m if, for every distributions D,
given a sample N of size m, with probability 1 ‚àí Œ¥, |errN (c) ‚àí err(c)| <  for every c ‚àà F. Notice that,
if F is (, Œ¥)-uniformly learnable with m samples, then it is also (, Œ¥)-PAC learnable with m samples. We
now state a well-known upper bound on the uniform sample complexity of a class as a function of its VC
dimension.
Theorem 16 (See, e.g. Vapnik and Chervonenkis (1971)) Suppose F is a class of binary functions. Then,
F can be (, Œ¥)-uniformly learned with a sample of size
m = O
VC(F) ln 1
 + ln 1
Œ¥
2
!
.
Appendix C. Formal Statements of Known Revenue Guarantees for Simple Mechanisms
In various special cases, it has been shown that the aforementioned auctions earn a constant fraction of
the optimal revenue. All of these results rely on buyers‚Äô valuations displaying some kind of independence
across items: for additive and unit-demand buyers, this just means that for all i, vi = (vi1, . . . , vik) ‚àº D =
D1 √ó . . . Dk is drawn from a product distribution. Under this assumption, Chawla et al. (2010) showed that
individualized item pricings are sufficient to earn a constant fraction of optimal revenue.
Theorem 17 [Chawla et al. (2010)] Suppose each i ‚àà [n] has a unit-demand valuation vi ‚àº Di = (Di1 √ó
. . . √ó Dik). Then, there exists some nonanonymous item pricing p ‚àà Rkn such that
REV(p, D) ‚â•
1
10.67
REV(OPT).
For a single item-independent additive buyer, the better of the best item pricing and grand bundle pricing
also earns a constant fraction of optimal revenue for that setting (Babaioff et al., 2014).
7. The upper bound stated here is a quite recent result which removes a ln 1

factor from the upper bound; a slightly weaker but
long-standing upper bound can be attributed to Vapnik and Kotz (1982).
16
Theorem 18 [Babaioff et al. (2014)] Suppose there is a single buyer which has an additive valuation vi ‚àº
Di = (Di1 √ó . . . √ó Dik). Then, for an item pricing p ‚àà Rk and q a grand bundle price, q ‚àà R
max(max
p‚ààRk
REV(p, Di), max
q‚ààR
REV(q, Di)) ‚â•
1
6
REV(OPT, Di).
The final well-known result for approximately optimal Rubinstein and Weinberg (2015), ‚Äúsimple‚Äù revenue-
maximizing mechanisms states that, for an appropriately generalized definition of valuations distributed
‚Äúindependently across items‚Äù, one can approximately maximize revenue selling to a single subadditive buyer
with item or grand bundle pricings. We now present the formal definition of independence they use for these
more complicated valuation functions, and present their main result.
Definition 19 (Rubinstein and Weinberg (2015)) A distribution D over valuation functions v : 2k ‚Üí R is
subadditive over independent items if:
1. All v in the support of D are monotone; v(K ‚à™ K0) ‚â• v(K) for all K, K0.
2. All v in the support of D are subadditive: v(K ‚à™ K0) ‚â§ v(K) + v(K0) for all K, K0.
3. All v in the support of D exhibit no externalities: there exists some Dx over Rk and a function V such
that D is a distribution that samples x ‚àº Dx and outputs v such that v(K) = V ({xŒ∫}Œ∫‚ààK, K) for
all K.
4. Dx is product across its k dimensions.
Theorem 20 [Rubinstein and Weinberg (2015)] Suppose Di is subadditive over independent items. Then,
there exists a universal constant c ‚â• 1 such that
max(max
p‚ààRk
REV(p, Di), max
q‚ààR
REV(q, Di)) ‚â•
1
c
REV(OPT, Di).
Appendix D. A tighter bound on the pseudo-dimension of second-price item auctions with
reserves for additive bidders
We now present a tighter analysis of second-price item auctions with reserves which exploits the total inde-
pendence of buyers‚Äô behavior on items j, j0.
Theorem 21 The pseudo-dimension of item auctions and second-price item auctions with anonymous item
reserves is O(k log k) and with nonanonymous item prices/reserves is O(nk log(nk)) when bidders are
additive.
Proof We present the proof for the class of second-price item auctions with item reserves; the item price
result follows easily since the winner for j always pays her item price (rather than the maximum of that and
the second-highest bid for j).
Rather than proving the allocation rules are linearly separable, we upper-bound the number of interme-
diate labelings these classes can induce for m samples, where the intermediate label space we consider is
the allocation combined with, for each item, whether the winner for that item is paying the item‚Äôs reserve or
second price for that item. Fix some sample S = (v1, . . . , vm) where vt ‚àà Vn and (r1, . . . , rm) ‚àà Rm.
17
This can be encoded in {0, 1}2k for anonymous item reserves (a bit for whether or not an item is sold at
its reserve and another for whether it is sold for its second-price), and {0, 1}2nk for nonanonymous reserves
(where each item is labeled as being allocated to some bidder, along with whether it is sold for that bidder‚Äôs
item-specific reserve or the second-highest bid). In the latter case, there is a post-processing rule which can
reduce the label space to have size O(n2k), since all allocations are feasible allocations. In both cases, we
will use yt to denote the intermediate label for sample vt.
We begin with anonymous item reserves. Since buyers are additive, we can consider each item sepa-
rately. We consider item j ‚àà [k]. There are 2m + 1 relevant quantities which affect the revenue any reserve
achieves for item j: pj, the reserve for j, and for each t ‚àà [m], vt
i‚àó
j
({j}) and vt
i0
j
({j}), where i‚àó
j , i0
j are
the first and second highest bidders for j from sample t, respectively. When pj ‚â§ vt
i0
j
({j}), let yt
j = 1
and yt
k+j = 0, when vt
i‚àó
j
({j}) ‚â• pj > vt
i0
j
({j}), let yt
j = 0 and yt
k+j = 1, and when pj > vt
i‚àó
j
({j}), let
yt
j = yt
n+j = 0. Thus, when the relative ordering of these 2m + 1 parameters is fixed, the jth and n + jth
coordinates for all m samples are fixed. Varying pj can induce at most 2m + 2 distinct labelings of all of S.
Thus, for all k items, there are at most (2m + 2)k distinct vectors (y1, . . . , yt).
Now, fix some intermediate labeling (y1, . . . , ym) of S. Then, the revenue for a particular reserve
vector (p1, . . . , pk) which induces this labeling on the sample is easy to describe as a linear of this labeling.
Namely,
rev(vt
, p, yt
) =
X
j:yt
j=1
vt
i0
j
({j}) +
X
j:yt
n+j=1
pj
which is a linear function in 2k dimensions of p and vt, yt (which are constants). Thus, since linear functions
in 2k dimensions have VC-dimension 2k + 1, the item reserves which agree with (y1, . . . , ym) can induce
at most m2k+1 labelings of S with respect to (r1, . . . , rm).
Thus, the set of all item reserves can induce at most m2k+1 ¬∑ (2m + 2)k labelings with respect to
(r1, . . . , rm), so if S is shatterable it must be that 2m ‚â§ m2k+1 ¬∑ (2m + 2)k, or that m = O(k log k).
With nonanonymous reserves, each sample will instead be given an intermediate label in {0, 1}nk+k,
where there is a bit for each item/bidder pair (corresponding to whether or not that bidder wins the item and
pays her individualized reserve for the item), and an additional bit for each item (corresponding to whether
or not that item is sold for its second-highest bid). There are at most [n+1]k valid labelings of a single sam-
ple (each item is sold to at most one bidder, and is either sold to her at her reserve or at the second-highest
price). For m samples, for a particular item j, there are now 2m+n parameters whose ordering matters (the
highest and second-highest bids and the bidder-specific reserves for that item); the bidder-specific item re-
serves for that item can induce at most (2m+n)n distinct orderings of these parameters; fixing this ordering,
the intermediate label is also fixed for all samples. Furthermore, once one has fixed the intermediate label
for all samples, the revenues of all individualized item reserve auctions which agree with that intermediate
labeling are again expressible as a linear function in 2nk dimensions. Thus, if the sample is shatterable,
2m ‚â§ (2m + n)nk ¬∑ m2nk, implying m = O(nk ln(nk)).
Appendix E. Omitted Proofs
Proof of Theorem 7: Consider a sample S = (x1, . . . , xm) ‚àà Xm of size m with targets r = (r1, . . . , rm) ‚àà
Rm. We first claim that, since F1 is a-dimensionally linearly separable, F1 can label S in at most m
a

¬∑ |Q|a
distinct ways. To see this, first recall that Theorem 5 implies that F1 must admit a compression scheme
compress, decompress of size at most a. Let f1(S) denote the labeling of all of S by some fixed f1 ‚àà F1.
18
Then, F1 can label S in at most |rangef1‚ààF1
(decompress ‚ó¶ compress)(S, f1(S))| ways since this is a
compression scheme for F1. The decompression function takes as input a labeled examples which are a
subset of S, so it will have one of m
a

¬∑ |Q|a inputs for a fixed set S (some subset of S labeled in some
arbitrary way), and therefore at most that many outputs, which upper-bounds the total number of possible
labelings of S by the same quantity.
Then, fixing the labeling of S to be consistent with some f1 ‚àà F1, the pseudo-dimension of F2|f1
is at
most b (by assumption), so it can induce at most mb many labelings of S according to r. Thus, there are at
most ma|Q|amb binary labelings of S with respect to r over all of F2 (and, therefore over all of F). If S is
shatterable, it must be that
2m
‚â§ ma
|Q|a
mb
implying m ‚â§ (a + b) log2(m) + a log2 |Q|, as desired. 
Proof of Remark 9: The proof is identical to the proof of Theorem 7, with the additional application of
Observation 1 to upper-bound the number of labelings that q ‚ó¶ F1 can induce by at most m
a

¬∑ |Q0|a. 
Proof of Remark 8: For each x ‚àà X, y ‚àà Qx, there exists Œ®(x, y) and for f ‚àà F1, some wf ‚àà Rd such that
argmaxy‚ààQx
Œ®(x, y) ¬∑ wf
= f(x).
We simply must extend the definition of Œ®(x, y) to be defined over all y ‚àà Q such that
Œ®(x, y0
) ¬∑ wf
< max
y‚ààQx
Œ®(x, y) ¬∑ wf
for y0 ‚àà Q \ Qx. Define Œ®(x, y0)t = 0 for any t /
‚àà T+, and Œ®(x, y0)t = ‚àí1 for all t ‚àà T+. Then, for any
y0 ‚àà Q \ Qx, Œ®(x, y0) ¬∑ wf < 0 while maxy‚ààQx Œ®(x, y) ¬∑ wf ‚â• 0, so the maximizing label y will be the
same as before.. 
Proof of Theorem 12: In either case, Q is a set of feasible allocations, so we only must show linear separabil-
ity over the set of feasible allocations (that is, we need only show separability over labels B : Bi ‚à© Bj = ‚àÖ).
We start with the first case of sequential allocations. We will show that F1 is an-dimensionally linearly
separable. By definition, F1 is a set of n-wise sequential allocations from some H which is a-dimensionally
linearly separable over {0, 1}k. This means there exists some Œ® : (V √ó {0, 1}k) √ó {0, 1}k ‚Üí Ra, wh ‚àà Rd
such that argmaxBŒ®((v, X), B) ¬∑ wh = h(v, X) for all h ‚àà H, (v, X) ‚àà V √ó {0, 1}k.
We simply need to construct some new Œ®ÃÇ : Vn √ó Q ‚Üí Ran, wÃÇh1,...,hn ‚àà Ran such that
argmaxB=(B1...Bn)Œ®ÃÇ(v, B) ¬∑ wÃÇh1,...,hn
= (h1(v1, X1(v)), h2(v2, X2(v)), . . . , hn(vn, Xn(v))).
Define Œ±i = 2iH, and define
Œ®((v, B)ij = Œ±i ¬∑ Œ®((vi, [k] \ ‚à™i0<iBi0 )Bi)j
Then, for some
Q
(h1,...,hn) ‚àà F1, define
wÃÇh1,...,hn
ij = whi
j
Now, inspecting the dot product for some v, B we see
Œ®ÃÇ(v, B) ¬∑ wÃÇh1,...,hn
=
X
i
Œ±iŒ®((vi, [k] \ ‚à™i0<iBi0 ), Bi) ¬∑ whi
19
which, by the definition of Œ±i and the assumption that Œ®((vi, X), B) ¬∑ wh ‚â§ H for all vi, X, B, h ‚àà H
implies that the maximizing label B will first pick B1 ‚äÜ [k] = X1(v) to maximize Œ®((v1, X1(v)), B1) ¬∑
wh1 , then will pick B2 ‚äÜ [k] \ B1 = X2(v) to maximize Œ®((v2, X2(v)), B2) ¬∑ wh2 , and so on. Thus, F1
is an-dimensionally linearly separable.
Now, suppose F1 is a set of n-wise repeated allocations. Since H is a-dimensionally linearly separable,
we know that for all v, X, Bi, there exists Œ®((vi, X), Bi), and for all h ‚àà H there is some wh such that
argmaxBi
Œ®((vi, X), Bi) ¬∑ wh
= h(vi, X).
We simply need to define some Œ®ÃÇ : Vn √ó Q ‚Üí Ra, wÃÇh ‚àà Ra such that
argmaxBŒ®ÃÇ(v, B) ¬∑ wÃÇh
= (h(v1, X1(v)), h(v2, X2(v)), . . . , h(vn, Xn(v))).
Then, define
Œ®ÃÇ(v, B)x =
X
i
Œ±i ¬∑ Œ®((vi, [k] \ ‚à™i0<iBi0 ), Bi)x
Then, for some
Q
h,...,h) ‚àà F1, define
wÃÇh
x = wh
x
Then, the dot product
Œ®(v, B) ¬∑ wÃÇh
=
X
x
X
i
Œ±i ¬∑ Œ®((vi, [k] \ ‚à™i0<iBi0 ), Bi)x ¬∑ wh
x =
X
i
Œ±i ¬∑ Œ®((vi, [k] \ ‚à™i0<iBi0 ), Bi) ¬∑ wh
,
which by the definition of Œ±i and the guaranteed upper bound on the dot product Œ® ¬∑ wh ‚â§ H, we know
will be maximized by first picking some B1 ‚äÜ [k] = X1(v) which maximizes Œ®((v1, X1(v)), B1) ¬∑ wh,
then picking B2 ‚äÜ X1(v) \ h(v1, X1(v)) = X2(v) which maximizes Œ®((v2, X2(v)), B2) ¬∑ wh, and so on.
Thus, F1 is a-dimensionally linearly separable. 
Proof of Corollary 13: We first prove first that for a single buyer, the grand-bundle mechanism is 2-
dimensionally linearly separable over {0, 1}. Let H denote the class of single-buyer grand bundle pricings.
For some h ‚àà H, we define h1 : V ‚Üí {0, 1} as h1(v) = I[v ‚â• ph], where ph ‚àà R represents the price
of the grand bundle under h. We will show H is 2-dimensionally linearly separable over {0, 1}. Define
Œ®(v, b) = I[b = 1](v([k]), 1) for each b ‚àà {0, 1} and wh = (1, ‚àíph). Then,
argmaxbŒ®(v, b) ¬∑ wh
= argmaxbI[b = 1](v([k] ‚àí pf
) = I[v ‚â• ph
] = f1(v)
since the penultimate expression is maximized by b = 1 only if v([k]) ‚â• pf . Thus, H is 2-dimensionally
separable.
Notice that when F is the set of anonymous grand bundle pricings, its allocation rules F1 are n-wise
repeated allocations from H. Thus, by Theorem 12, anonymous grand bundle pricings‚Äô allocations are
linearly separable in 2 dimensions. The obvious intermediate label space Q = {0} ‚à™ {ei|i ‚àà [n]}, the set of
standard basis vectors, contains more information than is needed to compute the revenue of these auctions.
Define g(x) = I[||x|| > 0]. Let F0
1 = g ‚ó¶ F1. Now we prove for each f1 ‚àà F0
1 that F2|f1
has
pseudo-dimension O(1). Fix some f1 ‚àà F0
1. Then, we have that
f0
2(v) = f2(g(f1(v)), v) = pf
¬∑ f1(v)
20
so, the class F2|g‚ó¶f1
is a class of linear functions in 1 dimensions, which have pseudo-dimension at most 2.
Thus, F is (2, 2, g)-factorable over {0, 1}, and Remark 9 implies that the pseudo-dimension of anonymous
grand bundle pricings is O(1).
Similarly, when F is the the set of non-anonymous grand bundle pricings, F1 are n-wise sequential
allocations from H. Thus, these allocation rules are 2n-dimensionally linearly separable, respectively. In
this case, we leave the intermediate label space as Q = {0} ‚à™ {ei|i ‚àà [n]}. For any f ‚àà F, let pf ‚àà Rn
denote the price vector for the grand bundle, that is pf
i is i‚Äôs price for purchasing the grand bundle. Fix some
f1 ‚àà F1; we claim that F2|f1
has pseudo-dimension O(n). For any f0
2 ‚àà F2 and any f which is decomposed
into (f1, f2) , we have that f0
2(v) = f2(f1(v), v) = pf ¬∑ f1(v), which again is a linear function when f1
is fixed, in this case in n dimensions. Thus, F is (2n, n)-factorable over Q, so Theorem 7 implies that the
pseudo-dimension of nonanonymous grand bundle pricings is O(n log n). 
Proof of Corollary 14: As in the previous proof, we claim that F1, the allocation rules of these auctions are
n-wise repeated allocations and n-wise sequential allocations from the single-buyer item pricings allocation
set H. We begin by showing H is k + 1-dimensionally linearly separable. For some h ‚àà H, let ph ‚àà Rn
denote the item pricing faced by the single buyer. Then, define for v ‚àà V, B ‚àà {0, 1}k,
Œ®(v, B)j =
(
I[j ‚àà B] if j ‚àà [k]
v(B) if j = k + 1
and for h ‚àà H, define
wh
j =
(
‚àíph
j if j ‚àà [k]
1 if j = k + 1 .
Then, we have that Œ®(v, B) ¬∑ wh = v(B) ‚àí
P
j‚ààB ph
j , which will be maximized by B which maximizes
v‚Äôs utility. Thus, h(v) = argmaxBv(B) ‚àí
P
j‚ààB ph
j = argmaxBŒ®(v, B) ¬∑ wh, so H is k + 1-dimensionally
linearly separable.
Consider F the class of anonymous item prices. Theorem 12 implies that this class is k+1-dimensionally
linearly separable over Q = [n]k. Again, the intermediate label space suggested by this reduction to the
single-buyer case, Q = [n]k, is larger than necessary to compute revenue. Define g(B)j = I[j ‚àà ‚à™iBi] and
Q0 = {0, 1}k. We now show that, for a fixed f1 ‚àà F1, the class F2|g‚ó¶f1
has pseudo-dimension O(k). Notice
that for any f0
2 ‚àà F2|g‚ó¶f1
, we have that
f0
2(v) = f2(g(f1(v)), v) = pf
¬∑ f1(v)
which, again is a k-dimensional linear function for some fixed f1, and therefore has pseudo-dimension at
most k + 1. Thus, the class F can be (k + 1, k + 1, g)-factored over {0, 1}k, and Remark 9 implies the
pseudo-dimension is thus at most O(k2).
The proof for the nonanonymous case is identical, with two changes. First, F1 is a set of n-wise se-
quential allocations, so it is linearly separable in n(k + 1) dimensions. Second, we cannot compress the
intermediate label space Q ‚äÇ {0, 1}nk, |Q| ‚â§ [n]k, since f0
2(v) = f2(f1(v), v) = pf ¬∑ f1(v) only ex-
presses the revenue of the auction if f1(v) expresses which buyers purchase which items; thus, the set F2|f1
has pseudo-dimension at most O(nk). Thus, the class F can be (O(nk), O(nk))-factored over Q with
|Q| ‚â§ [n]k, and Theorem 7 implies the pseudo-dimension is thus at most O(nk2 ln(n)). 
21
