arXiv:0910.5260v2[cs.NA]3Nov2009OptSpace:AGradientDescentAlgorithmontheGrassmanManifoldforMatrixCompletionRaghunandanH.KeshavanandSewoongOhMay30,2018AbstractWeconsidertheproblemofreconstructingalowrankmatrixfromasmallsubsetofitsentries.Inthispaper,wedescribetheimplementationofanefficientalgorithmproposedin[19],basedonsingularvaluedecompositionfollowedbylocalmanifoldoptimization,forsolvingthelow-rankmatrixcompletionproblem.Ithasbeenshownthatifthenumberofrevealedentriesislargeenough,theoutputofsingularvaluedecompositiongivesagoodestimatefortheoriginalmatrix,sothatlocaloptimizationreconstructsthecorrectmatrixwithhighprobability.Wepresentnumericalresultswhichshowthatthisalgorithmcanreconstructthelowrankmatrixexactlyfromanm×nrank-rmatrixMhasr(m+n−r)degreesoffreedomandwithoutthesamenumberofobservationsitisimpossibletofixthem.Theextralognfactorisduetoacoupon-collectoreffect:thatallowforabroaderapplicationandabetterperformance.Thealgorithmdescribedin[19]requiresaknowledgeoftherankoftheoriginalmatrix.Inthefollowing,weintroduceaprocedure,RankEstimation,thatisguaranteedtocorrectlyestimatetherankoftheoriginalmatrixfromapartiallyrevealedmatrixundersomeconditions,whichinturnallowsustousethealgorithminabroadersetofapplications.Next,weintroduceIncrementalOptSpace,anovelmodificationtoOptSpace.Weshowthat,empirically,IncrementalOptSpacehasThesolutionofthisproblemisthelowestrankmatrixthatmatchestheobservedentries.NoticethatthisisoptimalinthesensethatifthisproblemdoesnotrecoverthecorrectmatrixMthenthereexistsatleastoneotherrank-rmatrixthatmatchesalltheobservations,andnootheralgorithmcandobetter.However,thisoptimizationproblemisNP-hardandallknownalgorithmsrequiredoublyexponentialtimeinn[9].ThisisespeciallyinadequatesinceweareinterestedincaseswherethedimensionofthematrixMislarge(eg.suchas5·105×2·104for[3]).Incompressedsensingproblems,minimizingtheℓ1normofavectorisusedasaconvexrelaxationofminimizingtheℓ0norm,orequivalentlyMinimizingF(X,Y)isanaprioridifficulttask,sinceFisanon-convexfunction.Thebasicideaisthatthesingularvaluedecomposition(SVD)ofMEprovidesanexcellentinitialguess,andthattheminimumcanbefoundwithhighprobabilitybystandardgradientdescentafterthisinitialization.Twocaveatsmustbeaddedtothisdescription:(1)IngeneralthematrixMEmustbe‘trimmed’toeliminateover-representedrowsandcolumns;(2)Weneedtoestimatethetargetrankr.Algorithm1:OptSpaceInput:observationmatrixME,observedsetEOutput:estimatedmatrixcM1:TrimME,andletfMEbetheoutput;2:EstimatetherankofM,andletr̂betheestimation;3:Computetherank-r̂projectionoffME,Pr̂(fME)=X0S0YT0;4:MinimizeF(X,Y)throughgradientdescent,withinitialcondition(X0,Y0),andreturncM=XSYT.3.1TrimmingWesaythatarowisover-representedifitsdegreeismorethan2|E|/m(twicetheaveragedegree),wheredegreeofarowisdefinedasthenumberofobservedentriesinthatrow.Analogously,acolumnisover-representedifitsthefollowingcostfunctionisdefinedintermsofthesingularvalues.R(i)=σi+1+σ1qiǫσi.(13)Basedontheabovedefinition,RankEstimationconsistsoftwosteps:RankEstimationInput:trimmedobservationmatrixfMEOutput:estimatedrankr̂1:Computesingularvalues{σi}offME;2:FindtheindexithatminimizesR(i),andletr̂betheminimizer.Theideabehindthisalgorithmisthat,ifenoughentriesTheabovegeneralformulationallowsforafreedominchoosingasuitablecostfunctionffordifferentapplications.However,acommonexampleofthecostfunctionf(x,y)=12(x−y)2worksverywellinManifoldOptimizationInput:observedmatrixME,estimatedrankr̂,initialfactorsx0=(X0,Y0),toleranceδtol,maximumiterationcountkmax,stepsizeτOutput:reconstructedmatrixcM4NumericalresultswithrandomlygeneratedmatricesTheOptSpacealgorithmdescribedabovewasimplementedinC2andtestedona3.4GHzDesktopcomputerwith4GBRAM.Forefficientsingularvaluedecompositionofsparsematrices,weused(amodificationof)SVDLIBC3whichisbasedonSVDPACKC.Inthissection,wecomparetheperformanceofOptSpacewithotheralgorithmsbynumericalsimulations.InSection4.1,thealgorithmsaretestedonrandomlygeneratedmatriceswithnoiselessobservations,andinSection4.2wecomparethealgorithmswhenwehavenoisyobservationsunderdifferentscenarios.Forexactmatrixcompletionexperiments,weusen×ntestmatricesMofrankrgeneratedasM=UVT.Here,UandVaren×rmatriceswitheachentrybeingsampledindependentlyfromastandardGaussiandistributionN(0,1),unlessspecifiedotherwise.Then,eachentryisrevealedindependentlywithprobabilityǫ/n,sothatonanaveragenǫentriesarerevealed.Numericalresultsshowthatthereisnonotabledifferenceifwechoosetherevealedsetof1e-121e-101e-081e-060.00010.011020406080100120FitError:ǫ=100ǫ=200Pred.Error:ǫ=100ǫ=200IterationsRelativeErrorFigure1:Predictionandfit00.51020406080100120140160LowerBound,r=10r=20r=40OptSpace,r=10r=20r=40|E|/nReconstructionRateFigure3:Reconstructionratesformatriceswithdimensionm=n=500usingOptSpacefor00.51020406080100120140160180200LowerBoundOptSpaceFPCASVTADMiRA|E|/nReconstructionRateFigure4:Comparisonofreconstructionratesforrandomlygeneratedrank10matrixofdimensionm=nnrǫOptSpaceSVTFPCAADMiRArel.errortime(s)rel.err.time(s)rel.err.time(s)rel.err.time(s)1000101201.18×10−5281.68×10−5405.20×10−5189.09×1000.20.40.60.810100200300400500600FPCAADMiRAOracleBoundOptSpace:rank-rprojection1iteration2iterations3iterations10iterations|E|/nRMSEFigure5:RootmeansquarederrorachievedbyOptSpace0.20.40.60.8112345678910FPCAADMiRAOracleBoundOptSpace:rank-rprojection1iteration2iterations3iterations10iterationsRankRMSEFigure6:Therootmeansquareerror00.20.40.60.811.21.40100200300400500rank-rprojectionFPCAADMiRAOptSpaceOracleBound|E|/nRMSEFigure7:Therootmeansquarederrorasafunctionoftheaveragenumberofobservedentriesperrow|E|/nforfixednoiseratioN=1/2underthestandardscenario.ofeachentryinZ.Aconvincingargumentforthischoiceofµisgivenin[8].Inthestandardscenario,wetypicallymakethefollowingthreeassumptionsonthenoisematrixZ.(1)ThenoiseZijdoesnotdependonthevalueofthematrixMij.(2)TheentriesofZ,{Zij},areindependent.(3)ThedistributionofeachentriesofZisGaussian.ThematrixcompletionalgorithmsdescribedinSection2areexpectedtobeespeciallyeffectiveunderthisstandardscenarioforthefollowingtworeasons.First,thesquarederrorobjectivefunctionthatthealgorithmsminimizeiswellsuitedfortheGaussiannoise.Second,theindependenceofZij’sensurethatthenoisematrixisalmostfullrankandthesingularvaluesareevenlydistributed.Thisimpliesthatforagivennoisepower||Z||F,thespectralnorm||Z||2ismuchsmallerthan||Z||F.Inthefollowing,wefixm=n=500andr=4,00.511.522.533.544.500.511.522.5rank-rprojectionFPCAADMiRAOptSpaceOracleBoundNRMSEFigure8:TherootmeansquarederrorasafunctionofnoiseratioNfor00.20.40.60.811.21.40100200300400500rank-rprojectionFPCAADMiRAOptSpaceOracle(Std.Scenario)|E|/nRMSEFigure9:Therootmeansquarederrorasafunctionoftheaveragenumberofobservedentriesperrow|E|/nforfixednoiseratioN=1/2withinthemultiplicativenoisemodel.Figure9showstheRMSEwithrespectto|E|/nundermultiplicativeGaussiannoise.TheRMSEoftherank-rprojectionfor|E|/n=40islargerthan1.5andisomittedinthefigure.Thebottommostlinecorrespondstotheoracleperformanceunderstandardscenario,andisdisplayedhere,andallofthefollowingfigures,toserveasareferenceforcomparison.ThemaindifferencewithrespecttoFigure7isthatmostoftheperformancecurvesarelargerundermultiplicativenoise.ForthesamevalueofthenoiseratioN,itismoredifficulttodistinguishthenoisefromtheoriginalmatrix,sincethenoiseisnowcorrelatedwiththematrixM.4.2.3OutliersInstructurefrommotion[12],the00.20.40.60.811.21.40100200300400500rank-rprojectionFPCAADMiRAOptSpaceOracle(Std.Scenario)|E|/nRMSE00.511.522.533.544.500.511.522.500.20.40.60.811.21.40100200300400500rank-rprojectionFPCAADMiRAOptSpaceOracle(Std.Scenario)|E|/nRMSEFigure11:TherootmeansquarederrorasafunctionoftheaveragenumberofobservednumsamplesrankIncrementalOptSpaceFPCAADMiRANMAEtime(s)NMAEtime(s)NMAEtime(s)100100748420.176740.10.20386250.181940.310001007362690.15835110.161141110.161940.5200010014670090.15747260.161012430.162860.9400010029047390.15918560.162915120.163172943168280000100.186382130.190187530.242765Table5:NumericalresultsfortheJesterjokedataset,wherethenumberofjokesmisfixedat100(topfourrows),andfortheMovielensdatasetwith943usersand1682movies(lastrow).5NumericalresultswithrealdatamatricesInthissection,weconsiderlow-rankmatrixcompletionproblemsinthecontextofrecommendersystems,basedontworealdatasets:theJesterjokedataset[1]andtheMovielensdataset[2].TheJesterjokedatasetcontains4.1×106ratingsfor100jokesfrom73,421users.4Sincethenumberofusersislargecomparedtothenumberofjokes,werandomlyselectnu05001000150020002500300035000102030405060708090100Figure13:DistributionofthesingularvaluesofthecompletesubmatrixintheJesterjokedataset.u1.test,respectively,in01000002000003000004000005000000100000200000300000400000500000NetflixDataRandomlyGeneratedFigure14:Cumulativesumofthesortedrownormsofthefactorcorrespondingtousers.0500010000150002000005000100001500020000NetflixDataRandomlyGeneratedFigure15:Cumulativesumofthesortedrownormsofthefactorcorrespondingtomovies.curvewouldbeclosetoastraightline.Thecurvatureintheplotsisindicativeofthedisparityamongtherowweigthsofthefactors.WecanseethatarandomlygeneratedmatrixwouldsatisfyA1withasmallervalueofµ0comparedtothemovieratingsmatrix,hencecanbesaidtobemoreincoherent.Thefactorcorrespondingtomovieshasalargerdisparitythanthefactorcorrespondingtousers,whereitisunderstoodthatΣq=0forq>r,andMmax=max{Mij}.Theproofofthislemmaisprovidedin[19].ApplyingthisresulttothecostfunctionR(i)=σi+1+σ1√i/ǫσi,wegetthefollowingbounds:R(r)≤CMmax√αǫ+(Σ1+CMmaxpα/ǫ)√rǫǫΣr−CMmax√αǫ,R(i)≥ǫΣi+1−CMmax√αǫǫΣi+CMmax√αǫ,∀i<rR(i)≥(Σ1−CMmaxpα/ǫ)√rǫCMmax√αǫ,∀i>rLet,β=Σ1/Σrandξ=(Mmax√α)/(Σ1√r).Aftersomecalculus,weestablishthatforǫ>Crmaxξ2,ξ4β2,β4,wehavethedesiredinequalityR(r)<R(i)foralli6=r.Thisprovestheremark.AcknowledgmentWethankAndreaMontanariforstimulatingdiscussionsandhelpfulcommentsonthesubjectofthispaper.ThisworkwaspartiallysupportedbyaTermanfellowship,theNSFCAREERawardCCF-0743978andtheNSFgrantDMS-0806211.References[1]Jesterjokes.http://eigentaste.berkeley.edu/user/index.php.[2]Movielens.http://www.movielens.org.[3]Netflixprize.http://www.netflixprize.com/.[4]P.-A.Absil,R.Mahony,andR.Sepulchrer.OptimizationAlgorithmsonMatrixManifolds.PrincetonUniversityPress,2008.[5]L.Armijo.Minimizationoffunctionshavinglipschitzcontinuousfirstpartialderivatives.PacificJ.Math.,16(1):1–3,1966.[6]T.BlumensathandM.E.Davies.Iterativehardthresholdingforcompressedsensing.AppliedandComputationalHarmonicAnalysis,27(3):265–274,2009.arXiv:0805.0510.[7]J-FCai,E.J.Candès,andZ.Shen.Asingularvaluethresholdingalgorithmformatrixcom-pletion.arXiv:0810.3286,2008.[8]E.J.CandèsandY.Plan.Matrixcompletionwithnoise.arXiv:0903.3131,2009.[9]E.J.Candèsand[11]V.Chandrasekaran,S.Sanghavi,P.A.Parrilo,andA.S.Willsky.Rank-sparsityincoherenceformatrixdecomposition.arXiv:0906.2220,2009.[12]P.ChenandD.Suter.Recoveringthemissingcomponentsinalargenoisylow-rankma-trix:applicationtosfm.Pattern[28]A.Singer.Aremarkonglobalpositioningfromlocaldistances.ProceedingsoftheNationalAcademyofSciences,105(28):9507–9511,2008.[29]A.SingerandM.Cucuringu.Uniquenessoflow-rankmatrixcompletionbyrigiditytheory.arXiv:0902.3846,January2009.[30]K.Toh