IterativeLearningforReliableCrowdsourcingSystemsTheMITFacultyhasmadethisarticleopenlyavailable.Pleasesharehowthisaccessbenefitsyou.Yourstorymatters.CitationDavidR.Karger,SewoongOh,DevavratShah."IterativeLearningforReliableCrowdsourcingSystems"NeuralInformationProcessingIterativeLearningforReliableCrowdsourcingSystemsDavidR.KargerSewoongOhDevavratShahDepartmentofElectricalEngineeringandComputerScienceMassachusettsInstituteofTechnologyCambridge,MA02139{karger,swoh,devavrat}@mit.eduAbstractCrowdsourcingsystems,inwhichtasksareelectronicallydistributedtonumerous‚Äúinformationpiece-workers‚Äù,haveemergedasaneffectiveparadigmforhuman-poweredsolvingoflargescaleproblemsindomainssuchasimageclassification,dataentry,opticalcharacterrecognition,recommendation,andproofreading.Be-causetheselow-paidworkerscanbeunreliable,nearlyallcrowdsourcersmustdeviseschemestoincreaseconfidencevoting.Forsuchsystemsthereisanaturalcoreoptimizationproblemtobesolved.Assumingthetaskmasterwishestoachieveacertainreliabilityintheiranswers,howcantheydosoatminimumcost(whichisequivalenttoaskinghowtheycandosowhileaskingthefewestpossiblequestions)?Severalcharacteristicsofcrowdsourcingsystemsmakethisprobleminteresting.Workersareneitherpersistentnoridentifiable;eachbatchoftaskswillbesolvedbyaworkerwhomaybecompletelynewandwhoyoumayneverseeUnderthiscrowdsourcingmodel,ataskmasterfirstdecideswhichtasksshouldbeassignedtowhichworkers,andthenestimatesthecorrectsolutions{si}i‚àà[m]oncealltheanswers{Aij}aresubmit-ted.Weassumeaone-shotscenarioinwhichallquestionsareaskedsimultaneouslyandthenanestimationisperformedafteralltheanswersareobtained.Inparticular,wedonotallowallocatingtasksadaptivelybasedontheanswersreceivedthusfar.Then,assigningtaskstonodesamountstodesigningabipartitearandomgraphgenerationschemeknownastheconfigurationmodelinrandomgraphliterature[8,9].Inprinciple,onecouldusearbitrarybipartitegraphGfortaskallocation.However,asweshowlaterinthispaper,randomregulargraphsaresufficienttoachieveorder-optimalperformance.Inferencealgorithm.Weintroduceanoveliterativealgorithmwhichoperatesonreal-valuedtaskmessages{xi‚Üíj}(i,j)‚ààEandworkermessages{yj‚Üíi}(i,j)‚ààE.TheworkermessagesareinitializedasindependentGaussianrandomvariables.Ateachiteration,themessagesareupdatedaccordingtothedescribedupdaterule,where‚àÇiistheneighborhoodofti.Intuitively,aworkermessageyj‚Üíirepresentsourbeliefonhow‚Äòreliable‚Äôtheworkerjis,suchthatourfinalestimateisaweightedsumoftheanswersweightedbyeachworker‚Äôsreliability:sÃÇi=sign(Pj‚àà‚àÇiAijyj‚Üíi).IterativeAlgorithmInput:E,{Aij}(i,j)‚ààE,kmaxOutput:EstimationsÃÇ{Aij}1:Forall(i,j)‚ààEdoInitializey(0)j‚ÜíiwithrandomZij‚àºN(1,1);2:Fork=1,...,kmaxdoForall(i,j)‚ààEdox(k)i‚Üíj‚ÜêPj0‚àà‚àÇi\jAij0y(k‚àí1)j0‚Üíi;Forall(i,j)‚ààEdoy(k)j‚Üíi‚ÜêPi0‚àà‚àÇj\iAi0jx(k)i0‚Üíj;3:Foralli‚àà[m]doxi‚ÜêPj‚àà‚àÇiAijy(kmax‚àí1)j‚Üíi;4:OutputestimatevectorsÃÇ{Aij}=[sign(xi)].WhileouralgorithmisinspiredbythestandardBeliefPropagation(BP)algorithmforapproximat-ingmax-marginals[10,11],ouralgorithmisoriginalandovercomesafewcriticallimitationsofthestandardBP.First,theiterativealgorithmdoesnotrequireanyknowledgeofthepriordistributionofpj,whereasthestandardBPrequirestheknowledgeofthedistribution.Second,thereisnoefficientwaytoimplementstandardBP,sinceweneedtopasssufficeintstatistics(ormessages)whichunderourgeneralmodelaredistributionsoverthereals.Ontheotherhand,theiterativealgorithmonlypassesmessagesthatarerealnumbersregardlessofthepriordistributionofpj,whichiseasytoim-plement.Third,theiterativealgorithmisprovablyasymptoticallyorder-optimal.Densityevolution,explainedindetailinSection3,isastandardtechniquetoanalyzetheperformanceofBP.AlthoughwecanwritedownthedensityevolutionforthestandardBP,wecannotanalyzethedensities,ana-lyticallyornumerically.Itisalsoverysimpletowritedownthedensityevolutionequationsfortheiterativealgorithm,butitisnottrivialtoanalyzethedensitiesinthiscaseeither.Wedevelopanoveltechniquetoanalyzethedensitiesandproveoptimalityofouralgorithm.2.1PerformanceguaranteeWestatethemainanalyticalresultofthispaper:forrandom(l,r)-regularbipartitegraphbasedtaskassignmentswithouriterativeinferencealgorithm,theprobabilityoferrordecaysexponentiallyinlq,uptoauniversalconstantandforabroadrangeoftheparametersl,randq.Withareasonablechoiceofl=randbothscalinglike(1/q)log(1/),theproposedalgorithmisguaranttedtoachieveerrorlessthanforany‚àà(0,1/2).Further,analgorithmindependentlowerboundthatweestablishsuggeststhatsuchanerrordependenceonlqisunavoidable.Hence,intermsofthetaskallocationbudget,ouralgorithmisorder-optimal.Theprecisestatementsfollownext.Let¬µ=E[2pj‚àí1]andrecallq=E[(2pj‚àí1)2].Tolightenthenotation,letÀÜl‚â°l‚àí1andrÃÇ‚â°r‚àí1.DefineœÅ2k‚â°2q¬µ2(q2ÀÜlrÃÇ)k‚àí1+3+1qrÃÇ1‚àí(1/q2ÀÜlrÃÇ)k‚àí11‚àí(1/q2ÀÜlrÃÇ).Forq2ÀÜlrÃÇ>1,letœÅ2‚àû‚â°limk‚Üí‚àûœÅ2ksuchthatœÅ2‚àû=3+(1/qrÃÇ)q2ÀÜlrÃÇ/(q2ÀÜlrÃÇ‚àí1).Thenwecanshowthefollowingboundontheprobabilityofmakinganerror.Theorem2.1.Forfixedloftheworkerreliaiblitysatisfy¬µ‚â°E[2pj‚àí1]>0andq2>1/(ÀÜlrÃÇ),thenforanys‚àà{¬±1}m,theestimatesfromkiterationsoftheiterativealgorithmachievelimm‚Üí‚àûanswers.Wecancomputeitusingpoweriteration:foru‚ààRmandv‚ààRn,startingwitharandomlyinitializedv,poweriterationiterativelyupdatesuandvaccordingtoforalli,ui=1e-050.00010.0010.010.11051015202530MajorityVotingEMAlgorithmIterativeAlgorithmLowerBoundlPError1e-061e-050.00010.0010.010.1100.050.10.150.20.250.30.350.4MajorityVotingEMAlgorithmIterativeAlgorithmLowerBoundqPErrorFigure1:TheiterativealgorithmimprovesovermajorityvotingandEMalgorithm[7].ThisisalsoillustratedinFigure1.Werannumericalexperimentswith1000tasksand1000work-ersfromthespammer-hammermodelAnalyzingthedensity.OurstrategytoprovideanupperboundonP(xÃÇ(k)‚â§0)istoshowthatxÃÇ(k)issub-GaussianwithappropriateparametersandusetheChernoffbound.ArandomvariablezwithmeanmissaidReferences[1]A.P.DawidandA.M.Skene.Maximumlikelihoodestimationofobservererror-ratesusingtheemalgorithm.JournaloftheRoyalStatisticalSociety.SeriesC(AppliedStatistics),28(1):20‚Äì28,1979.[2]A.P.Dempster,N.M.Laird,andD.B.Rubin.Maximumlikelihoodfromincompletedataviatheemalgorithm.JournaloftheRoyalStatisticalSociety.SeriesB(Methodological),39(1):pp.1‚Äì38,1977.[3]R.JinandZ.Ghahramani.Learningwithmultiplelabels.Advancesinneuralinformationprocessingsystems,pages921‚Äì928,2003.[4]V.C.Raykar,S.Yu,L.H.Zhao,G.H.Valadez,C.Florin,L.Bogoni,andL.Moy.Learningfromcrowds.J.Mach.Learn.Res.,99:1297‚Äì1322,August2010.[5]J.Whitehill,P.Ruvolo,T.Wu,J.Bergsma,andJ.Movellan.Whosevoteshouldcountmore:Optimalintegrationoflabelsfromlabelersofunknownexpertise.AdvancesinNeuralInfor-mationProcessingSystems,22:2035‚Äì2043,2009.[6]P.Welinder,S.Branson,S.Belongie,andP.Perona.TheMultidimensionalWisdomofCrowds.pages2424‚Äì2432,2010.[7]V.S.Sheng,F.Provost,andP.G.Ipeirotis.Getanotherlabel?improvingdataqualityanddataminingusingmultiple,noisylabelers.InProceedingofthe14thACMSIGKDDinternationalconferenceonKnowledgediscoveryanddatamining,KDD‚Äô08,pages614‚Äì622.ACM,2008.[8]T.RichardsonandR.Urbanke.ModernCodingTheory.CambridgeUniversityPress,march2008.[9]B.BollobaÃÅs.RandomGraphs.CambridgeUniversityPress,January2001.[10]J.Pearl.ProbabilisticReasoninginIntelligentSystems.MorganKaufmannPubl.,SanMateo,Califonia,1988.[11]J.S.Yedidia,W.T.Freeman,andY.Weiss.Understandingbeliefpropagationanditsgen-eralizations,pages239‚Äì269.MorganKaufmannPublishersInc.,SanFrancisco,CA,USA,2003.[12]M.