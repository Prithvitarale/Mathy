Extending Lipschitz functions via random metric partitions
James R. Leeâˆ—
U.C. Berkeley
jrl@cs.berkeley.edu
Assaf Naor
Microsoft Research
anaor@microsoft.com
1 Introduction
Many classical problems in geometry and analysis involve the gluing together of local informa-
tion to produce a coherent global picture. Inevitably, the difficulty of such a procedure lies at
the local boundary, where overlapping views of the same locality must somehow be merged.
It is therefore desirable that the boundaries be â€œsmooth,â€ allowing a graceful transition from
one viewpoint to the next. For instance, one may point to Whitneyâ€™s use of partitions of unity
in studying what is now known as the Whitney extension problem [36, 37].
In the present work, we consider what is perhaps the most basic Whitney-type extension
problem, that of extending a Lipschitz function so that it remains Lipschitz. Often such a
map is extended by first producing a cover of the new domain, extending the mapping locally,
and then gluing together the individual pieces. Our main observation is that in many cases, if
one chooses a random cover from the right distribution, the boundary can be made â€œsmoothâ€
on average, even when the local maps are individually quite coarse. This insight leads to the
unification, generalization, and improvement of many known results, as well as to new results
for many interesting spaces.
1.1 The Lipschitz extension problem
Let (Y, dY ), (Z, dZ) be metric spaces, and for every X âŠ† Y , denote by e(X, Y, Z) the infimum
over all constants K such that every Lipschitz function f : X â†’ Z can be extended to a
function Ëœ
f : Y â†’ Z satisfying k Ëœ
fkLip â‰¤ KkfkLip. (If no such K exists, we set e(X, Y, Z) = âˆ).
We also define e(Y, Z) = sup{e(X, Y, Z) : X âŠ† Y } and for every integer n, en(Y, Z) =
sup{e(X, Y, Z) : X âŠ† Y, |X| â‰¤ n}.
Estimating e(Y, Z) is a classical and fundamental problem that has attracted a lot of
attention due to its intrinsic interest and applications to geometry and approximation theory.
It is a classical fact that for every metric space Y , e(Y, â„“âˆ) = 1, and Kirszbraunâ€™s famous
extension theorem [19] states that whenever H1 and H2 are Hilbert spaces, e(H1, H2) = 1. We
refer to the books [3, 35] for a detailed account of the case e(Y, Z) = 1.
Typically, proofs of the fact that e(Y, Z) = 1 involve showing that it is possible to extend
an arbitrary Lipschitz function to an additional point while preserving the Lipschitz constant.
Once this is achieved, the existence of the required extension follows from Zornâ€™s lemma. When
e(Y, Z) > 1, this â€œone point at a timeâ€ argument cannot work, since the Lipschitz constant
will deteriorate with each iteration. Hence, in proving â€œnon-isometricâ€ extension results, one
âˆ—
Work partially supported by NSF grant CCR-0121555 and an NSF Graduate Research Fellowship. The
majority of this work was completed while the author was an intern at Microsoft Research, Redmond, WA.
1
must argue that it is possible to extend Lipschitz functions to arbitrarily many points at once,
and it is therefore not surprising that such results are more recent.
The following theorem was proved by Marcus and Pisier in [27], via a probabilistic argu-
ment.
Theorem 1.1 (Marcus-Pisier [27]). For every 1 < p < 2 there exists a constant C(p) such
that for every integer n,
en(Lp, L2) â‰¤ C(p) (log n)1/pâˆ’1/2
.
The Marcus-Pisier theorem initiated the study of the parameter en(Â·, Â·), and using a differ-
ent probabilistic argument, Johnson and Lindenstrauss [17] subsequently proved the following
theorem.
Theorem 1.2 (Johnson-Lindenstrauss [17]). For every metric space Y and every integer
n,
en(Y, L2) â‰¤ 2
p
log n.
In [17], it was also shown that Theorem 1.1 and Theorem 1.2 are almost optimal, in the
sense that, for every 1 â‰¤ p < 2, en(Lp, L2) â‰¥ C(p)

log n
log log n
1/pâˆ’1/2
.
In [18] Johnson, Lindenstrauss and Schechtman studied the case when the target space is
an arbitrary Banach space, proving the following two theorems.
Theorem 1.3 (Johnson-Lindenstrauss-Schechtman [18]). There exists a universal con-
stant C such that for every metric space Y , every Banach space Z and every integer n,
en(Y, Z) â‰¤ C log n.
Theorem 1.4 (Johnson-Lindenstrauss-Schechtman [18]). There exists a universal con-
stant C such that for every d-dimensional normed space Y and every Banach space Z, e(Y, Z) â‰¤
Cd.
Additionally, MatousÌŒek has shown in [28] that
Theorem 1.5 (MatousÌŒek [28]). There exists a universal constant C such that for every
metric tree T and every Banach space Z, e(T, Z) â‰¤ C.
In the important paper [1] (which introduced, among other things, the notion of Markov
type), K. Ball has shown that for every 1 < p < 2, e(L2, Lp) â‰¤ 6
âˆš
pâˆ’1
. More recently
Tsarâ€²kov [34] proved that for every 2 < p < âˆ, e(Lp, L2) â‰¤ C(p) < âˆ and the second
named author proved in [30] that in the same range of p, e(L2, Lp) = âˆ. A quantitative
version of the last result is discussed in the next section.
The extension problem when the target space Z isnâ€™t linear (e.g. Hadamard manifolds)
has also received a lot of attention. We deal with this problem in Section 1.3 below.
1.2 Absolute Lipschitz extendability
We return to these old problems with the new perspective made possible by recent advances
in combinatorics and theoretical computer science. Often in theoretical computer science,
one needs to analyze data with an inherent metric structure (e.g. graphs). A technique
developed over the past decade to handle such problems can be referred to as the method of
stochastic metric decomposition. The basic idea is that given a metric space X, one constructs
2
a distribution over partitions of X with certain desirable properties. For example, one often
requires that each set in the partition has small diameter and yet, in expectation, that every
point is â€œfar from the boundaryâ€ of the partition. Variants of this approach have appeared in
numerous contexts; see for instance [26, 20, 2].
We offer a new approach to extension problems by showing that one can pass from a
stochastic decomposition to a â€œwell-behavedâ€ partition of unity which, in turn, can be used to
extend Lipschitz functions in such a way that we have control on the growth of the Lipschitz
constant. This allows us to obtain simple proofs of many of the extension theorems stated
above, and more importantly, to obtain new extension theorems which, in some cases, are
significant generalizations of the above results.
Additionally, we observe a new phenomenon underlying some of the previous results which
we refer to as absolute extendabilityâ€”the notion that for some spaces X, Lipschitz functions
f from X into any Banach space Z can be extended to any containing space Y âŠ‡ X, where
the loss in the Lipschitz constant is independent of Y , Z, and f, and thus depends only on X.
To this end, let us define, for a metric space X, the absolute extendability constant ae(X) by
ae(X) = sup{e(X, Y, Z) : Y âŠ‡ X, Z a Banach space}.
If ae(X) < âˆ, we say that X is absolutely extendable. Additionally, for a family of metric
spaces M, let us define ae(M) = supXâˆˆM ae(X) to be a uniform bound on the extendability
of metrics in M. As far as we are aware, the only previously known families of absolutely
extendable metrics had such a property for a â€œtrivialâ€ reason; these are the cases when X
is an absolute Lipschitz retract or when the family M consists of finite metrics of uniformly
bounded cardinality (it is not to difficult to see that Theorem 1.3 is true when log n is replaced
by n). We now turn to our results, some of which have been announced in [24].
Recall that the doubling constant (see, e.g. [15]) of a metric space X, denoted Î»(X), is
the infimum over all numbers Î» such that every ball in X can be covered by Î» balls of half
the radius. When Î»(X) < âˆ, one says that X is doubling. Applying our approach to the
stochastic decomposition of [14] yields the following result.
Theorem 1.6. There exists a universal constant C > 0 such that
ae(X) â‰¤ C log Î»(X).
Since log Î»(X) = O(log n) for any n-point metric space X, and log Î»(X) = O(d) whenever
X is a subset of some d-dimensional normed space, Theorem 1.6 unifies and generalizes The-
orems 1.3 and 1.4. Moreover, it is interesting to note that, unlike Theorem 1.4, Theorem 1.6
only assumes a bound on the dimension of some normed space containing X, while Y is al-
lowed to be arbitrary. The proof of Theorem 1.4 in [18] cannot be used to obtain such a result,
since their proof uses nets in the complement of X. Techniques used in the proof of the above
theorem also allow one to extend Lipschitz functions to neighborhoods of subsets of manifolds
of negative curvature using an estimate of Bishop (see Corollary 3.13 in Section 3.2).
Our next theorem provides a significant generalization of Theorem 1.5. Let G = (V, E) be
a countable graph with edge weights in [0, âˆ]. Denote by Î£(G) the one-dimensional simplicial
complex that arises from G by replacing every edge e of G by an interval whose length is
equal to that of e. Note that Î£(G) has a natural Riemannian metric structure and that the
shortest path metric on G occurs as a submetric. For a family of metric spaces M, define
M = {(X, d) : X âŠ† Y for some (Y, d) âˆˆ M}, i.e. the closure of M under taking submetrics.
3
We now define the set of metrics supported on G by
hGi =
[
all weights
Î£(G)
where the union is taken over all possible weights on edges of G. Finally, for a family of graphs
F, let hFi =
S
GâˆˆF hGi. Given such a family of graphs F, one can ask when there exists a
constant KF such that, ae(hFi) â‰¤ KF . For instance, note that if F is the family of graph-
theoretic trees, then hFi is precisely the class of metrics which are a submetric of a separable
metric tree, and such a result would strengthen Theorem 1.5 in the separable case. We will
see momentarily that such a result does follow and thus implies that a Lipschitz function on
any subset of a separable metric tree can be extended to any superspace with a universally
bounded loss in the Lipschitz constant, while MatousÌŒekâ€™s proof relies heavily on the fact that
the superspace is a tree.
To state the next result, we need to recall the definition of a graph minor. Namely, consider
the following two operations on a graph G = (V, E).
1. Removal of an edge e âˆˆ E, i.e. moving to the graph Gâ€² = (V, E \ {e}).
2. Contraction of an edge {u, v} âˆˆ E, yielding the graph Gâ€² = (V â€², Eâ€²), where V â€² = V \
{u, v} âˆª {vâˆ—} and {s, t} âˆˆ Eâ€² precisely when either (i) {s, t} âˆˆ E for vâˆ— /
âˆˆ {s, t} or when
(ii) s = vâˆ—, t 6= vâˆ—, and either {u, t} âˆˆ E or {v, t} âˆˆ E.
When a graph Gâ€² is obtainable from G by a finite sequence of such operations, Gâ€² is called a
minor of G. If a family of graphs F has the property that Gâ€² âˆˆ F whenever G âˆˆ F and Gâ€² is
a minor of G, we say that F is minor-closed. Finally, we say that a graph G excludes Kr if
it does not contain the complete graph on r vertices as a minor. Using the decomposition of
[20], along with its stochastic formulation in [31] and a quantitative improvement due to [10]
yields
Theorem 1.7. If a graph G excludes Kr, then ae(hGi) â‰¤ C r2 for some universal constant C.
In particular, it is not difficult to see that trees are precisely the class of graphs which
exclude K3 as a minor. But the above result provides an even more significant extension to
Theorem 1.5 by showing, for instance, that the family of planar metrics is absolutely extendable
(it is well-known that every planar graph excludes K5 as a minor).
To see a striking consequence of this result, which is proved in Section 5 in conjunction with
a deep theorem of Robertson and Seymour [32], let us restrict ourselves (for the moment) to
families of finite graphs and ask the question, for such a family, when is it that ae(hFi) â‰¤ KF
and when do we have ae(hFi) = âˆ? Clearly if hFi contains all finite metrics, then ae(hFi) =
âˆ (see, for instance, the remark after the statement of Theorem 1.2, which shows that there
is no uniform bound for finite subsets of L1). It happens that this is the only case.
Corollary 1.8. For a family of finite graphs F, ae(hFi) < âˆ if and only if hFi does not
contain all finite metrics.
The techniques used in proving Theorem 1.7 also yield the following result.
Corollary 1.9. If M is a two-dimensional Riemannian manifold of genus g, then for every
subset X âŠ† M, we have ae(X) â‰¤ C Â· (g + 1) for some universal constant C.
4
We note here that since any n-point metric space is isometrically embeddable in a two-
dimensional Riemannian manifold of genus O(n3), in Corollary 1.9, ae(M) must tend to infinity
with the genus of M.
Using our approach, together with the stochastic decomposition of [6] and the improved
analysis of [8, 9] (which we generalize to arbitrary measurable metric spaces in Theorem 3.17),
it is possible to obtain an asymptotic improvement over Theorem 1.3.
Theorem 1.10. There exists a universal constant C such that for every n-point metric space
X,
ae(X) â‰¤ C
log n
log log n
.
Our techniques, in conjunction with the decomposition of [7], also give a different kind of
improvement to Theorem 1.4 (of a geometric flavor).
Theorem 1.11. For any Banach space Z, e(â„“d
2, Z) â‰¤ C
âˆš
d.
It follows that for any normed space Y , we have e(Y, Z) â‰¤ C
âˆš
d Â· dist(Y, â„“d
2), where dist is
the Banach-Mazur distance. In particular, when Y is a d-dimensional normed space, Johnâ€™s
theorem [16] implies that e(Y, Z) â‰¤ C Â· d. When Y is closer to a Hilbert space, improved
bounds are achieved.
Finally, in the case when Y is an Lp space and 1 < p â‰¤ 2, we obtain the following estimate
for finite subsets.
Theorem 1.12. For every 1 < p â‰¤ 2 there exits a constant C(p) such that for every integer
n and every Banach space Z,
en(Lp, Z) â‰¤ C(p) (log n)1/p
.
The case p = 2 in Theorem 1.12 may be viewed as a â€œdualâ€ to Theorem 1.2.
It has been asked in [18] whether en(L2, Z) is bounded for every Banach space Z. Since
in [30] it was shown by the second named author that for 2 < p < âˆ, e(L2, Lp) = âˆ, it
follows that the answer to this question is negative (this fact was overlooked in [30]). Since
en(L2, L2) = en(L2, Lâˆ) = 1, it is of interest to give quantitative lower bounds on en(L2, Lp)
for 2 < p < âˆ. We therefore analyze the proof in [30] and obtain the following lower bound.
Lemma 1.13. For every integer n and every 2 < p < âˆ,
en(L2, Lp) â‰¥ C

log n
log log n
pâˆ’2
p2
,
where C is a universal constant.
1.3 Lipschitz functions which take values in a barycentric metric space
In recent years there has been considerable effort to obtain extension theorems for Lips-
chitz functions which take values in spaces which are not Banach spaces. A generalization
of Kirszbraunâ€™s extension theorem to metric spaces with certain curvature bounds was proved
by Lang and Schroeder in [26]. The problem of estimating e(X, Y, Z) when Z is the hyperbolic
space Hn arose in the context of geometric group theory. This problem was posed by Gromov
5
in [11] and has been subsequently studied by Lang, PavlovicÌ and Schroeder in [23]. We refer
to [5, 23, 26] and the references therein for a selection of related results.
Since our approach to the extension problem is based on a random construction and an
averaging argument, it is most natural to present it in the context of Banach spaces (as in this
case taking expectation has a concrete meaning). However, our methods generalize to a wider
class of target spaces which encompasses, for example, the spaces considered by Lang, PavlovicÌ
and Schroeder in [23]. The basic idea is that instead of taking expectations, we need to require
that every compactly supported measure on the target space Z has a barycenter, and that the
map which assigns to each measure its barycenter is Lipschitz continuous. A similar notion
was introduced by Gromov in [13] (see also [33]). It will be instructive to begin by presenting
the definition of Gromov codiffusion spaces from [13, 33]. For a metric space Z let MZ be the
set of all regular Borel probability measures on X, topologized with the total variation norm
k Â· kTV . A random walk, or a diffusion, on Z is a continuous map Âµ : Z â†’ MZ. A codiffusion
on Z is a continuous map c : M â†’ Z defined on a convex subset M âŠ† MZ containing all
the Dirac measures Î´z such that c(Î´z) = z for every z âˆˆ Z and such that câˆ’1(z) is convex for
every z âˆˆ Z. The notion of a codiffusion is close to what we need, except that in the context
of the Lipschitz extension problem it is natural to require that c is not only continuous, but
also satisfies a certain Lipschitz condition, described in the following definition.
Definition 1.14 (Barycentric metric space). For a metric space Z let Mbounded
Z be the
set of all regular Borel probability measures on Z with bounded support. We shall say that Z
is barycentric if there exists a constant Î² > 0 and a map c : Mbounded
Z â†’ Z such that c(Î´z) = z
for every z âˆˆ Z and for every Âµ, Î½ âˆˆ Mbounded
Z ,
dZ(c(Âµ), c(Î½)) â‰¤ Î² Â· diam(supp(Âµ + Î½)) Â· kÂµ âˆ’ Î½kTV . (1)
The least constant Î² for which there exists such a mapping c is denoted Î²(Z). When Î²(Z) â‰¤ Î²
we say that Z is Î²-barycentric.
If Z is a Banach space then Î²(Z) = 1. Indeed, for Âµ âˆˆ Mbounded
Z we define c(Âµ) to
be the usual â€œcenter of massâ€
R
Z xdÂµ(x). Barycentric metric spaces need not, however, be
linear. Examples of barycentric spaces are Hadamard spaces, i.e. complete geodesic metric
spaces satisfying the CAT(0) comparison inequality of Alexandrov-Toponogov (see [23]). This
class of spaces includes Hadamard manifolds, i.e. complete, simply connected Riemannian
manifolds of nonpositive sectional curvature and is closed under taking products and gluing
along closed convex subsets. If Z is a Hadamard space and Âµ âˆˆ Mbounded
Z then c(Âµ) is defined
as the unique minimizer of the function z 7â†’
R
Z d(y, z)2dÂµ(y). The existence and uniqueness
of c(Âµ), as well as the fact that this map satisfies the barycentric condition (1) with Î² = 1 are
proved in Section 4 of [23].
Most of the results presented above (namely Theorem 1.6, Theorem 1.7, Corollary 1.8,
Corollary 1.9, Theorem 1.11 and Theorem 1.12) transfer to the case when the target space Z
is allowed to be any complete barycentric metric space, the only difference being that when Z is
Î²-barycentric, the estimates for the Lipschitz constant of the extended function are multiplied
by Î². Our proof of Theorem 1.10 does not seem to admit such a generalizationâ€”this issue
is briefly discussed in Appendix 6. We present our results first for the case of linear Z, and
in Appendix 6 we explain the simple modifications required to transfer them to arbitrary
barycentric target spaces.
6
1.4 Some open problems
We end this introduction by recalling some related problems which remain open. In [1], K. Ball
asked whether e(L2, L1) is finite or infinite. Similarly, it is not known whether for 2 < p < âˆ
and 1 < q < 2, e(Lp, Lq) < âˆ. The second problem will be answered affirmatively if Ballâ€™s
Markov type 2 problem [1] is resolved positively. Finally, it is not known whether, for every
metric space X and every normed space Z, en(X, Z) = O
âˆš
log n

. All known lower bounds
fail to beat the â€œ
âˆš
log n barrier.â€
The flexibility of our approach suggests that it could be applied to other extension problems.
For example, the extendability of large scale Lipschitz maps (studied in [22]), HoÌˆlder maps
(studied in [30]) and uniformly continuous maps (studied in [4]) are all of great interest. It
is also interesting to study the applicability of the random method presented in this paper to
the higher order Whitney extension problem.
Acknowledgements: We are grateful to Misha Gromov for his support and many helpful
suggestions. Specifically, we thank him for suggesting that we look at codiffusion spaces. We
also thank Yuval Peres for several useful discussions.
2 Gentle partitions of unity
Let (Y, d) be a metric space, X a subspace of Y and (â„¦, F, Âµ) a measure space. Given K > 0
we shall say that a function Î¨ : â„¦ Ã— Y â†’ [0, âˆ) is a K-gentle partition of unity with respect
to X if the following conditions hold true:
1. For every x âˆˆ Y \ X the function Ï‰ 7â†’ Î¨(Ï‰, x) is measurable and
R
â„¦ Î¨(Ï‰, x)dÂµ(Ï‰) = 1.
2. For every Ï‰ âˆˆ â„¦ and x âˆˆ X, Î¨(Ï‰, x) = 0.
3. There exists a Borel measurable function Î³ : â„¦ â†’ X such that for every x, y âˆˆ Y ,
Z
â„¦
d(Î³(Ï‰), x) Â· |Î¨(Ï‰, x) âˆ’ Î¨(Ï‰, y)| dÂµ(Ï‰) â‰¤ Kd(x, y).
If in condition (1) above, we require that the set {Ï‰ âˆˆ â„¦ : Î¨(Ï‰, x) > 0} is finite, we shall
say the partition of unity Î¨ is locally finite.
Lemma 2.1. Let (Y, d) be a metric space and X a subspace of Y . Fix K â‰¥ 1 and assume
that Y admits a K-gentle partition of unity Î¨ : â„¦ Ã— Y â†’ [0, âˆ) with respect to X. Let C
be a closed convex set in some Banach space Z. If Î¨ is locally finite or if X is separable,
then every Lipschitz function f : X â†’ C can be extended to a function Ëœ
f : Y â†’ C such that
|| Ëœ
f||Lip â‰¤ 3K||f||Lip. Furthermore, the extension depends linearly and continuously on f.
Proof. The completeness of C implies that f can be extended to the closure of X with the
same Lipschitz constant, so we may assume without loss of generality that X is closed. Let
Î³ : â„¦ â†’ T be as in condition (2) above. If Î¨ is locally finite, then all integrals appearing below
reduce to finite sums, and we may ignore measurability issues. Thus we now assume that C
is closed and X is separable.
In what follows we refer to [3] for the basic facts on Bochner integration which we use.
Since X is separable we may assume that Z is separable. In this case, Pettisâ€™ measurability
7
lemma implies that for every y âˆˆ Y the function Ï‰ 7â†’ f(Î³(Ï‰))Î¨(Ï‰, y) is Bochner measurable.
Moreover, for every x âˆˆ X,
Z
â„¦
kf(Î³(Ï‰))kÎ¨(Ï‰, y) dÂµ(Ï‰) â‰¤
Z
â„¦
kf(Î³(Ï‰)) âˆ’ f(x)k + kf(x)k

Î¨(Ï‰, y) dÂµ(Ï‰)
â‰¤ kfkLip Â·
Z
â„¦
d(Î³(Ï‰), x) Â· |Î¨(Ï‰, x) âˆ’ Î¨(Ï‰, y)| dÂµ(Ï‰) + kf(x)k
â‰¤ kfkLip Â· Kd(x, y) + kf(x)k < âˆ.
Since C is closed, it follows that the Bochner integral
R
â„¦ d(Î³(Ï‰), x)Î¨(Ï‰, y) dÂµ(Ï‰) is a well-
defined element of C. We can therefore define, for x âˆˆ Y,
Ëœ
f(x) =
 R
â„¦ f(Î³(Ï‰))Î¨(Ï‰, x) dÂµ(Ï‰) x âˆˆ Y \ X,
f(x) x âˆˆ X.
(2)
Clearly Ëœ
f is an extension of f. To check the Lipschitz condition, take x âˆˆ Y and y âˆˆ Y \X.
Fix z âˆˆ X such that d(x, z) â‰¤ 2 d(x, X), and observe that
Ëœ
f(y) âˆ’ Ëœ
f(x) =
Z
â„¦

f(Î³(Ï‰)) âˆ’ f(z)

Â·

Î¨(Ï‰, y) âˆ’ Î¨(Ï‰, x)

dÂµ(Ï‰).
Indeed, this is obviously true if x, y âˆˆ Y \ X, while if x âˆˆ X then necessarily x = z, and the
required identity follows from (2) and the fact that Î¨(Ï‰, z) â‰¡ 0.
Now,
|| Ëœ
f(x) âˆ’ Ëœ
f(y)|| â‰¤ kfkLip
Z
â„¦
d(Î³(Ï‰), z) Â· |Î¨(Ï‰, x) âˆ’ Î¨(Ï‰, y)| dÂµ(Ï‰)
â‰¤ kfkLip
Z
â„¦

d(Î³(Ï‰), x) + d(x, z)

Â· |Î¨(Ï‰, x) âˆ’ Î¨(Ï‰, y)| dÂµ(Ï‰)
â‰¤ 3 kfkLip
Z
â„¦
d(Î³(Ï‰), x) Â· |Î¨(Ï‰, x) âˆ’ Î¨(Ï‰, y)| dÂµ(Ï‰) â‰¤ 3 K Â· kfkLip d(x, y).
3 Stochastic metric decomposition
In this section, we introduce various notions of â€œwell-behavedâ€ random (pointed) partitions of
a metric space and show that they exist in several important cases. Section 4 establishes that
such decompositions imply the existence of gentle partitions of unity.
3.1 Well-behaved decompositions
In what follows, we use the convention that the distance from a point in a metric space to the
empty set is âˆ.
Definition 3.1 (Stochastic decomposition). Let (Y, d) be a metric space and X a subspace
of Y . We shall say that (â„¦, Âµ, {Î“i(Â·), Î³i(Â·)}iâˆˆI) is a stochastic decomposition of Y with respect to
X if I is some index set, (â„¦, Âµ) is a probability space, for every Ï‰ âˆˆ â„¦, {Î“i(Ï‰)}iâˆˆI is a partition
of Y into Borel subsets and for every x âˆˆ Y the set {i âˆˆ I : âˆƒ Ï‰ âˆˆ â„¦ such that x âˆˆ Î“i(Ï‰)}
is countable. We assume that for every i âˆˆ I, Î³i : â„¦ â†’ X is a Borel measurable function
8
such that for every Ï‰ âˆˆ â„¦, d Î³i(Ï‰), Î“i(Ï‰)

< 2d X, Î“i(Ï‰)

. Finally, we require that for every
x âˆˆ Y and i âˆˆ I the set {Ï‰ âˆˆ â„¦ : x âˆˆ Î“i(Ï‰)} is measurable.
If {{Î“i(Ï‰)}iâˆˆI : Ï‰ âˆˆ â„¦} ranges over only a finite number of partitions of Y we shall say
that the decomposition (â„¦, Âµ, {Î“i(Â·), Î³i(Â·)}iâˆˆI) is finitely supported.
Definition 3.2 (Bounded decomposition). Let (â„¦, Âµ, {Î“i(Â·), Î³i(Â·)}iâˆˆI) be a stochastic de-
composition of Y with respect to X and âˆ† > 0. We say that it is âˆ†-bounded if for every
Ï‰ âˆˆ â„¦ and i âˆˆ I, diam(Î“i(Ï‰)) â‰¤ âˆ†.
Definition 3.3 (Padded decomposition). Let (â„¦, Âµ, {Î“i(Â·), Î³i(Â·)}iâˆˆI) be a âˆ†-bounded stochas-
tic decomposition of Y with respect to X and Îµ, Î´ > 0. We say that it is (Îµ, Î´)-padded if for
every x âˆˆ Y and i âˆˆ I the function Ï‰ 7â†’ d x, Y \ Î“i(Ï‰)

is measurable and if d(x, X) â‰¤ Îµâˆ†
then
Âµ
[
iâˆˆI

Ï‰ : d x, X \ Î“i
(Ï‰)

â‰¥ Îµâˆ†
!
â‰¥ Î´.
Observe that the assumptions in Definition 3.1 imply that the above union is countable.
Remark 3.4. Note that when Y is countable, the requirement the function Ï‰ 7â†’ d x, Y \ Î“i(Ï‰)

is measurable is redundant (i.e. it is enough to demand that {Ï‰ âˆˆ â„¦ : x âˆˆ Î“i(Ï‰)} is measur-
able). Indeed, for every Ï > 0,

Ï‰ âˆˆ â„¦ : d x, Y \ Î“i
(Ï‰)

< Ï =
[
yâˆˆBâ—¦(x,Ï)
{Ï‰ âˆˆ â„¦ : y /
âˆˆ Î“i
(Ï‰)}.
This observation is useful since if we are interested in extending Lipschitz functions from a
closed subset X of a separable space Y then it is enough to restrict our attention to the case
when Y is countable. Indeed, let f : X â†’ Z be a Banach space-valued Lipschitz function and
S âŠ† X, T âŠ† Y be countable dense subsets in X and Y \ X, respectively. Clearly S is closed
in S âˆª T and if we extend f|S to a Lipschitz function defined on S âˆª T then we may pass to
the closure and obtain the required extension without further loss in the Lipschitz constant.
Definition 3.5 (Thick decomposition). Let (â„¦, Âµ, {Î“i(Â·), Î³i(Â·)}iâˆˆI) be a âˆ†-bounded stochas-
tic decomposition of Y with respect to X and Îµ, Î´ > 0. We say that it is (Îµ, Î´)-thick if for every
x âˆˆ Y and i âˆˆ I the function Ï‰ 7â†’ d x, Y \ Î“i(Ï‰)

is measurable and if d(x, X) â‰¤ Îµâˆ† then
Z
â„¦
X
iâˆˆI
min

d x, Y \ Î“i
(Ï‰)

, âˆ† dÂµ(Ï‰) â‰¥ Î´âˆ†.
Observe that since {Î“i(Ï‰)}âˆ
i=1 is a partition of X, the above sum contains only one element.
Remark 3.6. Observe that if (â„¦, Âµ, {Î“i(Â·), Î³i(Â·)}iâˆˆI) is (Îµ, Î´)-padded then it is also (Îµ, ÎµÎ´)-
thick.
Definition 3.7 (Separating decomposition). Let (â„¦, Âµ, {Î“i(Â·), Î³i(Â·)}iâˆˆI) be a âˆ†-bounded
stochastic decomposition of Y with respect to X and Îµ, Î´ > 0. We say that it is (Îµ, Î´)-separating
if for every x, y âˆˆ Y such that d({x, y}, X) â‰¤ Îµâˆ†,
Z
â„¦
X
iâˆˆI
|1Î“i(Ï‰)(x) âˆ’ 1Î“i(Ï‰)(y)| dÂµ(Ï‰) â‰¤
2d(x, y)
Î´âˆ†
.
9
The next lemma simply states that for a metric space (Y, d) and an arbitrary closed sub-
space X, an (Îµ, Î´)-padded decomposition of X (with respect to itself) can be extended to a
(roughly) (Îµ, Î´)-padded decomposition of Y with respect to X. This will make it possible for
us to place assumptions only on X, letting Y be arbitrary.
Lemma 3.8 (Partition extension). Let (Y, d) be a metric space and X a closed subspace of
Y . If X admits a finitely supported (Îµ, Î´)-padded âˆ†-bounded stochastic decomposition (with re-
spect to itself), then Y admits a finitely supported ( Îµ
16+8Îµ , Î´)-padded (1+ Îµ
2 )âˆ†-bounded stochastic
decomposition with respect to X.
Proof. Let (â„¦, Âµ, {Î“i(Â·), Î³i(Â·)}iâˆˆI) be a finitely supported (Îµ, Î´)-padded âˆ†-bounded stochastic
decomposition of X. For every point x âˆˆ Y , let tx âˆˆ X be such that d(x, tx) â‰¤ 2d(x, X). Now,
for every Ï‰ âˆˆ â„¦ and i âˆˆ I, create a new set
b
Î“i
(Ï‰) = Î“i
(Ï‰)
[ 
x âˆˆ Y : d tx, X \ Î“i
(Ï‰)

â‰¥
Îµâˆ†
2
and d(x, tx) â‰¤
Îµâˆ†
4

.
Finally, for any point x âˆˆ Y \
S
iâˆˆI
b
Î“i(Ï‰), place x in a singleton cluster {x}. This constitutes
a finitely supported distribution over partitions of Y . The selection function corresponding to
b
Î“i(Â·) is simply chosen to be Î³Ì‚i = Î³i, while the selection function corresponding to a singleton
cluster {x} is an arbitrary point t âˆˆ X satisfying d(t, x) â‰¤ 2d(x, X) .
Let us now show that the above stochastic decomposition is ( Îµ
16 , Î´)-padded and (1 + Îµ
2)âˆ†-
bounded. The (1 + Îµ
2)âˆ†-bounded condition is easy; singleton clusters have diameter zero. For
points x, y âˆˆ b
Î“i(Ï‰), i âˆˆ I, we have
d(x, y) â‰¤ d(x, tx) + d(tx, ty) + d(y, ty) â‰¤
Îµâˆ†
4
+ diam Î“i
(Ï‰)

+
Îµâˆ†
4
â‰¤

1 +
Îµ
2

âˆ†.
Fix some x âˆˆ Y with d(x, X) â‰¤ Îµ
16+8Îµ 1 + Îµ
2

âˆ† = Îµâˆ†
16 . By the definition of padded
decompositions, with probability at least Î´, d tx, X \ Î“i(Ï‰)

â‰¥ Îµâˆ† for some i âˆˆ I. Our goal
will be to show that in this case we have d

x, Y \ b
Î“i(Ï‰)

â‰¥ Îµâˆ†
16 , which will complete the proof.
Assume to the contrary that there is some y âˆˆ Y \ b
Î“i(Ï‰) with d(x, y) â‰¤ Îµâˆ†
16 . Observe that
d(tx, ty) â‰¤ d(tx, x) + d(x, y) + d(y, ty) â‰¤ 2d(x, X) +
Îµâˆ†
16
+ 2 (d(x, X) + d(x, y)) <
Îµâˆ†
2
.
Hence,
d ty, X \ Î“i
(Ï‰)

â‰¥ d tx, X \ Î“i
(Ï‰)

âˆ’ d(tx, ty) >
Îµâˆ†
2
,
Since we also have that
d(y, ty) â‰¤ 2d(y, X) â‰¤ 2d(x, X) + 2d(x, y) â‰¤
Îµâˆ†
4
,
we see that y âˆˆ b
Î“i(Ï‰), which contradicts the choice of y.
Remark 3.9. For later applications, we note that if X is Îµâˆ†
32 -dense in Y and Îµ < 1, then
the above proof shows that Y admits an ( Îµ
32 , Î´)-padded 2âˆ†-bounded stochastic decomposition
with respect to itself.
Remark 3.10. Lemma 3.8 holds true when Y is countable and the decomposition in not
necessarily finitely supported (in which case the extended decomposition is not necessarily
finitely supported either). The proof is the same, and all one has to observe is that in this
case the resulting decomposition satisfies the required measurability assumptions.
10
3.2 Constructions
In this section, we construct stochastic decompositions for various classes of metric spaces.
Most of the constructions come directly from the theoretical computer science literature, but
since we are dealing here with infinite spaces, we must be somewhat delicate in placing these
finite random processes into the appropriate probability spaces and dealing with the measura-
bility issues that arise. Because of this, some of the constructions are restated in a form which
is different than that in which they originally appeared.
Let (X, d) be a metric space and R > r > 0. Denote by C(X; R, r) the largest cardinality
of a set N âŠ† X satisfying for every distinct x, y âˆˆ N, r â‰¤ d(x, y) â‰¤ R. The following result
is essentially contained in [14], though we must deal with a technical issue due to our use of
possibly infinite nets.
Lemma 3.11. For every âˆ† > 0, every metric space (X, d) admits an Îµ, 1
2

-padded âˆ†-
bounded finitely supported stochastic decomposition of X with respect to itself, where Îµ =
1
256 log[C(X;2âˆ†,âˆ†/4)] .
Proof. For ease of notation, we construct a 4âˆ†-bounded decomposition. We may assume that
C(X; 8âˆ†, âˆ†) is finite, since otherwise the result holds vacuously. Let N be a âˆ†-net of X. First,
we need to introduce a distribution over partial orders â‰º on N such that for every ball B âŠ‚ X
of radius 3âˆ†, â‰º is a uniformly random total order on B âˆ© N (note that |B âˆ© N| is finite). To
this end, consider the infinite graph G = (N, E) where {x, y} âˆˆ E if and only if d(x, y) â‰¤ 3âˆ†.
The degree of G is at most C(X; 6âˆ†, âˆ†) < âˆ, and thus G admits a proper coloring using
some finite number of color classes; call these classes 1, 2, . . . , M. Now let Ïƒ be a random
permutation on {1, . . . , M} and let Ï‡ : N â†’ {1, . . . , M} be a proper coloring. Finally, define
x â‰º y if and only if Ïƒ(Ï‡(x)) < Ïƒ(Ï‡(y)). It is easy to see that for a ball B of radius 3âˆ†, every
point in B âˆ© N receives a unique color, and thus Ïƒ induces a uniformly random permutation
on B. It follows that â‰º satisfies the desired properties.
Now choose a radius R âˆˆ [âˆ†, 2âˆ†] uniformly at random. For each y âˆˆ N, define a cluster
Cy = {x âˆˆ X : x âˆˆ B(y, R) and y â‰º z for all z âˆˆ N with x âˆˆ B(z, R)}.
Since N is a âˆ†-net and R â‰¥ âˆ†, P = {Cy}yâˆˆN constitutes a partition of X. Clearly all the
clusters Cy have diameter at most 4âˆ†. Finally, we construct the required selectors as follows:
for y âˆˆ N let Î³y be the minimal element of N in Cy (with respect to â‰º).
Now fix a value t âˆˆ [0, âˆ†] and some x âˆˆ X. Let W = B(x, 2âˆ† + t) âˆ© N, and note that
m = |W| â‰¤ C(X; 6âˆ†, âˆ†). Arrange the points w1, . . . , wm âˆˆ W in order of increasing distance
from x, and let Ik be the interval [d(x, wk) âˆ’ t, d(x, wk) + t]. Let us say that B(x, t) is cut if
for some cluster Cwk
, Cwk
âˆ© B(x, t) 6= âˆ…, but B(x, t) * Cwk
. Finally, write Ek for the event
that wk is the minimal element in W (according to â‰º) for which Cwk
cuts B(x, t). Then,
Pr[B(x, t) is cut] â‰¤
m
X
k=1
Pr[Ek]
=
m
X
k=1
Pr[R âˆˆ Ik] Â· Pr[Ek | R âˆˆ Ik]
â‰¤
m
X
k=1
2t
âˆ†
Â·
1
k
â‰¤
2t
âˆ†
(1 + log m) â‰¤
8t
âˆ†
log [C(X; 6âˆ†, âˆ†)] .
11
Setting t = âˆ†
64 log[C(X;6âˆ†,âˆ†)] yields the required result. We remark that the stochastic decom-
position can be made finitely supported by choosing R uniformly from a sufficiently fine mesh
in [âˆ†, 2âˆ†].
Corollary 3.12 (Doubling metrics). Let (X, d) be a doubling metric space. Then for every
âˆ† > 0, there exists a

1
C log Î»(X), 1
2

-padded âˆ†-bounded finitely supported stochastic decompo-
sition of X with respect to itself, where C is a universal constant.
Proof. This is a direct consequence of Lemma 3.11, since it is evident that log [C(X; 2âˆ†, âˆ†/4)] =
O (log Î»(X)). Indeed, let N âŠ† X be a set such that, for every distinct x, y âˆˆ N, âˆ†
4 â‰¤ d(x, y) â‰¤
2âˆ†. Then clearly X is contained in a ball of radius 2âˆ† which can be covered by Î»(X)4 balls of
radius âˆ†
8 . Since every such ball contains at most one point of N, we see that |N| â‰¤ Î»(X)4.
Corollary 3.13 (Negatively curved manifolds). Fix r > 0 and let M be an n-dimensional
Riemannian manifold satisfying Ricci(g) â‰¥ âˆ’(n âˆ’ 1)rg, where g is the Riemannian metric on
M and Ricci(g) is the Ricci curvature of g. Then for any subset A âŠ† M and every âˆ† > 0,
A admits an Îµ, 1
2

-padded âˆ†-bounded finitely supported stochastic decomposition (with respect
to itself), where Îµ = c
n(1+
âˆš
râˆ†)
and c is a universal constant.
Proof. Fix 0 < R1 < R2 and x âˆˆ M. The following inequality is a well known consequence of
Bishopâ€™s inequality (see Lemma 5.3, pg. 275 in [12]):
Vol (BM (x, R2))
Vol (BM (x, R1))
â‰¤
R R2
0

e
âˆš
rt âˆ’ eâˆ’
âˆš
rt
nâˆ’1
dt
R R1
0

e
âˆš
rt âˆ’ eâˆ’
âˆš
rt
nâˆ’1
dt
.
By standard arguments it follows that:
log [C(A; 2âˆ†, âˆ†/4)] â‰¤ log [C(M; 2âˆ†, âˆ†/4)] â‰¤ O

1 +
âˆš
râˆ†

Â· n,
so that Lemma 3.11 implies the required result.
A strong decomposition for excluded-minor spaces follows from the (graph) decompositions
of [20], and a similar notion was used in [31] to embed planar metrics into â„“2. We sketch the
argument below.
Lemma 3.14 (Excluded minors). Let G be a graph which does not possess Kr as a minor,
and suppose that X âˆˆ hGi. Then for every âˆ† > 0, X admits a c
r2 , 1
2

-padded âˆ†-bounded
finitely supported stochastic decomposition with respect to itself.
Proof. Let G be a weighted graph without a Kr minor such that X âŠ† Î£(G). Fix some
Î² âˆˆ (0, 1] and k âˆˆ N. Consider the distribution Âµ on P which arises from the following random
process. We decompose Î£(G) recursively. Let x0 be an arbitrary point of X. Choose now
some u âˆˆ [0, Î²âˆ†) uniformly at random and consider, for each n âˆˆ N âˆª {0}, the annuli
An =

x âˆˆ Î£(G) : (n âˆ’ 1)Î²âˆ† + u â‰¤ dÎ£(G)(x, x0) < nÎ²âˆ† + u .
In general, the sets An may be disconnected in the topology of Î£(G). Let C denote the set of
(disjoint) connected components of the {An}, and apply the above random process again to
each component in C. The process ends after k such steps, producing a partition P of Î£(G).
12
In [20], it is shown that for some fixed Î² = Î²(r) and k = r, the above process produces
a partition P such that for every C âˆˆ P, diam(C) â‰¤ âˆ†. Improved quantitative bounds were
obtained in [10], yielding Î²(r) = â„¦ 1
r

.
For every partition P and x âˆˆ X let Ï€P (X) be the maximal r â‰¥ 0 for which there exists
A âˆˆ P such that BÎ£(G)(x, r) âŠ† A. We claim that for any x âˆˆ Î£(G) and every t > 0,
Pr[Ï€P (x) â‰¥ t] â‰¥

1 âˆ’ 2t
Î²âˆ†
k
. To see this, simply note that the probability of BÎ£(G)(x, t) being
separated into two different connected components at any step of the decomposition is at most
2t
Î²âˆ†. Choosing t = â„¦ âˆ†
r2

gives Pr[Ï€P (x) â‰¥ t] â‰¥ 1
2 . This random partition can be modified to
have finite support by choosing u uniformly from a sufficiently fine mesh in [0, Î²âˆ†), so that
Î£(G), and hence also X, admits the required padded stochastic decomposition.
Corollary 3.15 (Surfaces of bounded genus). Let M be a two dimensional Riemannian
manifold with genus g and X âŠ† M. Then for every âˆ† > 0, X admits a

c
g+1 , 1
2

-padded
âˆ†-bounded finitely supported stochastic decomposition with respect to itself.
Proof. Let N be an Î·-net in X. For every x, y âˆˆ N let â„“x,y be a minimal length geodesic joining
x and y. Consider the set Nâ€² âŠ‡ N obtained from adding all the points of intersection of the
geodesics {â„“x,y}x,yâˆˆN . Consider the graph G = (Nâ€², E), where {u, v} âˆˆ E if there is some
x, y âˆˆ N such that u and v are connected by a sub-geodesic â„“ âŠ† â„“x,y for which â„“ âˆ© Nâ€² = {u, v}.
By construction, the graph G is embedded in M (in the graph-theoretic sense). It follows
(see [29]) that G excludes a Kâ„¦(
âˆš
g+1) minor. Furthermore, N is isometric to a subset of
Î£(G) where the weight of an edge {u, v} is equal to the length of the sub-geodesic connecting
u and v. Hence N is a Kâ„¦(
âˆš
g+1)-excluded metric, so that the required result follows from
Lemma 3.14 and Remark 3.9 (for Î· small enough).
Optimal decompositions for finite subsets of â„“d
2 were given in [7]. The following lemma is
based on their techniques.
Lemma 3.16 (Finite dimensional Hilbert space.). For any closed subset X of â„“d
2 and
for every âˆ† > 0 there exists a stochastic decomposition of â„“d
2 with respect to X which is (Îµ, Î´)-
separating and âˆ†-bounded for every Îµ > 0 and Î´ = 1
2
âˆš
d
.
Proof. We construct a graph G = (Zd, E) where for u, v âˆˆ Zd, {u, v} is an edge if and
only if d u + [0, 1)d, v + [0, 1)d

â‰¤ 8âˆ†. As before, the degree of G is uniformly bounded,
and thus it admits an M-coloring Ï‡ : Zd â†’ {1, 2, . . . , M} such that Ï‡(u) 6= Ï‡(v) whenever
d u + [0, 1)d, v + [0, 1)d

â‰¤ 8âˆ†.
Denote by md the Lebesgue measure on [0, 1]d and by Î½ the uniform probability measure
on {1, . . . , M}. Consider the product space â„¦ =
Qâˆ
i=1 [0, 1)d Ã— {1, . . . , M}

equipped with
the natural product measure Âµ. Given Ï‰ = (x1, c1, x2, c2, . . .) âˆˆ â„¦ we construct recursively a
sequence of disjoint subsets of Rd, {Î“i,v(Ï‰) : i âˆˆ N, v âˆˆ Zd} as follows:
Î“k,v
(Ï‰) =
(
B2 v + xk, âˆ†
2

\
Skâˆ’1
j=1
S
uâˆˆZd Î“j,u(Ï‰)

if Ï‡(v) = ck
âˆ… otherwise,
where B2(y, Ï) denotes the closed Euclidean ball of radius Ï centered at y. The sets {Î“i,v(Ï‰) :
i âˆˆ N, v âˆˆ Zd} form a partition of [0, 1)d with probability one. We claim that there exist
measurable maps Î³i,v : â„¦ â†’ X such that for every Ï‰ âˆˆ â„¦, d Î³i,v(Ï‰), Î“i,v(Ï‰)

â‰¤ 2d X, Î“i,v(Ï‰)

.
13
Indeed, by a classical measurable selection theorem of Kuratowski and Ryll-Nardzewski [21]
it is enough to check that for every open ball B âŠ† Rd the set
n
Ï‰ âˆˆ â„¦ : B âˆ© X âˆ©
n
a âˆˆ Rd
; d a, Î“i,v
(Ï‰)

â‰¤ 2d X, Î“i,v
(Ï‰)
o
6= âˆ…
o
is measurable, and this fact follows directly from the construction.
The above decomposition is trivially âˆ†-bounded. Now, fix x, y âˆˆ Rd. Since the (Îµ, Î´)-
separating condition is trivial for d(x, y) > âˆ†, assume that d(x, y) â‰¤ âˆ†. We now bound the
probability that x and y end up in different clusters. It follows from the construction that x
and y are separated in the partition induced by Ï‰ = (x1, c1, x2, c2, . . .) precisely when there
is an index j for which

xj + Ï‡âˆ’1(cj)

âˆ©

B2 x, âˆ†
2

â–³ B2 y, âˆ†
2

6= âˆ… while

xi + Ï‡âˆ’1(ci)

âˆ©

B2 x, âˆ†
2

âˆ© B2 y, âˆ†
2

= âˆ… for every i < j. Notice that since d(x, y) â‰¤ âˆ†, no two cubes from
{v + [0, 1)d : v âˆˆ Zd} which intersect B2 x, âˆ†
2

âˆª B2 y, âˆ†
2

have the same color. Denoting by
K âŠ† Rn the union of all the cubes which intersect B2 x, âˆ†
2

âˆª B2 y, âˆ†
2

, it follows that for
every Borel measurable A âŠ† K, Âµ [xk + Ï‡âˆ’1(ck)] âˆ© A 6= âˆ…

= Vol(A)
Vol(K). Hence
Z
â„¦
X
iâˆˆI
|1Î“i(Ï‰)(x)âˆ’1Î“i(Ï‰)(y)| dÂµ(Ï‰) = 2Âµ({x and y are not in the same Î“i
(Ï‰)})
â‰¤ 2
n
X
j=1
Vol B2 x, âˆ†
2

â–³ B2 y, âˆ†
2

Vol(K)
"
1 âˆ’
Vol B2 x, âˆ†
2

âˆ© B2 y, âˆ†
2

Vol(K)
#jâˆ’1
= 2
Vol B2 x, âˆ†
2

â–³ B2 y, âˆ†
2

Vol B2 x, âˆ†
2

âˆ© B2 y, âˆ†
2
 â‰¤
4
âˆš
d
âˆ†
kx âˆ’ yk2,
by straightforward volume estimates.
Finally, we present a decomposition theorem for general metric spaces Y with respect to
a compact, measurable submetric X. The analysis is based on ideas from [6] and [9] for finite
metrics.
Theorem 3.17. Let (Y, d) be a metric space and X a compact subspace of Y . If Ïƒ is any
non-degenerate Borel measure on X (i.e. one which assigns non-zero measure to every ball in
X), then for every âˆ† > 0, there exists a âˆ†-bounded stochastic decomposition of Y with respect
to X such that, for every x, y âˆˆ Y with d({x, y}, X) < âˆ†
16 ,
Z
â„¦
X
iâˆˆI
|1Î“i(Ï‰)(x) âˆ’ 1Î“i(Ï‰)(y)| dÂµ(Ï‰) â‰¤
2 d(x, y)
âˆ†

1 + log

Ïƒ(BX(x, 5âˆ†))
Ïƒ(BX(x, âˆ†))

. (3)
Proof. Since X is compact, we may assume that Ïƒ is a probability measure on X. Let us
then equip the product space â„¦â€² =
Qâˆ
i=1 X with the natural product measure Âµâ€². Finally, let
â„¦ = â„¦â€²Ã—[2âˆ†, 4âˆ†], equipped with the probability measure Pr = Âµâ€²Ã—Î», where Î» is the normalized
Lebesgue measure on [2âˆ†, 4âˆ†]. Given Ï‰ = (x1, x2, x3, . . .) âˆˆ â„¦â€² and some R âˆˆ [2âˆ†, 4âˆ†], we
construct recursively a sequence of disjoint subsets of Y , {Î“i(Ï‰, R) : i âˆˆ N} as follows,
Î“k
(Ï‰, R) = B(xk, R) \
ï£«
ï£­
kâˆ’1
[
j=1
Î“j
(Ï‰)
ï£¶
ï£¸ .
Let S = {y âˆˆ Y : d(x, y) < âˆ†
2 }, then with probability 1, for any R âˆˆ [2âˆ†, 4âˆ†], the sets
{Î“i(Ï‰, R) âˆ© S}âˆ
i=1 form a partition of S. To see this, let N be a âˆ†
4 -net in X, and consider the
14
balls B(x, âˆ†
8 ) for x âˆˆ N. Since Ïƒ is non-degenerate, it assigns any such ball positive measure,
and hence with probability 1, we have xj âˆˆ B(x, âˆ†/8) for some j âˆˆ N. Now fix a point y âˆˆ Y
such that d(y, X) < âˆ†
2 , and let z âˆˆ X be such that d(y, z) < 2 d(y, X). Observe that z is
within âˆ†
4 of some point of N, and hence within 3âˆ†
8 of some xj with probability 1. But now
we see that d(y, xj) â‰¤ d(y, z) + d(z, xj) < âˆ† + 3âˆ†
8 < 2âˆ†, hence y âˆˆ B(xj, R). It follows that
the proposed sets are indeed a partition of S with probability 1.
We define the final partition by
{Î“i
(Ï‰, R)}âˆ
i=1
[
(
{y} : y âˆˆ Y \
[
iâˆˆN
Î“i
(Ï‰, R)
)
,
and note that the required selectors exist due to an application of the Kuratowski, Ryll-
Nardzewski Theorem as in the proof of Lemma 3.16.
Fix x âˆˆ Y such that d(x, X) < âˆ†
2 and denote by Î½ the distribution of the random variable
z 7â†’ d(z, x), i.e. for 0 â‰¤ Î± < Î², Î½([Î±, Î²)) = Ïƒ({z âˆˆ X : Î± â‰¤ d(z, x) < Î²}). Fix t â‰¤ âˆ† and for
every R âˆˆ [2âˆ†, 4âˆ†] denote by DR the set of all z âˆˆ X for which B(z, R)âˆ©B(x, t) /
âˆˆ {âˆ…, B(x, t)}
(when this happens we say that B(x, t) is cut by B(z, R)). Finally, let
â„¦i,R = {Ï‰ âˆˆ â„¦â€²
: Ï‰i âˆˆ DR} \
iâˆ’1
[
j=1
{Ï‰ âˆˆ â„¦â€²
: Ï‰j âˆˆ DR}.
Observe that for Ï‰ = (Ï‰1, Ï‰2, . . .) âˆˆ â„¦â€², if Ï‰ âˆˆ â„¦i,R then the triangle inequality implies that
R âˆˆ [d(x, Ï‰i) âˆ’ t, d(x, Ï‰i) + t]. Moreover, if Ï‰i âˆˆ B(x, âˆ†) then B(x, t) âŠ† B(Ï‰i, R), since t â‰¤ âˆ†
and R â‰¥ 2âˆ†, so that B(Ï‰i, R) canâ€™t cut B(x, t). Additionally, B(Ï‰i, R) âˆ© B(x, t) 6= âˆ… implies
Ï‰i âˆˆ B(x, 5âˆ†), since R â‰¤ 4âˆ†. It follows that if Ï‰ âˆˆ â„¦i,R, then âˆ† < d(Ï‰i, x) â‰¤ 5âˆ†. Finally, if
Ï‰ âˆˆ â„¦i,R then d(Ï‰j, x) > d(Ï‰i, x) for j < i, since otherwise B(Ï‰i, R) will not be the first ball
to cut B(x, t). These observations imply that for every i = 1, 2, . . ., every R âˆˆ [2âˆ†, 4âˆ†] and
every Ï > 0,
Âµâ€²
(â„¦i,R|d(x, Ï‰i) = Ï) â‰¤ 1{Râˆˆ[Ïâˆ’t,Ï+t]} Â· 1{âˆ†<Ïâ‰¤5âˆ†}[1 âˆ’ Î½([0, Ï])]iâˆ’1
.
Hence,
Pr[B(x, t)is cut] =
1
2âˆ†
Z 4âˆ†
2âˆ†
âˆ
X
i=1
Âµâ€²
(â„¦i,R)
!
dR
=
1
2âˆ†
Z 4âˆ†
2âˆ†
âˆ
X
i=1
Z âˆ
0
Âµâ€²
(â„¦i,R|d(x, Ï‰i) = Ï)dÎ½(Ï)
!
dR
â‰¤
1
2âˆ†
Z 4âˆ†
2âˆ†
âˆ
X
i=1
Z
(âˆ†,5âˆ†]
1{Râˆˆ[Ïâˆ’t,Ï+t]} Â· [1 âˆ’ Î½([0, Ï])]iâˆ’1
dÎ½(Ï)
!
dR
â‰¤
t
âˆ†
Z
(âˆ†,5âˆ†]
dÎ½(Ï)
Î½([0, Ï])
â‰¤
t
âˆ†
log

Î½([0, 5âˆ†])
Î½([0, âˆ†])

=
t
âˆ†
log

Ïƒ(BX(x, 5âˆ†))
Ïƒ(BX(x, âˆ†))

. (4)
The last inequality above is a classical fact, which can be proved as follows: Approximate the
integral by the sum
Pk
i=1
Î½([0,Ïi])âˆ’Î½([0,Ïiâˆ’1])
Î½([0,Ïi]) for some âˆ† < Ï0 < Ï1 < . . . < Ïk = 5âˆ†, and use
the estimate Î½([0,Ïi])âˆ’Î½([0,Ïiâˆ’1])
Î½([0,Ïi]) â‰¤
R Î½([0,Ïi])
Î½([0,Ïiâˆ’1])
ds
s .
15
Observe that (3) holds trivially if d(x, y) â‰¥ âˆ†. Otherwise, choosing t = d(x, y) in (4) yields
the required result.
4 Constructing gentle partitions
In this section we show that the various decompositions that were introduced in the previous
section can be used to construct gentle partitions of unity.
Theorem 4.1 (Stochastic decompositions yield gentle partitions). There exists a uni-
versal constant C > 0 such that for every metric space (Y, d) and every subspace X âŠ† Y the
following assertions hold true:
1. If for every n âˆˆ Z, Y admits an (Îµ, Î´)-thick 2n-bounded stochastic decomposition with
respect to X, then Y also admits a C
ÎµÎ´ -gentle partition of unity with respect to X.
2. If for every n âˆˆ Z, Y admits an (Îµ, Î´)-padded 2n-bounded stochastic decomposition with
respect to X, then Y also admits a C
ÎµÎ´ -gentle partition of unity with respect to X.
3. If for every n âˆˆ Z, Y admits an (Îµ, Î´)-separating 2n-bounded stochastic decomposition
with respect to X, then Y also admits a C 1
Îµ + 1
Î´

-gentle partition of unity with respect
to X.
Proof. For every n âˆˆ Z let (â„¦n, Âµn, {Î“i
n(Â·), Î³i
n(Â·)}iâˆˆI) be a 2n-bounded stochastic decomposition
of Y with respect to X. Let Ï• : R â†’ R+ be any 2-Lipschitz map with supp(Ï•) âŠ‚ [1
2, 4] and
Ï• â‰¡ 1 on [1, 2]. Define Ï•n(x) = Ï•

d(x,X)
Îµ2nâˆ’3

and let (â„¦, Âµ) be the disjoint union of {I Ã— â„¦n}nâˆˆZ
(where the measure on I is the counting measure). In all the cases of the theorem the partition
of unity which we construct will have the following form: For every n âˆˆ Z, Ï‰ âˆˆ â„¦n, i âˆˆ I and
x âˆˆ Y denote:
Î¨(i, Ï‰, x) =
1
S(x)
Î¸n
Ï‰(x)Ï•n(x)1Î“i
n(Ï‰)(x), (5)
where for every n âˆˆ Z and x âˆˆ Y the function Ï‰ 7â†’ Î¸n
Ï‰(x) âˆˆ [0, âˆ) is Âµn-integrable and
S(x) =
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
Î¸n
Ï‰(x)Ï•n(x)1Î“i
n(Ï‰)(x) dÂµn(Ï‰) =
X
nâˆˆZ
Ï•n(x)
Z
â„¦n
Î¸n
Ï‰(x) dÂµn(Ï‰).
Additionally define Î³(i, Ï‰) = Î³i
n(Ï‰).
Observe that supp(Ï•n) âŠ†

x âˆˆ Y : d(x, X) âˆˆ

Îµ2nâˆ’4, Îµ2nâˆ’1

, so the sum in the denomi-
nator of (5) contains at most 5 terms, and is therefore finite. Additionally, the definition of
Ï•n ensures that for every x âˆˆ X and Ï‰ âˆˆ â„¦, Î¨(Ï‰, x) = 0.
The functions Î¸n
Ï‰(x) will be different in each particular case, but we begin by making some
general comments. Our goal is to show that for every x, y âˆˆ Y ,
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
d(Î³(i, Ï‰), x) Â· |Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµn(Ï‰) â‰¤
C
ÎµÎ´
Â· d(x, y). (6)
In cases (1) and (2) above and
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
d(Î³(i, Ï‰), x) Â· |Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµn(Ï‰) â‰¤ C

1
Îµ
+
1
Î´

Â· d(x, y). (7)
in case (3).
16
Claim 4.2. Fix Ï‰ âˆˆ â„¦n and assume that Î¨(i, Ï‰, x) 6= Î¨(i, Ï‰, y). Then
d(Î³(i, Ï‰), x) â‰¤ d(x, y) +
18
Îµ
Â· max{d(x, X), d(y, X)}.
Proof. Our assumption implies that either Î¨(i, Ï‰, x) > 0 or Î¨(i, Ï‰, y) > 0. In the first case,
x âˆˆ Î“i
n(Ï‰) and
d (Î³(i, Ï‰), x) â‰¤ d Î³(i, Ï‰), Î“i
n(Ï‰)

+ diam(Î“i
n(Ï‰)) â‰¤ 2d X, Î“i
n(Ï‰)

+ 2n
â‰¤ 2d(x, X) + 2n
.
On the other hand, Ï•n(x) > 0, so d(x, X) â‰¥ Îµ2nâˆ’4, which implies the required estimate. In
the second case, Î¨(i, Ï‰, y) > 0, so that
d(Î³(i, Ï‰), x) â‰¤ d(Î³(i, Ï‰), y) + d(x, y) â‰¤ 2d(y, X) + diam(Î“i
n(Ï‰)) + d(x, y)
â‰¤ 2d(y, X) + 2n
+ d(x, y) â‰¤
18
Îµ
Â· d(y, X) + d(x, y).
By Claim 4.2 we can estimate the left-hand side of (6) and (7) as follows:
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
d(Î³(i, Ï‰), x) Â· |Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµn(Ï‰)
â‰¤ d(x, y) Â·
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n

Î¨(i, Ï‰, x) + Î¨(i, Ï‰, y)

dÂµn(Ï‰)
+
18
Îµ
Â· max{d(x, X), d(y, X)}
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµn(Ï‰)
= 2d(x, y) +
18
Îµ
Â· max{d(x, X), d(y, X)}
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµn(Ï‰)
It is therefore enough to show that:
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµn(Ï‰) â‰¤
Câ€²
Î´
Â·
d(x, y)
max{d(x, X), d(y, X)}
, (8)
when the decompositions are either (Îµ, Î´)-padded or (Îµ, Î´)-thick and
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµn(Ï‰) â‰¤ Câ€²

1 +
Îµ
Î´

Â·
d(x, y)
max{d(x, X), d(y, X)}
, (9)
when the decompositions are (Îµ, Î´)-separating. Here Câ€² is a universal constant.
We may assume that Câ€² > 4, in which case inequality (8) (resp. inequality (9)) holds
trivially when d(x, y) â‰¥ d({x, y}, X). Indeed, in this case d(x, X) â‰¤ d(x, y) + d(y, X) â‰¤
2d(x, y) and analogously d(y, X) â‰¤ 2d(x, y). Hence the right-hand side of (8) (resp. (9)) is
greater than 2 while the left-hand side of (8) (resp. (9)) is at most 2 since by construction
P
nâˆˆZ
P
iâˆˆI
R
â„¦n
Î¨(i, Ï‰, z)dÂµn(Ï‰) = 1 for every z âˆˆ Y .
17
Our goal is therefore to prove (8) (resp. (9)) under the assumption d(x, y) < d({x, y}, X).
We may also assume without loss of generality that d(x, X) â‰¥ d(y, X). Now,
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµn(Ï‰)
=
X
nâˆˆZ
Z
â„¦n
X
iâˆˆI
Î¸n
Ï‰(x)Ï•n(x)1Î“i
n(Ï‰)(x)S(y) âˆ’ Î¸n
Ï‰(y)Ï•n(y)1Î“i
n(Ï‰)(y)S(x)
S(x)S(y)
dÂµn(Ï‰)
â‰¤
X
nâˆˆZ
Z
â„¦n
X
iâˆˆI
Î¸n
Ï‰(x)Ï•n(x)1Î“i
n(Ï‰)(x) âˆ’ Î¸n
Ï‰(y)Ï•n(y)1Î“i
n(Ï‰)(y)
S(x)
dÂµn(Ï‰) +
X
nâˆˆZ
Z
â„¦n
Î¸n
Ï‰(y)Ï•n(y) dÂµn(Ï‰)
!
|S(x) âˆ’ S(y)|
S(x)S(y)
â‰¤
X
nâˆˆZ
Z
â„¦n
X
iâˆˆI
Î¸n
Ï‰(x)Ï•n(x)1Î“i
n(Ï‰)(x) âˆ’ Î¸n
Ï‰(y)Ï•n(y)1Î“i
n(Ï‰)(y)
S(x)
dÂµn(Ï‰) +
X
nâˆˆZ
Z
â„¦n
Î¸n
Ï‰(y)Ï•n(y) dÂµn(Ï‰)
X
kâˆˆZ
Z
â„¦k
X
iâˆˆI
Î¸n
Ï„ (x)Ï•k(x)1Î“i
k(Ï„)(x) âˆ’ Î¸n
Ï„ (y)Ï•k(y)1Î“i
k(Ï„)(y)
S(x)S(y)
dÂµk(Ï„)
=
2
S(x)
X
nâˆˆZ
Z
â„¦n
X
iâˆˆI
Î¸n
Ï‰(x)Ï•n(x)1Î“i
n(Ï‰)(x) âˆ’ Î¸n
Ï‰(y)Ï•n(y)1Î“i
n(Ï‰)(y) dÂµn(Ï‰). (10)
We now deal with each of the particular cases in the statement of the theorem:
Case 1. The stochastic decomposition (â„¦n, Âµn, {Î“i
n(Â·), Î³i
n(Â·)}iâˆˆI) is (Îµ, Î´)-thick and 2n-bounded
for all n âˆˆ Z. In this case we take Î¸n
Ï‰(x) = Ï€n
Ï‰(x), where for every Ï‰ âˆˆ â„¦n and x âˆˆ Y ,
Ï€n
Ï‰(x) =
X
iâˆˆI
min

d x, Y \ Î“i
n(Ï‰)

, 2n
. (11)
Observe that since {Î“i
n(Ï‰)}iâˆˆI is a partition of Y , the above sum consists of only one element.
Let n0 be an integer such that d(x,X)
Îµ2n0âˆ’3 âˆˆ [1, 2]. Then
S(x) â‰¥
X
n: d(x,X)â‰¤Îµ2n
Ï•n(x)
Z
â„¦n
Ï€n
Ï‰(x) dÂµn(Ï‰)
â‰¥
X
n: d(x,X)â‰¤Îµ2n
Î´2n
Ï•n(x) â‰¥ Î´2n0
Ï•

d(x, X)
Îµ2n0âˆ’1

â‰¥ Î´2n0
â‰¥
Î´
Îµ
d(x, X). (12)
We now estimate the numerator in (10). Fix n âˆˆ Z and Ï‰ âˆˆ â„¦n. Assume first of all that
x, y âˆˆ Î“j
n(Ï‰) for some j âˆˆ I. Hence
X
iâˆˆI
Ï€n
Ï‰(x)Ï•n(x)1Î“i
n(Ï‰)(x) âˆ’ Ï€n
Ï‰(y)Ï•n(y)1Î“i
n(Ï‰)(y) = Ï€n
Ï‰(x)Ï•

d(x, X)
Îµ2nâˆ’3

âˆ’ Ï€n
Ï‰(y)Ï•

d(y, X)
Îµ2nâˆ’3

â‰¤ Ï•

d(x, X)
Îµ2nâˆ’3

|Ï€n
Ï‰(x) âˆ’ Ï€n
Ï‰(y)| + Ï€n
Ï‰(y) Ï•

d(x, X)
Îµ2nâˆ’3

âˆ’ Ï•

d(y, X)
Îµ2nâˆ’3

â‰¤ d(x, y) + Ï€n
Ï‰(y)
16d(x, y)
Îµ2n
â‰¤ d(x, y) + 2n
Â·
16d(x, y)
Îµ2n
â‰¤
17
Îµ
d(x, y). (13)
18
If, on the other hand, there are distinct i, j âˆˆ I such that x âˆˆ Î“i
n(Ï‰) and y âˆˆ Î“j
n(Ï‰) then
clearly Ï€n
Ï‰(x), Ï€n
Ï‰(y) â‰¤ d(x, y), so:
X
â„“âˆˆI
Ï€n
Ï‰(x)Ï•n(x)1Î“â„“
n(Ï‰)(x) âˆ’ Ï€n
Ï‰(y)Ï•n(y)1Î“â„“
n(Ï‰)(y) = Ï€n
Ï‰(x)Ï•

d(x, X)
Îµ2nâˆ’1

+ Ï€n
Ï‰(y)Ï•

d(y, X)
Îµ2nâˆ’1

â‰¤ Ï€n
Ï‰(x) + Ï€n
Ï‰(y) â‰¤ 2 d(x, y). (14)
Plugging the estimates (12), (13), (14) into (10) we obtain
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµn(Ï‰) â‰¤
2Îµ
Î´ d(x, X)
X
n: {x,y}âˆ©supp(Ï•n)6=âˆ…
Z
â„¦n
17
Îµ
d(x, y)dÂµn
â‰¤
340 d(x, y)
Î´ d(x, X)
, (15)
where we have used the fact that for every z âˆˆ Y , |{n : z âˆˆ supp(Ï•n)}| â‰¤ 5.
Case 2. The stochastic decomposition (â„¦n, Âµn, {Î“i
n(Â·), Î³i
n(Â·)}iâˆˆI) is (Îµ, Î´)-padded and 2n-
bounded for all n âˆˆ Z. In this case let g : [0, âˆ) â†’ [0, âˆ) be given by:
g(x) =
ï£±
ï£²
ï£³
1 x â‰¥ 2
x âˆ’ 1 1 â‰¤ x â‰¤ 2
0 0 â‰¤ x â‰¤ 1,
and define Î¸n
Ï‰(x) = g

Ï€n
Ï‰(x)
Îµ2nâˆ’1

, where Ï€n
Ï‰(x) is as in (11). Let n0 be as in the proof of (12).
Then:
S(x) â‰¥
X
n: d(x,X)â‰¤Îµ2n
Ï•n(x)
Z
{Ï‰âˆˆâ„¦n: Ï€n
Ï‰(x)â‰¥Îµ2n}
g

Ï€n
Ï‰(x)
Îµ2nâˆ’1

(x) dÂµn(Ï‰)
â‰¥ Ï•

d(x, X)
Îµ2n0âˆ’3

Âµn0
[
iâˆˆI

Ï‰ âˆˆ â„¦n0 : d x, X \ Î“i
n(Ï‰)

â‰¥ Îµ2n0
!
â‰¥ Î´. (16)
Fix n âˆˆ Z and Ï‰ âˆˆ â„¦n. Assume Ï•n(x) Â· Ï•n(y) > 0. In this case {d(x, X), d(y, X)} âˆ©
[Îµ2nâˆ’4, Îµ2nâˆ’1] 6= âˆ…, so that in particular d(y, X) â‰¤ Îµ2nâˆ’1. We are assuming that d(x, y) <
d(y, X), so d(x, X) â‰¤ d(x, y) + d(y, X) â‰¤ 2d(y, X) â‰¤ Îµ2n. If x, y âˆˆ Î“j
n(Ï‰) for some j âˆˆ I then
since g is Lipschitz with constant 1 and bounded by 1, the same reasoning as in (13) gives:
X
iâˆˆI
Î¸n
Ï‰(x)Ï•n(x)1Î“i
n(Ï‰)(x) âˆ’ Î¸n
Ï‰(y)Ï•n(y)1Î“i
n(Ï‰)(y) â‰¤
6d(x, y)
Îµ2n
â‰¤
6d(x, y)
d(x, X)
. (17)
On the other hand, if there distinct i, j âˆˆ I such that x âˆˆ Î“i
n(Ï‰) and y âˆˆ Î“j
n(Ï‰) then using the
fact that Ï€n
Ï‰(x), Ï€n
Ï‰(y) â‰¤ d(x, y) we get :
X
â„“âˆˆI
Ï€n
Ï‰(x)Ï•n(x)1Î“â„“
n(Ï‰)(x) âˆ’ Ï€n
Ï‰(y)Ï•n(y)1Î“â„“
n(Ï‰)(y) â‰¤ g

Ï€n
Ï‰(x)
Îµ2nâˆ’1

+ g

Ï€n
Ï‰(y)
Îµ2nâˆ’1

â‰¤
Ï€n
Ï‰(x)
Îµ2nâˆ’1
+
Ï€n
Ï‰(y)
Îµ2nâˆ’1
â‰¤
4d(x, y)
d(x, X)
, (18)
and we conclude as in (15).
19
Case 3. The stochastic decomposition (â„¦n, Âµn, {Î“i
n(Â·), Î³i
n(Â·)}iâˆˆI) is (Îµ, Î´)-separating 2n-bounded
for all n âˆˆ Z. This case is simpler: we take Î¸n
Ï‰(x) â‰¡ 1. Arguing as in (12) we get that S(x) â‰¥ 1.
Fix n âˆˆ Z and Ï‰ âˆˆ â„¦n and assume as before that Ï•n(x) Â· Ï•n(y) > 0. Observe that
X
iâˆˆI
Ï•n(x)1Î“i
n(Ï‰)(x) âˆ’ Ï•n(y)1Î“i
n(Ï‰)(y) â‰¤ |Ï•n(x) âˆ’ Ï•n(y)|
+
Ï•n(x) + Ï•n(y)
2
X
iâˆˆI
1Î“i
n(Ï‰)(x) âˆ’ 1Î“i
n(Ï‰)(y)
â‰¤
8d(x, y)
Îµ2n
+
X
iâˆˆI
1Î“i
n(Ï‰)(x) âˆ’ 1Î“i
n(Ï‰)(y)
â‰¤
8d(x, y)
d(x, X)
+
X
iâˆˆI
1Î“i
n(Ï‰)(x) âˆ’ 1Î“i
n(Ï‰)(y) . (19)
Plugging this estimate into (10) we get
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x)âˆ’Î¨(i, Ï‰, y)| dÂµn(Ï‰) â‰¤
8d(x, y)
d(x, X)
Â· |{n : {x, y} âˆ© supp(Ï•n) 6= âˆ…}|
+
X
n: {x,y}âˆ©supp(Ï•n)6=âˆ…
Z
â„¦n
X
iâˆˆI
1Î“i
n(Ï‰)(x) âˆ’ 1Î“i
n(Ï‰)(y) dÂµn
â‰¤
80 d(x, y)
d(x, X)
+
X
n: {x,y}âˆ©supp(Ï•n)6=âˆ…
2d(x, y)
Î´2n
â‰¤
80 d(x, y)
d(x, X)
+
20Îµd(x, y)
Î´d(x, X)
,
where we have used the (Îµ, Î´)-separating condition and the fact that in the above sum,
d(x, X) â‰¤ Îµ2n.
We proceed to construct gentle partitions of unity when X is finite. The proof is analogous
to the proof of Theorem 4.1, but there are several subtle differences, so we deal with this
important case separately. The analysis uses ideas from [8, 9], namely that a certain sum
of logarithms collapses in the analysis of the decomposition of Lemma 3.17. This allows the
smoothing function Ï• to have larger support, which will be the key to achieving an improved
result.
Theorem 4.3. There exists a universal constant C > 0 such that for all m âˆˆ N, any metric
space (Y, d) and any m-point subset X âŠ† Y , Y admits a C log m
log log m-gentle partition of unity
with respect to X.
Proof. Let M > 2 be an integer which will be determined later. Let Ï• : R â†’ R+ be a 5-
Lipschitz map with supp(Ï•) âŠ† [1
5, 5M+1] and Ï• â‰¡ 1 on [1, 5M ]. By Theorem 3.17, with Ïƒ the
counting measure on X, for every n âˆˆ Z there exists a stochastic decomposition of Y with
respect to X, (â„¦n, Âµn, {Î“i
n(Â·), Î³i
n(Â·)}iâˆˆI), which is 5n-bounded and for every x, y âˆˆ Y satisfying
d({x, y}, X) â‰¤ 5nâˆ’2,
Z
â„¦n
X
iâˆˆI
1Î“i
n(Ï‰)(x) âˆ’ 1Î“i
n(Ï‰)(y) dÂµn(Ï‰) â‰¤
2d(x, y)
5n

1 + log

|BX(x, 5n+1)|
|BX(x, 5n)|

. (20)
20
Define Ï•n(x) = Ï•

d(x,X)
5nâˆ’Mâˆ’4

, and let (â„¦, Âµ), Î¨(i, Ï‰, x), Î³(i, Ï‰), S(x) be as in the proof of
Theorem 4.1, with Î¸n
Ï‰(x) â‰¡ 1. Our goal is to show that for every x, y âˆˆ Y ,
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
d(Î³(i, Ï‰), x) Â· |Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµ(Ï‰) â‰¤ O

log m
log log m

Â· d(x, y).
In what follows we fix x, y âˆˆ Y and we may assume without loss of generality that d(x, X) â‰¥
d(y, X). As in the proof of Claim 4.2, if |Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| > 0 then d(Î³(i, Ï‰), x) â‰¤
5n + d(x, y). It is therefore enough to show that
X
nâˆˆZ
5n
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµ(Ï‰) â‰¤ O

log m
log log m

Â· d(x, y).
Since Ï•n(x) = 1 for at least M âˆ’ 1 values of n, S(x) =
P
nâˆˆZ Ï•n(x) â‰¥ M âˆ’ 1 â‰¥ M
2 . Hence,
arguing as in (10) we get that
X
nâˆˆZ
5n
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµ(Ï‰)
â‰¤
2
M
X
nâˆˆZ
5n
Z
â„¦n
X
iâˆˆI
Ï•n(x)1Î“i
n(Ï‰)(x) âˆ’ Ï•n(y)1Î“i
n(Ï‰)(y) dÂµn(Ï‰) +
4
M2
X
nâˆˆZ
5n
Ï•n(y)
!
|S(x) âˆ’ S(y)|. (21)
Let j be the maximal integer for which Ï•j(y) > 0. Then 5j â‰¤ 5M+5d(y, X) and
X
nâˆˆZ
5n
Ï•n(y) â‰¤
X
nâ‰¤j
5n
â‰¤ 5j+1
â‰¤ 5M+6
d(y, X).
Analogously,
P
nâˆˆZ 5nÏ•n(x) â‰¤ 5M+6d(x, X). Since in |S(x) âˆ’ S(y)| there are at most 4M
non-zero summands, each of which is bounded by 2, we get the following estimate:
X
nâˆˆZ
5n
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµ(Ï‰) â‰¤
4
M
X
n: {x,y}âˆ©supp(Ï•n)6=âˆ…
5n
+
5M+9d(y, X)
M
â‰¤
5M+7
M
[d(x, X) + d(y, X)] +
5M+9d(y, X)
M
â‰¤
5M+10
2M
[d(y, X) + d(x, y)].
Corollary 4.4. If d(y, X) â‰¤ d(x, y) then:
X
nâˆˆZ
5n
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµ(Ï‰) â‰¤
5M+10
M
d(x, y).
We now deal with the case d(x, X) â‰¥ d(y, X) > d(x, y). The reasoning above shows that
21
the estimate (21) can be written as
X
nâˆˆZ
5n
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµ(Ï‰)
â‰¤
2
M
X
nâˆˆZ
5n
Z
â„¦n
X
iâˆˆI
Ï•n(x)1Î“i
n(Ï‰)(x) âˆ’ Ï•n(y)1Î“i
n(Ï‰)(y) dÂµn(Ï‰) +
5M+7
M2
Â· d(x, X) Â· |S(x) âˆ’ S(y)|. (22)
For the sake of simplicity, denote
Ex,y = {n âˆˆ Z : Ï•n(x) = Ï•n(y) = 1} and Fx,y = {n âˆˆ Z : Ï•n(x) + Ï•n(y) > 0} \ Ex,y.
By the definition of Ï•n, if n âˆˆ Fx,y then 5n must be in
[53
d(x, X), 5M+5
d(x, X)] âˆª [53
d(y, X), 5M+5
d(y, X)]
but not in
[54
d(x, X), 5M+4
d(x, X)] âˆ© [54
d(y, X), 5M+4
d(y, X)].
Since d(y, X) â‰¤ d(x, X) â‰¤ d(y, X) + d(x, y) â‰¤ 2d(y, Y ), it follows that n can take at most 10
values. We have shown that |Fx,y| â‰¤ 10. Hence, using the fact that Ï• is 5-Lipschitz,
|S(x) âˆ’ S(y)| â‰¤
X
nâˆˆFx,y
|Ï•n(x) âˆ’ Ï•n(y)| â‰¤ 10
d(x, y)
5nâˆ’Mâˆ’5
â‰¤ 5M+7
Â·
d(x, y)
d(x, X)
. (23)
Fix n âˆˆ Z and Ï‰ âˆˆ â„¦n and argue as in (19) to get that
X
iâˆˆI
Ï•n(x)1Î“i
n(Ï‰)(x) âˆ’ Ï•n(y)1Î“i
n(Ï‰)(y) â‰¤
d(x, y)
5nâˆ’Mâˆ’5
Â· 1Fx,y (n) +
X
iâˆˆI
1Î“i
n(Ï‰)(x) âˆ’ 1Î“i
n(Ï‰)(y) .
Since for n âˆˆ Ex,y âˆª Fx,y, d(x, X) â‰¤ 5nâˆ’2, we may use (20) to get that
Z
â„¦n
X
iâˆˆI
Ï•n(x)1Î“i
n(Ï‰)(x) âˆ’ Ï•n(y)1Î“i
n(Ï‰)(y) dÂµn(Ï‰)
â‰¤
d(x, y)
5nâˆ’Mâˆ’5
Â· 1Fx,y (n) +
2d(x, y)
5n

1 + log

|BX(x, 5n+1)|
|BX(x, 5n)|

(24)
Let j, J be the minimal and maximal integers i, respectively, for which Ï•i(x) + Ï•i(y) > 0.
Observe that in this case J âˆ’ j â‰¤ 4M and 5jâˆ’3 â‰¥ d(x,X)
2 . Hence
X
nâˆˆZ
5n
Z
â„¦n
X
iâˆˆI
Ï•n(x)1Î“i
n(Ï‰)(x) âˆ’ Ï•n(y)1Î“i
n(Ï‰)(y) dÂµn(Ï‰)
â‰¤
X
nâˆˆFx,y
5n
Â·
d(x, y)
5nâˆ’Mâˆ’5
+
X
nâˆˆEx,yâˆªFx,y
5n
Z
â„¦n
X
iâˆˆI
1Î“i
n(Ï‰)(x) âˆ’ 1Î“i
n(Ï‰)(y) dÂµn
â‰¤ 10 Â· 5M+5
d(x, y) +
J
X
n=j
2d(x, y)

1 + log

|BX(x, 5n+1)|
|BX(x, 5n)|

â‰¤ 5M+7
d(x, y) + 2d(x, y)

4M + log

|BX(x, 5J+1)|
|BX(x, 5j)|

â‰¤ 5M+7
+ 8M + 2 log m

Â· d(x, y), (25)
Plugging (23) and (25) into (22) we arrive at the following corollary:
22
Corollary 4.5. If d(x, y) < d(y, X) then
X
nâˆˆZ
5n
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµ(Ï‰) â‰¤ O

52M
M2
+
log m
M

Â· d(x, y).
Using Corollary 4.4 and Corollary 4.5 with M â‰ˆ log log m yields the required result.
5 Extension theorems
The following theorem is a direct consequence of the results of Section 2, Section 3 and Sec-
tion 4.
Theorem 5.1. There exists a universal constant C > 0 such that
1. For every metric space X, ae(X) â‰¤ C log Î»(X).
2. For every r > 0 and any Kr-excluded metric space X, ae(X) â‰¤ C Â· r2.
3. Let M be a two dimensional Riemannian manifold with genus g and X âŠ† M. Then
ae(X) â‰¤ C Â· (g + 1).
4. If X is an n-point metric space then ae(X) â‰¤ C log n
log log n .
5. For every integer d and every Banach space Z, e(â„“d
2, Z) â‰¤ C
âˆš
d.
We also have the following extension result for neighborhoods of subsets of negatively
curved manifolds.
Proposition 5.2. Fix r > 0 and let M be an n-dimensional Riemannian manifold satisfying
Ricci(g) â‰¥ âˆ’(nâˆ’1)rg, where g is the Riemannian metric on M. Then for any subset X âŠ† M,
any metric space Y âŠ‡ X such that X is âˆ†-dense in Y , and any Banach space Z, e(X, Y, Z) â‰¤
C Â· n

1 +
âˆš
râˆ†

. Here C is a universal constant.
Proof. Observe that in this case in the proof of 4.1 we only require the existence of 2n-
padded decomposition with 2n â‰¤ âˆ†. Hence the required result follows from an application of
Corollary 3.13 and Lemma 3.8.
Let us recall that for a family of finite graphs F, we claim that ae(hFi) â‰¤ KF if and only
if hFi does not contain all finite metrics. We now give the simple proof which is based on a
deep result of Robertson and Seymour [32].
Proof of Corollary 1.8. For a family of graphs F, let mc(F) denote its closure under taking
minors, i.e. the maximal minor-closed family containing F. Robertson and Seymour proved
that if mc(F) is non-trivial, i.e. does not contain all finite graphs, then there is some finite
list of graphs H1, Â· Â· Â· , Hk such that G âˆˆ mc(F) if and only if G does not contain any Hi as a
minor.
Observe that contraction/deletion of an edge corresponds to weighting by 0/âˆ, respec-
tively. It follows that hFi = hmc(F)i, thus if hFi does not contain all finite metrics, then
certainly mc(F) does not contain all finite graphs, hence if X âˆˆ hFi, it must be supported
on some graph G which excludes a Kr minor with r = maxi |Hi|, and in this case part (2) of
Theorem 5.1 applies.
23
We are now in position to prove Theorem 1.12 which was stated in the introduction.
Proof of Theorem 1.12. We begin with the case p = 2. Let X be an n-point subset of L2,
Z a Banach space and f : X â†’ Z a Lipschitz function. Let H be the linear span of
X and let Q be the orthogonal projection from L2 onto H. By the proof of the Johnson-
Lindenstrauss dimension reduction lemma [17] there is a probability space (â„¦, P) such that
for every Ï‰ âˆˆ â„¦ there is a rank d linear operator TÏ‰ : H â†’ H such that for every x âˆˆ H,
P kTÏ‰(x)k2 âˆ’ kxk2 â‰¥ 1
2

â‰¤ 2eâˆ’cd, where c is a universal constant. We can therefore find
for d â‰ˆ 4
c log n a subset A âŠ‚ â„¦ with P(A) â‰¥ 1
2 such that for every x, y âˆˆ X and Ï‰ âˆˆ A,
kTÏ‰(x)âˆ’TÏ‰(y)k2 â‰¥ 1
2 kxâˆ’yk2. The function gÏ‰ = f â—¦(TÏ‰|TÏ‰(X))âˆ’1 is Lipschitz on TÏ‰(X) with
constant 2kfkLip. By Theorem 5.1, there is a function gÌƒÏ‰ : TÏ‰(H) â†’ Z such that gÌƒÏ‰|TÏ‰(X) = gÏ‰
and kgÌƒÏ‰kLip â‰¤ 4C
âˆš
c
âˆš
log n Â· kfkLip. Define Ëœ
f : L2 â†’ Z by:
Ëœ
f(x) =
1
P(A)
Z
A
gÌƒÏ‰(TÏ‰Qx)dP(Ï‰).
Clearly Ëœ
f is an extension of f and since P(A) â‰¥ 1
2, for every x, y âˆˆ Lp,
k Ëœ
f(x) âˆ’ Ëœ
f(y)kZ â‰¤
1
P(A)
Z
A
kgÌƒÏ‰(TÏ‰Qx) âˆ’ gÌƒÏ‰(TÏ‰Qy)kZ dP(Ï‰)
â‰¤ O
p
log n

kfkLip Â·
Z
â„¦
kTÏ‰(Qx âˆ’ Qy)k2 dP(Ï‰)
= O
p
log n

kfkLip Â· kx âˆ’ yk2,
where we have used the fact that the concentration inequality for kTÏ‰zk2, z âˆˆ H, implies that
R
â„¦ kTÏ‰zkdP(Ï‰) = O(kzk2).
We pass to general 1 < p â‰¤ 2 via a method due to Marcus and Pisier [27]. In [27] they
show that for every 0 < p â‰¤ 2 there is a probability space (â„¦â€², Pâ€²) such that for every Ï‰ âˆˆ â„¦â€²
there is a linear operator SÏ‰ : Lp â†’ L2 such that for every x âˆˆ Lp \ {0} the random variable
X = kSÏ‰(x)k2
kxkp
satisfies for every a âˆˆ R, Eeâˆ’aX2
= eâˆ’ap/2
. Let T be an n-point subset of Lp,
Z a Banach space and f : T â†’ Z a Lipschitz function. A standard application of Markovâ€™s
inequality shows that there is constant cp and a subset Aâ€² âŠ‚ â„¦ with Pâ€²(Aâ€²) â‰¥ 1
2 such that for
every x, y âˆˆ X and Ï‰ âˆˆ Aâ€²,
kx âˆ’ ykp â‰¤ cp(log n)
1
p
âˆ’ 1
2 kSÏ‰(x) âˆ’ SÏ‰(y)k2.
For every Ï‰ âˆˆ Aâ€² the function gÏ‰ = f â—¦ (SÏ‰|SÏ‰(X))âˆ’1 is O

(log n)
1
p
âˆ’ 1
2

kfkLip Lipschitz. By
the above reasoning for the case p = 2, gÏ‰ can be extended to a function gÌƒÏ‰ defined on all of
L2 which is Lipschitz with constant O (log n)1/p

kfkLip. Define Ëœ
f : Lp â†’ L2 by:
Ëœ
f(x) =
1
Pâ€²(Aâ€²)
Z
Aâ€²
gÌƒÏ‰(SÏ‰(x)) dPâ€²
(Ï‰).
Clearly Ëœ
f is an extension of f and since Pâ€²(Aâ€²) â‰¥ 1
2 , for every x, y âˆˆ Lp,
k Ëœ
f(x) âˆ’ Ëœ
f(y)kZ â‰¤
1
Pâ€²(Aâ€²)
Z
Aâ€²
kgÌƒÏ‰(SÏ‰(x)) âˆ’ gÌƒÏ‰(SÏ‰(y))kZ dPâ€²
(Ï‰)
â‰¤ O

(log n)1/p

kfkLip Â·
Z
â„¦
kSÏ‰(x âˆ’ y)k2 dPâ€²
(Ï‰)
= O

(log n)1/p

kfkLip Â· kx âˆ’ ykp Â· EX,
24
and we conclude since for p > 1, EX = Cp < âˆ.
Remark 5.3. As stated in the introduction, it was asked in [17] and [18] whether for every
Banach space X, supn en(L2, X) < âˆ. This is false since in [30] it was shown that for
2 < p < âˆ, e(L2, Lp) = âˆ. We end by reproducing the argument from [30] (which is based on
ideas from [25]) in such a way that we get quantitative lower bounds on en(L2, â„“p), 2 < p < âˆ.
Since we are essentially repeating the proof from [30], our argument will be somewhat sketchy.
We claim that, for every integer n and every 2 < p < âˆ,
en(L2, Lp) â‰¥ â„¦
"
log n
log log n
pâˆ’2
p2
#
.
Proof (sketch). Fix an integer m and set Îµ = 1
n1/2âˆ’1/p . Let N be an Îµ net in the unit ball of
â„“2m
2 , denoted B. By standard (crude) volume estimates |N| â‰¤ m2m. Consider the Mazur map
f : â„“2m
2 â†’ â„“2m
p given by f(x)i = |xi|2/psign(xi). From the numerical inequality |a2/psign(a) âˆ’
b2/psign(b)| â‰¤ 21âˆ’2/p|aâˆ’b|2/p it follows that for every x, y âˆˆ â„“2m
2 , kf(x)âˆ’f(y)kp â‰¤ 2kxâˆ’yk
2/p
2 .
Since the elements of N are Îµ separated, the restriction of f to N is Lipschitz with constant
2/Îµ1âˆ’2/p = 2m(1âˆ’2/p)(1/2âˆ’1/p). Assume that it is possible to extend f|N to a function g : â„“2m
2 â†’
â„“2m
p which is K Lipschitz. Since N is Îµ-dense in B, for every x âˆˆ B, kf(x)âˆ’g(x)kp â‰¤ KÎµ+2Îµ2/p.
As in [30], by averaging g over all permutations and sign changes we arrive at a function h
satisfying h(a1A) = b1A for all scalars a and A âŠ‚ {1, . . . , 2m}, where b depends only on the
a and the cardinality of A. Additionally, h is K Lipschitz, and since f is invariant under
permutations and changes of sign of the coordinates, for every x âˆˆ B, kh(x) âˆ’ f(x)kp â‰¤ KÎµ +
2Îµ2/p. Setting xk = 1
âˆš
2m
1{k,...,k+mâˆ’1} it follows that kh(xm+1) âˆ’ h(x1)kp
p =
Pm
k=1 kh(xk+1) âˆ’
h(xk)kp
p, and since h is K-Lipschitz we get the estimate kh(xm+1) âˆ’ h(x1)kp â‰¤ K
m1/2âˆ’1/p = KÎµ.
On the other hand,
2KÎµ + 2Îµ2/p
â‰¥ kh(xm+1) âˆ’ f(xm+1)kp + kh(x1) âˆ’ f(x1)kp
â‰¥ kf(xm+1) âˆ’ f(x1)kp âˆ’ kh(xn+1) âˆ’ h(x1)kp â‰¥ 1 âˆ’ KÎµ.
This implies that the ratio between K and the Lipschitz constant of f is at least K/(2Îµ2/pâˆ’1) =
â„¦(Îµâˆ’2/p) = â„¦
n
[(log n)/(log log n)](2âˆ’p)/p2
o
, where n = m2m â‰¥ |N|.
6 Appendix: Passing to arbitrary barycentric target spaces
In order to deal with barycentric metric spaces it is convenient to introduce the following
variant of the notion of a gentle partition of unity. Let (Y, d) be a metric space, X a subspace
of Y and (â„¦, F, Âµ) a measure space. Given K, L > 0 we shall say that a function Î¨ : â„¦ Ã— Y â†’
[0, âˆ) is a (K, L)-gentle partition of unity with respect to X if the following conditions hold
true:
1. For every x âˆˆ Y \ X the function Ï‰ 7â†’ Î¨(Ï‰, x) is measurable and
R
â„¦ Î¨(Ï‰, x)dÂµ(Ï‰) = 1.
2. There exists a Borel measurable function Î³ : â„¦ â†’ X such that for every x, y âˆˆ Y ,
diam({x, y} âˆª {Î³(Ï‰) : Î¨(Ï‰, x) + Î¨(Ï‰, y) > 0}) â‰¤ K Â· [d(x, y) + max{d(x, X), d(y, X)}],
25
3. For every x, y âˆˆ Y , x 6= y,
Z
â„¦
|Î¨(Ï‰, x) âˆ’ Î¨(Ï‰, y)| dÂµ(Ï‰) â‰¤ L Â·
d(x, y)
d(x, y) + max{d(x, X), d(y, X)}
.
The following lemma is a variant of Lemma 2.1
Lemma 6.1. Let (Y, dY ) be a metric space and X a subspace of Y . Fix K, L > 0 and assume
that Y admits a (K, L)-gentle partition of unity Î¨ : â„¦ Ã— Y â†’ [0, âˆ) with respect to X. Let
(Z, dZ) be a complete barycentric metric space and Î² > Î²(Z). Then every Lipschitz function
f : X â†’ Z can be extended to a function Ëœ
f : Y â†’ Z such that k Ëœ
fkLip â‰¤ Î² max{KL, 2K + 2}.
Proof. As in the proof of Lemma 2.1, we may assume that X is closed. Let c : Mbounded
Z â†’ Z
be a mapping satisfying the conditions of Definition 1.14 and let Î³ : â„¦ â†’ X be as in condition 2
above.
For every x âˆˆ Y \ X define Î½x âˆˆ Mbounded
Z by
Î½x(A) =
Z
Î³âˆ’1(fâˆ’1(A))
Î¨(Ï‰, x)dÂµ(Ï‰).
In other words, Î½x is the pullback of the probability measure Î¨(Â·, x)dÂµ under the mapping
f â—¦ Î³. For x âˆˆ X we define Î½x = Î´f(x). Finally, for x âˆˆ Y set Ëœ
f(x) = c(Î½x). Clearly Ëœ
f is an
extension of f.
If x, y âˆˆ Y then by (1),
dZ( Ëœ
f(x), Ëœ
f(y)) â‰¤ Î² Â· diam(supp(Î½x + Î½y)) Â· kÎ½x âˆ’ Î½ykTV .
Now, if x, y âˆˆ Y \ X then
diam(supp(Î½x + Î½y)) â‰¤ kfkLip Â· diam({Î³(Ï‰) : Î¨(Ï‰, x) + Î¨(Ï‰, y) > 0})
â‰¤ kfkLip Â· K Â· [d(x, y) + max{d(x, X), d(y, X)}].
and
kÎ½x âˆ’ Î½ykTV â‰¤
Z
â„¦
|Î¨(Ï‰, x) âˆ’ Î¨(Ï‰, y)|dÂµ(y) â‰¤ L Â·
d(x, y)
d(x, y) + max{d(x, X), d(y, X)}
.
This implies that for x, y âˆˆ Y \ X,
dZ( Ëœ
f(x), Ëœ
f(y)) â‰¤ Î²KL Â· kfkLip.
It remains to deal with the case x âˆˆ X and y âˆˆ Y \X. In this case set Î“ = {Î³(Ï‰) : Î¨(Ï‰, y) > 0}.
Condition 2 (applied with x = y) implies that diam({y} âˆª Î“) â‰¤ Kd(y, X). In particular,
d(x, Î“) â‰¤ d(x, y) + d(y, Î“) â‰¤ d(x, y) + Kd(y, X) â‰¤ (K + 1)d(x, y). It follows that
diam(supp(Î½x + Î½y)) â‰¤ kfkLip Â· diam({x, y} âˆª Î“) â‰¤ kfkLip(K + 1)d(x, y).
On the other hand, kÎ½x âˆ’ Î½ykTV â‰¤ 2, and the required result follows.
The following theorem is a simple variant of Theorem 4.1, adapted to the case of (K, L)
gentle partitions of unity.
26
Theorem 6.2. For every Îµ, Î´ âˆˆ (0, 1), every metric space (Y, d) and every subspace X âŠ† Y
the following assertions hold true:
1. If for every n âˆˆ Z, Y admits an (Îµ, Î´)-thick 2n-bounded stochastic decomposition with
respect to X, then Y also admits a 36
Îµ , 680
Î´

-gentle partition of unity with respect to X.
2. If for every n âˆˆ Z, Y admits an (Îµ, Î´)-padded 2n-bounded stochastic decomposition with
respect to X, then Y also admits a 36
Îµ , 680
Î´

-gentle partition of unity with respect to X.
3. If for every n âˆˆ Z, Y admits an (Îµ, Î´)-separating 2n-bounded stochastic decomposition
with respect to X, then Y also admits a 36
Îµ , 160 1 + Îµ
Î´

-gentle partition of unity with
respect to X.
Proof. Since the proof is a straightforward modification of the proof of Theorem 4.1, we will
only sketch the necessary changes. As before, for every n âˆˆ Z let (â„¦n, Âµn, {Î“i
n(Â·), Î³i
n(Â·)}iâˆˆI)
be a 2n-bounded stochastic decomposition of Y with respect to X. Let Ï• : R â†’ R+ be any
2-Lipschitz map with supp(Ï•) âŠ‚ [1
2, 4] and Ï• â‰¡ 1 on [1, 2]. Define Ï•n(x) = Ï•

d(x,X)
Îµ2nâˆ’3

and let
(â„¦, Âµ) be the disjoint union of {I Ã— â„¦n}nâˆˆZ (where the measure on I is the counting measure).
The partition of unity which we construct has the following form: For every n âˆˆ Z, Ï‰ âˆˆ â„¦n,
i âˆˆ I and x âˆˆ Y denote:
Î¨(i, Ï‰, x) =
1
S(x)
Î¸n
Ï‰(x)Ï•n(x)1Î“i
n(Ï‰)(x), (26)
where for every n âˆˆ Z and x âˆˆ Y the function Ï‰ 7â†’ Î¸n
Ï‰(x) âˆˆ [0, âˆ) is Âµn-integrable and
S(x) =
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
Î¸n
Ï‰(x)Ï•n(x)1Î“i
n(Ï‰)(x) dÂµn(Ï‰) =
X
nâˆˆZ
Ï•n(x)
Z
â„¦n
Î¸n
Ï‰(x) dÂµn(Ï‰).
Additionally define Î³(i, Ï‰) = Î³i
n(Ï‰). Fix n âˆˆ Z, Ï‰ âˆˆ â„¦n, i âˆˆ I and assume that x âˆˆ Y is such
that Î¨(i, Ï‰, x) > 0. Then x âˆˆ Î“i
n(Ï‰) and d(x, X) âˆˆ

Îµ2nâˆ’4, Îµ2nâˆ’1

. Since d(Î³i
n(Ï‰), Î“i
n(Ï‰)) <
2d(X, Î“i
n(Ï‰)) â‰¤ 2d(x, X) there is xâ€² âˆˆ Î“i
n(Ï‰) for which d(Î³i
n(Ï‰), xâ€²) < 2d(x, X). Hence,
d(Î³i
n(Ï‰), x) â‰¤ 2d(x, X) + diam(Î“i
n(Ï‰)) â‰¤ 2d(x, X) + 2n
â‰¤

2 +
16
Îµ

d(x, X) â‰¤
18
Îµ
d(x, X).
Similarly, if m âˆˆ Z, Ï‰â€² âˆˆ â„¦m, j âˆˆ I are such that Î¨(j, Ï‰â€², y) > 0 for some y âˆˆ Y then
d(Î³j
m(Ï‰â€²
), y) â‰¤
18
Îµ
d(y, X).
It follows that
d(Î³i
n(Ï‰), Î³j
m(Ï‰â€²
)) â‰¤ d(x, y) +
18
Îµ
d(x, X) +
18
Îµ
d(y, X) â‰¤
36
Îµ
(d(x, y) + max{d(x, X), d(y, X)}) .
Hence,
diam ({x, y} âˆª {Î³(i, Ï‰) : Î¨(i, Ï‰, x) + Î¨(i, Ï‰, y) > 0}) â‰¤
36
Îµ
(d(x, y) + max{d(x, X), d(y, X)}) .
It is therefore enough to show that:
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµn(Ï‰) â‰¤
680
Î´
Â·
d(x, y)
d(x, y) + max{d(x, X), d(y, X)}
,
27
when the decompositions are either (Îµ, Î´)-padded or (Îµ, Î´)-thick and
X
nâˆˆZ
X
iâˆˆI
Z
â„¦n
|Î¨(i, Ï‰, x) âˆ’ Î¨(i, Ï‰, y)| dÂµn(Ï‰) â‰¤ 160

1 +
Îµ
Î´

Â·
d(x, y)
d(x, y) + max{d(x, X), d(y, X)}
,
when the decompositions are (Îµ, Î´)-separating. From here on the proof is exactly as in the
proof of Theorem 4.1.
Lemma 6.1, Theorem 6.2 and the results of Section 3.2 imply the extension results stated
in the introduction, in the case when the target space Z is a complete barycentric metric
space. The above argument does not yield a similar generalization of Theorem 1.10, since
the construction of Theorem 4.3 does not imply a satisfactory bound as in condition 2 in the
definition of a (K, L) gentle partition of unity. An inspection of the proof of Lemma 2.1 shows
that we have only used the following property of the Banach space Z: There exists a map
c : Mbounded
Z â†’ Z such that c(Î´z) = z for every z âˆˆ Z and for every Âµ, Î½ âˆˆ Mbounded
Z and
p âˆˆ Z,
dZ(c(Âµ), c(Î½)) â‰¤ C
Z
Z
d(p, z)d|Âµ âˆ’ Î½|(z), (27)
where C is a constant (depending on Z). This inequality holds true in Banach spaces due to
the identity Z
Z
zdÂµ(z) âˆ’
Z
Z
zdÎ½(z) =
Z
Z
(z âˆ’ p)d(Âµ âˆ’ Î½)(z).
All the results presented in this paper extend to target spaces satisfying (27) (using K-gentle
partitions of unity), and it would be of interest to find a wider class of spaces with this property.
References
[1] K. Ball. Markov chains, Riesz transforms and Lipschitz maps. Geom. Funct. Anal.,
2:137â€“172, 1992.
[2] Y. Bartal. Probabilistic approximation of metric spaces and its algorithmic applications.
In Proceedings of the 37th Annual Symposium Foundations of Computer Science, 1998.
[3] Y. Benyamini and J. Lindenstrauss. Geometric nonlinear functional analysis. Vol. 1,
volume 48 of American Mathematical Society Colloquium Publications. American Math-
ematical Society, Providence, RI, 2000.
[4] Y. Brudnyi and P. Shvartsman. Stability of the Lipschitz extension property under metric
transforms. Geom. Funct. Anal., 12(1):73â€“79, 2002.
[5] S. Buyalo and V. Schroeder. Extension of Lipschitz maps into 3-manifolds. Asian J.
Math., 5(4):685â€“704, 2001.
[6] G. Calinescu, H. Karloff, and Y. Rabani. Approximation algorithms for the 0-extension
problem. In Proceedings of the 12th Annual ACM-SIAM Symposium on Discrete Algo-
rithms. ACM, 2001.
28
[7] M. Charikar, C. Chekuri, A. Goel, S. Guha, and S. A. Plotkin. Approximating a finite
metric by a small number of tree metrics. In Proceedings of the 39th Annual Symposium
on Foundations of Computer Science, 1998.
[8] J. Fakcharoenphol, C. Harrelson, S. Rao, and K. Talwar. An improved approximation
algorithm for the 0-extension problem. In Proceedings of the 14th Annual ACM-SIAM
Symposium on Discrete Algorithms. ACM, 2003.
[9] J. Fakcharoenphol, S. Rao, and K. Talwar. A tight bound on approximating arbitrary
metrics by tree metrics. In 35th Annual ACM Symposium on Theory of Computing. ACM,
2003.
[10] J. Fakcharoenphol and K. Talwar. An improved decomposition theorem for graphs exclud-
ing a fixed minor. In 7th International Workshop on Randomization and Approximation
Techniques in Computer Science. Springer-Verlag, 2003.
[11] M. Gromov. Asymptotic invariants of infinite groups. In Geometric group theory, Vol.
2 (Sussex, 1991), volume 182 of London Math. Soc. Lecture Note Ser., pages 1â€“295.
Cambridge Univ. Press, Cambridge, 1993.
[12] M. Gromov. Metric structures for Riemannian and non-Riemannian spaces. BirkhaÌˆuser,
Boston, 1999.
[13] M. Gromov. Random walk in random groups. Geom. Funct. Anal., 13:73â€“146, 2003.
[14] A. Gutpa, R. Krauthgamer, and J. R. Lee. Bounded geometries, fractals, and low-
distortion embeddings. In Proceedings of the 44th Annual Symposium on Foundations
of Computer Science, 2003.
[15] J. Heinonen. Lectures on analysis on metric spaces. Universitext. Springer-Verlag, New
York, 2001.
[16] F. John. Extremum problems with inequlities as subsidiary conditions. Courant Anniver-
sary Volume. Interscience, New York, pages 187â€“204â€“245, 1948.
[17] W. B. Johnson and J. Lindenstrauss. Extensions of Lipschitz mappings into a Hilbert
space. In Conference in modern analysis and probability (New Haven, Conn., 1982),
volume 26 of Contemp. Math., pages 189â€“206. Amer. Math. Soc., Providence, RI, 1984.
[18] W. B. Johnson, J. Lindenstrauss, and G. Schechtman. Extensions of Lipschitz maps into
Banach spaces. Israel J. Math., 54(2):129â€“138, 1986.
[19] M. D. Kirszbraun. UÌˆber die zusammenziehenden und Lipschitzchen Transformationen.
Fund. Math., (22):77â€“108, 1934.
[20] P. Klein, S. A. Plotkin, and S. Rao. Excluded minors, network decomposition, and
multicommodity flow. In 25th Annual ACM Symposium on Theory of Computing, pages
682â€“690, May 1993.
[21] K. Kuratowski and C. Ryll-Nardzewski. A general theorem on selectors. Bull. Acad.
Polon. Sci. SeÌr. Sci. Math. Astron. Phys., 13:397â€“403, 1965.
29
[22] U. Lang. Extendability of large-scale Lipschitz maps. Trans. Amer. Math. Soc.,
351(10):3975â€“3988, 1999.
[23] U. Lang, B. PavlovicÌ, and V. Schroeder. Extensions of Lipschitz maps into Hadamard
spaces. Geom. Funct. Anal., 10(6):1527â€“1553, 2000.
[24] J. R. Lee and A. Naor. Absolute Lipschitz extendability. C. R. Acad. Sci. Paris, to
appear, 2003.
[25] J. Lindenstrauss. On nonlinear projections in Banach spaces. Michigan Math. J., 11:263â€“
287, 1964.
[26] N. Linial and M. Saks. Low diameter graph decompositions. Combinatorica, 13(4):441â€“
454, 1993.
[27] M. B. Marcus and G. Pisier. Characterizations of almost surely continuous p-stable
random Fourier series and strongly stationary processes. Acta Math., 152(3-4):245â€“301,
1984.
[28] J. MatousÌŒek. Extension of Lipschitz mappings on metric trees. Comment. Math. Univ.
Carolin., 31(1):99â€“104, 1990.
[29] B. Mohar and C. Thomassen. Graphs on surfaces. Johns Hopkins Studies in the Mathe-
matical Sciences. Johns Hopkins University Press, Baltimore, MD, 2001.
[30] A. Naor. A phase transition phenomenon between the isometric and isomorphic extension
problems for HoÌˆlder functions between Lp spaces. Mathematika, 48:253â€“271, 2001.
[31] S. Rao. Small distortion and volume preserving embeddings for planar and Euclidean
metrics. In Proceedings of the 15th Annual Symposium on Computational Geometry,
pages 300â€“306. ACM, 1999.
[32] N. Robertson and P. D. Seymour. Graph minors. VIII. A Kuratowski theorem for general
surfaces. J. Combin. Theory Ser. B, 48(2):255â€“288, 1990.
[33] L. Silberman. Addendum to â€Random walk in random groupsâ€ by M. Gromov. Geom.
Funct. Anal., 13:147â€“177, 2003.
[34] I. G. Tsarâ€²kov. Extension of Hilbert-valued Lipschitz mappings. Vestnik Moskov. Univ.
Ser. I Mat. Mekh., (6):9â€“16, 72, 1999.
[35] J. H. Wells and L. R. Williams. Embeddings and extensions in analysis. Springer-Verlag,
New York, 1975. Ergebnisse der Mathematik und ihrer Grenzgebiete, Band 84.
[36] H. Whitney. Analytic extension of differentiable functions defined in closed sets. Trans.
Amer. Math. Soc., 36:63â€“89, 1934.
[37] H. Whitney. Differentiable functions defined in closed sets I. Trans. Amer. Math. Soc.,
36:369â€“387, 1934.
30
