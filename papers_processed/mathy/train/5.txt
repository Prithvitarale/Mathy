arXiv:1209.2434v1[stat.ML]11Sep2012QueryComplexityofDerivative-FreeOptimizationKevinG.JamiesonUniversityofWisconsinMadison,WI53706,USAkgjamieson@wisc.eduRobertD.NowakUniversityofWisconsinMadison,WI53706,USAnowak@engr.wisc.eduBenjaminRechtUniversityofWisconsinMadison,WI53706,USAbrecht@cs.wisc.eduAbstractThispaperprovideslowerboundsontheconvergencerateofDerivativeFreeOp-timization(DFO)withnoisyfunctionevaluations,exposingafundamentalandunavoidablegapbetweentheperformanceofalgorithmswithaccesstogradientsandthosewithaccesstoonlyfunctionevaluations.However,therearesituationsinwhichDFOisunavoidable,andforsuchsituationsweproposeanewDFOal-gorithmthatisprovedtobenearoptimalfortheclassofstronglyconvexobjectivefunctions.AdistinctivefeatureofthealgorithmisthatitusesonlyBoolean-valued2ProblemformulationandbackgroundWenowformalizethenotationandconventionsforouranalysisofDFO.AfunctionfisstronglyconvexwithconstantτonaconvexsetB⊂RdifthereexistsaconstantτWhilethereremainsmanyopenproblemsinstochasticDFO(seeSection6),ratesofconvergencewithastochasticgradientoraclearewellknownandwerefirstlowerboundedbyNemirovskiandYudin[15].Theseclassicresultswererecentlytightenedtoshowadependenceonthedimensionoftheproblem[17].Andthentightenedagaintoshowabetterdependenceonthenoise[11]whichmatchestheupperboundachievedbystochasticgradientdescent[9].Theaimofthisworkistostartfillingintheknowledgefunctionevaluationoracles(e.g.additiveGaussiannoise),yieldinganupperboundofn3σ2/T1/2ignoringconstantsandlogfactors.ThismatchestherateofconvergenceasafunctionofTandσ2,butofVbyω0,ω1,...,ωM.Nextwestatesomeelementaryboundsonthefunctionsthatwillbeusedinouranalysis.Lemma1.Forǫ>0definethesetB⊂Rntobetheℓ∞ballofradiusǫanddefinethefunctionsonB:fi(x):=τ2||x−ǫωi||2,fori=0,...,M,ωi∈ApplyingTheorem4wehaveinfbfsupf∈FP(kxbf−xfk≥sT)≥infbfmaxi∈{0,...,M}P(kxbf−xik≥sT)=bythethirdclaimofLemma1.WethenrepeatthesameprocedureasinSection4.1toattaininfbfsupf∈FEhf(xbf)−f(xf)i≥17132nσ2log(2)64T12.5UpperboundsThealgorithmthatachievestheupperboundusingapairwisecomparisonoracleisacombinationofstandardtechniquesandmethodsfromtheconvexoptimizationandstatisticallearningliterature.ThealgorithmisexplainedinfulldetailinAppendixB,andissummarizedasfollows.Ateachiterationthealgorithmpicksacoordinateuniformlyatrandomfromthenpossibledimensionsandthenperformsanapproximatelinesearch.ByexploitingthefactthatthefunctionisstronglyTheorem5.Letf∈Fτ,L,BwithB=Rn.Foranyη>0assumethelinesearchreturnsanαkthatiswithinηoftheoptimalafteratmostTℓ(η)queriesfromthepairwisecomparisonoracle.IfxKisanestimateofx∗=argminxf(x)afterrequestingnomorethanKpairwisecomparisons,thensupfE[f(xK)−f(x∗)]≤4nL2η2τboundforanyǫweseethatthisisequivalenttoarateofOnlog(n/δ)nT12(κ−1)forκ>1andOexpn−cqTnlog(n/δ)oforReferences[1]T.EitrichandB.Lang.Efficientoptimizationofsupportvectormachinelearningparametersforunbalanceddatasets.Journalofcomputationalandappliedmathematics,196(2):425–436,2006.[2]R.OeuvrayandM.Bierlaire.Anewderivative-freealgorithmforthemedicalimageregistra-tionproblem.InternationalJournalofModellingandSimulation,27(2):115–124,2007.[3]A.R.Conn,K.Scheinberg,andL.N.Vicente.Introductiontoderivative-freeoptimization,volume8.SocietyforIndustrialMathematics,2009.[4]WarrenB.PowellandIlyaO.Ryzhov.OptimalLearning.JohnWileyandSons,2012.[5]ABoundson(κ,µ,δ0)forsomedistributionsInthissectionwerelatethefunctionevaluationoracletothefunctioncomparisonoracleforsomecommondistributions.Thatis,ifEf(x)=f(x)+wforsomerandomvariablew,welowerboundtheprobabilityη(y,x):=P(sign{Ef(y)−Ef(x)}=sign{f(y)−f(x)})intermsoftheparameterizationof(1).Lemma3.LetwbeaGaussianrandomvariablewithmeanzeroandvarianceσ2.Thenη(y,x)≥12+minn1√2πe,1√4πσ2e|f(y)−f(x)|o.Proof.Noticethatη(y,x)=P(Z+|f(y)−f(x)|/√2σ2≥0)whereZisastandardnormal.TheresultfollowsbylowerboundingthedensityofZby1√2πe1{|Z|≤1}andintegratingwhere1{·}isequaltoonewhenitsargumentsaretrueandzerootherwise.Wesaywisa2-sidedgammadistributedrandomvariableifitsdensityisgivenbyβα2Γ(α)|x|α−1e−β|x|forx∈[−∞,∞]andα,β>0.Notethatthisdistributionisunimodalonlyforα∈(0,1]andisequaltoaLaplacedistributionforα=1.Thisdistributionhasvarianceσ2=α/β2.Lemma4.Letwbea2-sidedgammadistributedrandomvariablewithparametersα∈(0,1]andβ>0.Thenη(y,x)≥12+minn14α2Γ(α)2αe2α,(β/2e)2α4α2Γ(α)2|f(y)−f(x)|2αo.Proof.LetEf(y)=f(y)+wandEf(x)=f(x)+w′wherewandw′arei.i.d.2-sidedgammadistributedrandomvariables.Ifwelowerbounde−β|x|withe−α1{|x|≤α/β}andintegratewefindthatP(−t/2≤w≤0)≥minn12αΓ(α)αeα,(β/e)α2αΓ(α)(t/2)αo.Andbythesymmetryandindependenceofwandw′wehaveP(−t≤w−w′)≥12+P(−t/2≤w≤0)P(−t/2≤w≤0).Whiletheboundinthelemmaimmediatelyabovecanbeshowntobeloose,thesetwolemmasaresufficienttoshowthattheentirerangeofκ∈(1,2]ispossible.BUpperBounds-ExtendedThealgorithmthatachievestheupperboundusingapairwisecomparisonoracleisacombinationofafewstandardtechniquesandmethodspulledfromtheconvexoptimizationandstatisticallearningliterature.Thealgorithmcanbesummarizedasfollows.Ateachiterationthealgorithmpicksacoordinateuniformlyatrandomfromthenpossibledimensionsandthenperformsanapproximatelinesearch.ByexploitingthefactthatthefunctionisstronglyconvexwithLipschitzgradients,oneguaranteesusingstandardargumentsthattheapproximatelinesearchmakesasufficientdecreaseintheobjectivefunctionvalueinexpectation[23,Ch.9.3].Ifthepairwisecomparisonoraclemadenoerrorsthentheapproximatelinesearchisaccomplishedbyabinary-search-likeschemethatisknownintheliteratureasthegoldensectionline-searchalgorithm[24].However,whenresponsesfromtheoracleareonlyprobablycorrectwemaketheline-searchrobusttoerrorsbyrepeatingthesamequeryuntilwecanbeconfidentaboutthetrue,uncorrupteddirectionofthepairwisecomparisonusingastandardprocedurefromtheactivelearningliterature[25].B.1CoordinatedescentalgorithmTheorem7.Letf∈Fτ,L,BwithB=Rn.Foranyη>0assumethelinesearchinthealgorithmofFigure1requiresatmostTℓ(η)queriesfromthepairwisecomparisonoracle.IfxKisanestimateofx∗=argminxf(x)afterrequestingnomorethanKpairwisecomparisons,thensupfE[f(xK)−f(xn-dimensionalPairwisecomparisonalgorithmInput:x0∈Rn,η≥0Fork=0,1,2,...Choosedk=eifori∈{1,...,n}chosenuniformlyatrandomObtainαkfromaline-searchsuchthat|αk−α∗|≤ηwhereα∗=argminαf(xk+αdk)xk+1=xk+αkdkendFigure1:Algorithmtominimizeaconvexfunctioninddimensions.Hereeiisunderstoodtobeavectorofallzeroswithaoneintheithposition.Proof.Firstnotethat||dk||=1forallkwithprobability1.BecausethegradientsoffareLipschitz(L)weB.2LinesearchThissectionisconcernedwithminimizingafunctionf(xk+αdk)oversomeα∈R.Becauseweareminimizingoverasinglevariable,α,wewillrestarttheindexingat0suchafterexitingtheinitialwhileloops,(i)atmost2+12log28τ(f(x)−f(x+dα∗))pairwisecom-parisonswererequested,(ii)α∗∈[α−k,α+k],and(iii)|α+k−α−k|≤8τ(f(x)−f(x+dα∗))1/2.Wealsohavethatα∗∈[α−k+1,α+k+1]ifα∗∈[α−k,α+k]forallk.Thus,itfollowsthat|α+k+l−α−k+l|=2−l|α+k−α−k|≤2−l8τ(f(x)ItwouldbeconvenientifwecouldsimplyapplytheresultofLemma2tothealgorithmofFigure2.Unfortunately,ifwedothisthereisnoguaranteethat|f(y)−f(x)|isboundedbelowsofor