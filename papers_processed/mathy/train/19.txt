Iterative Ranking from Pair-wise Comparisons
Sahand Negahban
Department of EECS
Massachusetts Institute of Technology
sahandn@mit.edu
Sewoong Oh
Department of IESE
University of Illinois at Urbana Champaign
swoh@illinois.edu
Devavrat Shah
Department of EECS
Massachusetts Institute of Technology
devavrat@mit.edu
Abstract
The question of aggregating pairwise comparisons to obtain a global ranking over
a collection of objects has been of interest for a very long time: be it ranking
of online gamers (e.g. MSRâ€™s TrueSkill system) and chess players, aggregating
social opinions, or deciding which product to sell based on transactions. In most
settings, in addition to obtaining ranking, finding â€˜scoresâ€™ for each object (e.g.
playerâ€™s rating) is of interest to understanding the intensity of the preferences.
In this paper, we propose a novel iterative rank aggregation algorithm for discov-
ering scores for objects from pairwise comparisons. The algorithm has a natural
random walk interpretation over the graph of objects with edges present between
two objects if they are compared; the scores turn out to be the stationary prob-
ability of this random walk. The algorithm is model independent. To establish
the efficacy of our method, however, we consider the popular Bradley-Terry-Luce
(BTL) model in which each object has an associated score which determines the
probabilistic outcomes of pairwise comparisons between objects. We bound the
finite sample error rates between the scores assumed by the BTL model and those
estimated by our algorithm. This, in essence, leads to order-optimal dependence
on the number of samples required to learn the scores well by our algorithm. In-
deed, the experimental evaluation shows that our (model independent) algorithm
performs as well as the Maximum Likelihood Estimator of the BTL model and
outperforms a recently proposed algorithm by Ammar and Shah [1].
1 Introduction
Rank aggregation is an important task in a wide range of learning and social contexts arising in
recommendation systems, information retrieval, and sports and competitions. Given n items, we
wish to infer relevancy scores or an ordering on the items based on partial orderings provided through
many (possibly contradictory) samples. Frequently, the available data that is presented to us is in
the form of a comparison: player A defeats player B; book A is purchased when books A and
B are displayed (a bigger collection of books implies multiple pairwise comparisons); movie A is
liked more compared to movie B. From such partial preferences in the form of comparisons, we
frequently wish to deduce not only the order of the underlying objects, but also the scores associated
with the objects themselves so as to deduce the intensity of the resulting preference order. For
example, the Microsoft TrueSkill engine assigns scores to online gamers based on the outcomes of
(pairwise) games between players. Indeed, it assumes that each player has inherent â€œskillâ€ and the
1
outcomes of the games are used to learn these skill parameters which in turn lead to scores associate
with each player. In most such settings, similar model-based approaches are employed.
In this paper, we have set out with the following goal: develop an algorithm for the above stated
problem which (a) is computationally simple, (b) works with available (comparison) data only and
does not try to fit any model per se, (c) makes sense in general, and (d) if the data indeed obeys
a reasonable model, then the algorithm should do as well as the best model aware algorithm. The
main result of this paper is an affirmative answer to all these questions.
Related work. Most rating based systems rely on users to provide explicit numeric scores for their
interests. While these assumptions have led to a flurry of theoretical research for item recommen-
dations based on matrix completion [2, 3, 4], it is widely believed that numeric scores provided
by individual users are generally inconsistent. Furthermore, in a number of learning contexts as
illustrated above, it is simply impractical to ask a user to provide explicit scores.
These observations have led to the need to develop methods that can aggregate such forms of or-
dering information into relevance ratings. In general, however, designing consistent aggregation
methods can be challenging due in part to possible contradictions between individual preferences.
For example, if we consider items A, B, and C, one user might prefer A to B, while another prefers
B to C, and a third user prefers C to A. Such problems have been well studied as in the work by
Condorcet [5]. In the celebrated work by Arrow [6], existence of a rank aggregation algorithm with
reasonable sets of properties (or axioms) was shown to be impossible.
In this paper, we are interested in a more restrictive setting: we have outcomes of pairwise compar-
isons between pairs of items, rather than a complete ordering as considered in [6]. Based on those
pairwise comparisons, we want to obtain a ranking of items along with a score for each item indicat-
ing the intensity of the preference. One reasonable way to think about our setting is to imagine that
there is a distribution over orderings or rankings or permutations of items and every time a pair of
items is compared, the outcome is generated as per this underlying distribution. With this, our ques-
tion becomes even harder than the setting considered by Arrow [6] as, in that work, effectively the
entire distribution over permutations was already known! Indeed, such hurdles have not stopped the
scientific community as well as practical designers from designing such systems. Chess rating sys-
tems and the more recent MSR TrueSkill system are prime examples. Our work falls precisely into
this realm: design algorithms that work well in practice, makes sense in general, and perhaps more
importantly, have attractive theoretical properties under common comparative judgment models.
With this philosophy in mind, in recent work, Ammar and Shah [1] have presented an algorithm that
tries to achieve the goal with which we have set out. However, their algorithm requires information
about comparisons between all pairs, and for each pair it requires the exact pairwise comparison
â€˜marginalâ€™ with respect to the underlying distribution over permutations. Indeed, in reality, not all
pairs of items can typically be compared, and the number of times each pair is compared is also very
small. Therefore, while an important step is taken in [1], it stops short of achieving the desired goal.
In somewhat related work by Braverman and Mossel [7], the authors present an algorithm that
produces an ordering based on O(n log n) pair-wise comparisons on adaptively selected pairs. They
assume that there is an underlying true ranking and one observes noisy comparison results. Each
time a pair is queried, we are given the true ordering of the pair with probability 1/2 + Î³ for some
Î³ > 0 which does not depend on the items being compared. One limitation of this model is that it
does not capture the fact that in many applications, like chess matches, the outcome of a comparison
very much depends on the opponents that are competing.
Such considerations have naturally led to the study of noise models induced by parametric distribu-
tions over permutations. An important and landmark model in this class is called the Bradley-Terry-
Luce (BTL) model [8, 9], which is also known as the Multinomial Logit (MNL) model (cf. [10]).
It has been the backbone of many practical system designs including pricing in the airline industry
[11]. Adler et al. [12] used such models to design adaptive algorithms that select the winner from
small number of rounds. Interestingly enough, the (near-)optimal performance of their adaptive
algorithm for winner selection is matched by our non-adaptive (model independent) algorithm for
assigning scores to obtain global rankings of all players.
Our contributions. In this paper, we provide an iterative algorithm that takes the noisy comparison
answers between a subset of all possible pairs of items as input and produces scores for each item
2
as the output. The proposed algorithm has a nice intuitive explanation. Consider a graph with
nodes/vertices corresponding to the items of interest (e.g. players). Construct a random walk on this
graph where at each time, the random walk is likely to go from vertex i to vertex j if items i and j
were ever compared; and if so, the likelihood of going from i to j depends on how often i lost to j.
That is, the random walk is more likely to move to a neighbor who has more â€œwinsâ€. How frequently
this walk visits a particular node in the long run, or equivalently the stationary distribution, is the
score of the corresponding item. Thus, effectively this algorithm captures preference of the given
item versus all of the others, not just immediate neighbors: the global effect induced by transitivity
of comparisons is captured through the stationary distribution.
Such an interpretation of the stationary distribution of a Markov chain or a random walk has been
an effective measure of relative importance of a node in wide class of graph problems, popularly
known as the network centrality [13]. Notable examples of such network centralities include the
random surfer model on the web graph for the version of the PageRank [14] which computes the
relative importance of a web page, and a model of a random crawler in a peer-to-peer file-sharing
network to assign trust value to each peer in EigenTrust [15].
The computation of the stationary distribution of the Markov chain boils down to â€˜power iterationâ€™
using transition matrix lending to a nice iterative algorithm. Thus, in effect, we have produced an
algorithm that (a) is computationally simple and iterative, (b) is model independent and works with
the data only, and (c) intuitively makes sense. To establish rigorous properties of the algorithm, we
analyze its performance under the BTL model described in Section 2.1.
Formally, we establish the following result: given n items, when comparison results between ran-
domly chosen O(npoly(log n)) pairs of them are produced as per an (unknown) underlying BTL
model, the stationary distribution produced by our algorithm (asymptotically) matches the true score
(induced by the BTL model). It should be noted that â„¦(n log n) is a necessary number of (random)
comparisons for any algorithm to even produce a consistent ranking (due to connectivity threshold
of random bipartite graph). In that sense, we will see that up to poly(log n) factor, our algorithm
is optimal in terms of sample complexity. Indeed, the empirical experimental study shows that the
performance of our algorithm is identical to the ML estimation of the BTL model. Furthermore, it
handsomely outperforms other popular choices including the algorithm by [1].
Some remarks about our analytic technique. Our analysis boils down to studying the induced sta-
tionary distribution of the random walk or Markov chain corresponding to the algorithm. Like most
such scenarios, the only hope to obtain meaningful results for such â€˜random noisyâ€™ Markov chain
is to relate it to stationary distribution of a known Markov chain. Through recent concentration of
measure results for random matrices and comparison technique using Dirichlet forms for charac-
terizing the spectrum of reversible/self-adjoint operators, along with the known expansion property
of the random graph, we obtain the eventual result. Indeed, it is the consequence of such powerful
results that lead to near-optimal analytic results.
The remainder of this paper is organized as follows. In Section 2 we will concretely introduce our
model, the problem, and our algorithm. In Section 3 we will discuss our main theoretical results.
The proofs will be presented in Section 4.
Notation. We use C, C0
, etc. to denote generic numerical constants. We use AT
to denote the
transpose of a matrix. The Euclidean norm of a vector is denoted by kxk =
pP
i x2
i , and the
operator norm of a linear operator is denoted by kAk2 = maxx xT
Ax/xT
x. Also define [n] =
{1, 2, . . . , n} to be the set of all integers from 1 to n.
2 Model, Problem Statement, and Algorithm
We now present a concrete exposition of our underlying probabilistic model and our problem. We
then present our explicit random walk approach to ranking.
2.1 Bradley-Terry-Luce model for comparative judgment
In this section we discuss our model of comparisons between various items. As alluded to above,
for the purpose of establishing analytic properties of the algorithm, we will assume comparisons are
3
governed by the BTL model of pairwise comparisons. However, the algorithm itself operates with
data generated in arbitrary manner.
To begin with, there are n items of interest, represented as [n] = {1, . . . , n}. We shall assume that
for each item i âˆˆ [n] that there is an associated weight score wi âˆˆ R+ (i.e. itâ€™s a strictly positive
real number). Hence, we may consider the vector w âˆˆ Rn
+ to be the associated weight vector of
all items. Given a pair of items i and j we will let Y l
ij be 1 if j is preferred over i and 0 otherwise
during the lth
competition for 1 â‰¤ l â‰¤ k, where k is the total number of competitions for the pair.
Under the BTL model we assume that
P(Y l
ij = 1) =
wj
wi + wj
. (1)
Furthermore, conditioned on the score vector w we assume the the variables Y l
i,j are independent
for all i, j, and l. We further assume that given some item i we will compare item j to i with
probability d/n. In our setting d will be poly-logarithmic in n. This model is a natural one to
consider because over a population of individuals the comparisons cannot be adaptively selected.
A more realistic model might incorporate selecting various items with different distributions: for
example, the Netflix dataset demonstrates skews in the sampling distribution for different films [16].
Thus, given this model our goal is to recover the weight vector w given such pairwise comparisons.
We now discuss our method for computing the scores wi.
2.2 Random walk approach to ranking
In our setting, we will assume that aij represents the fraction of times object j has been preferred to
object i, for example the fraction of times chess player j has defeated player i. Given the notation
above we have that aij = (1/k)
Pk
l=1 Y l
ij. Consider a random walk on a weighted directed graph
G = ([n], E, A), where a pair (i, j) âˆˆ E if and only if the pair has been compared. The weight edges
are defined as the outcome of the comparisons Aij = aij/(aij + aji) and Aji = aji/(aij + aji).
We let Aij = 0 if the pair has not been compared. Note that by the Strong Law of Large Numbers,
as the number k â†’ âˆ the quantity Aij converges to wj/(wi + wj) almost surely.
A random walk can be represented by a time-independent transition matrix P, where Pij =
P(Xt+1 = j|Xt = i). By definition, the entries of a transition matrix are non-negative and sat-
isfy
P
j Pij = 1. One way to define a valid transition matrix of a random walk on G is to scale
all the edge weights by 1/dmax, where we define dmax as the maximum out-degree of a node. This
ensures that each row-sum is at most one. Finally, to ensure that each row-sum is exactly one, we
add a self-loop to each node. More concretely,
Pij =
 1
dmax
Aij if i 6= j ,
1 âˆ’ 1
dmax
P
k6=i Aik if i = j .
(2)
The choice to construct our random walk as above is not arbitrary. In an ideal setting with infinite
samples (k â†’ âˆ) the transition matrix P would define a reversible Markov chain. Recall that
a Markov chain is reversible if it satisfies the detailed balance equation: there exists v âˆˆ Rn
+
such that viPij = vjPji for all i, j; and in that case, Ï€ âˆˆ Rn
+ defined as Ï€i = vi/(
P
j vj) is
itâ€™s unique stationary distribution. In the ideal setting (say k â†’ âˆ), we will have Pij â‰¡ PÌƒij =
(1/dmax)wj/(wi + wj). That is, the random walk will move from state i to state j with probability
equal to the chance that item j is preferred to item i. In such a setting, it is clear that v = w satisfies
the reversibility conditions. Therefore, under these ideal conditions it immediately follows that the
vector w/
P
i wi acts as a valid stationary distribution for the Markov chain defined by PÌƒ, the ideal
matrix. Hence, as long as the graph G is connected and at least one node has a self loop then we
are guaranteed that our graph has a unique stationary distribution proportional to w. If the Markov
chain is reversible then we may apply the spectral analysis of self-adjoint operators, which is crucial
in the analysis when we repeatedly apply the operator PÌƒ.
In our setting, the matrix P is a noisy version (due to finite sample error) of the ideal matrix PÌƒ
discussed above. Therefore, it naturally suggests the following algorithm as a surrogate. We esti-
mate the probability distribution obtained by applying matrix P repeated starting from any initial
condition. Precisely, let pt(i) = P(Xt = i) denote the distribution of the random walk at time t
4
with p0 = (p0(i)) âˆˆ Rn
+ be an arbitrary starting distribution on [n]. Then,
pT
t+1 = pT
t P . (3)
Regardless of the starting distribution, when the transition matrix has a unique top eigenvalue, the
random walk always converges to a unique distribution: the stationary distribution Ï€ = limtâ†’âˆ pt.
In linear algebra terms, this stationary distribution Ï€ is the top left eigenvector of P, which makes
computing Ï€ a simple eigenvector computation. Formally, we state the algorithm, which assigns
numerical scores to each node, which we shall call Rank Centrality:
Rank Centrality
Input: G = ([n], E, A)
Output: rank {Ï€(i)}iâˆˆ[n]
1: Compute the transition matrix P according to (2);
2: Compute the stationary distribution Ï€.
The stationary distribution of the random walk is a fixed point of the following equation:
Ï€(i) =
X
j
Ï€(j)
Aji
P
` Ai`
.
This suggests an alternative intuitive justification: an object receives a high rank if it has been
preferred to other high ranking objects or if it has been preferred to many objects.
One key question remains: does P have a well defined stationary distribution? As discussed ear-
lier, when G is connected, the idealized transition matrix PÌƒ has stationary distribution with desired
properties. But due to noise, P may not be reversible and the arguments of ideal PÌƒ do not apply to
our setting. Indeed, it is the finite sample error that governs the noise. Therefore, by analyzing the
effect of this noise (and hence the finite samples), it is likely that we can obtain the error bound on
the performance of the algorithm. As an important contribution of this work, we will show that even
the iterations (cf. (3)) induced by P are close enough to those induced by PÌƒ. Subsequently, we can
guarantee that the iterative algorithm will converge to a solution that is close to the ideal stationary
distribution.
3 Main Results
Our main result, Theorem 1, provides an upper bound on estimating the stationary distribution given
the observation model presented above. The results demonstrate that even with random sampling
we can estimate the underlying score with high probability with good accuracy. The bounds are
presented as the rescaled Euclidean norm between our estimate Ï€ and the underlying stationary dis-
tribution PÌƒ. This error metric provides us with a means to quantify the relative certainty in guessing
if one item is preferred over another. Furthermore, producing such scores are ubiquitous [17] as they
may also be used to calculate the desired rankings. After presenting our main theoretical result we
will then provide simulations demonstrating the empirical performance of our algorithm in different
contexts.
3.1 Error bound in stationary distribution recovery via Rank Centrality
The theorem below presents our main recovery theorem under the sampling assumptions described
above. It is worth noting that while the result presented below is for the specific sampling model
described above. The results can be extended to general graphs as long as the spectral gap of the
corresponding Markov chain is well behaved. We will discuss the point further in the sequel.
Theorem 1. Assume that, among n items, each pair is chosen with probability d/n and for each
chosen pair we collect the outcomes of k comparisons according to the BTL model. Then, there exists
positive universal constants C, C0
, and C00
such that when d â‰¥ C(log n)2
, and k d â‰¥ Cb5
log n,
the following bound on the error rate holds with probability at least 1 âˆ’ C00
/n3
:
Ï€ âˆ’ Ï€Ìƒ
kÏ€Ìƒk
â‰¤ C0
b3
r
log n
k d
,
where Ï€Ìƒ(i) = wi/
P
` w` and b â‰¡ maxi,j wi/wj.
5
Remarks. Some remarks are in order. First, the above result implies that as long as we choose
d = Î˜(log2
n) and k = Ï‰(1) (i.e. large enough, say k = Î˜(log n)), the error goes to 0 (with
k = Î˜(log n), it goes down at rate 1/
âˆš
log n) as n increases. Since we are sampling each of
the n
2

pairs with probability d/n and then sampling them k times, we obtain O(n log3
n) (with
k = Î˜(log n)) comparisons in total. Due to classical results on Erdos-Renyi graphs, the induced
graph G is connected with high probability only when total number of pairs sampled scales as
â„¦(n log n)â€“we need at least those many comparisons. Thus, our result can be sub-optimal only up
to log2
n (log1+
n if k = log
n).
Second, the b parameter should be treated as constant. It is the dynamic range in which we are trying
to resolve the uncertainty between scores. If b were scaling with n, then it would be really easy to
differentiate scores of items that are at the two opposite end of the dynamic range; in which case one
could focus on differentiating scores of items that have their parameter values near-by. Therefore,
the interesting and challenging regime is where b is constant and not scaling.
Finally, observe the interesting consequence that under the conditions on d, since the induced distri-
bution Ï€ is close to Ï€Ìƒ, it implies connectivity of G. Thus, the analysis of our algorithm provides an
alternative proof of connectivity in an Erdos-Renyi graph (of course, by using heavy machinery!).
3.2 Experimental Results
Under the BTL model, define an error metric of a estimated ordering Ïƒ as the weighted sum of pairs
(i, j) whose ordering is incorrect:
Dw(Ïƒ) =
n 1
2nkwk2
X
i<j
(wi âˆ’ wj)2
I (wi âˆ’ wj)(Ïƒi âˆ’ Ïƒj) > 0
o1/2
,
where I(Â·) is an indicator function. This is a more natural error metric compared to the Kemeny
distance, which is an unweighted version of the above sum, since Dw(Â·) is less sensitive to errors
between pairs with similar weights. Further, assuming without loss of generality that w is normal-
ized such that
P
i wi = 1, the next lemma connects the error in Dw(Â·) to the bound provided in
Theorem 1. Hence, the same upper bound holds for Dw error. Due to space constraints, we refer to
a longer version of this paper for a proof of this lemma.
Lemma 3.1. Let Ïƒ be an ordering of n items induced by a scoring Ï€. Then, Dw(Ïƒ) â‰¤ kwâˆ’Ï€k/kwk.
For a fixed n = 400 and a fixed b = 10, Figure. 1 illustrates how the error scales with two problem
parameters: varying the number of comparisons per pair with fixed d = 10 log n (left) and varying
the sampling probability with fixed k = 32 (right). The ML estimator directly maximizes the
likelihood assuming the BTL model [18]. If we reparameterize the problem so that Î¸i = log(wi)
then we obtain our estimates b
Î¸ by solving the convex program
b
Î¸ âˆˆ arg min
Î¸
X
(i,j)âˆˆE
k
X
l=1
log(1 + exp(Î¸j âˆ’ Î¸i)) âˆ’ Y l
ij(Î¸j âˆ’ Î¸i),
which is pair-wise logistic regression. This choice is optimal in the asymptotic setting, however for
fixed-samples there do not exist theoretical guarantees for recovering the transformed scores Î¸i. The
method Count Wins scores an item by counting the number of wins divided by the total number of
comparisons [1]. Ratio Matrix assigns scores according to the top eigenvector of a matrix, whose
(i, j)-th entry is aij/aji [19]. As we see in Figure 1, the error achieved by our Random Walk
approach is comparable to that of ML estimator, and vanishes at the rate of 1/
âˆš
k as predicted by
our main result. Interestingly, for fixed d, both the Count Wins and Ratio Matrix algorithms have
strictly positive error even if we take k â†’ âˆ. The figure on the right illustrates that the error scales
as 1/
âˆš
d as expected from our main result.
4 Proofs
We may now present the proof of Theorem 1. As previously alluded to the statement of Theorem 1
can be made more general. The result that we presented is a specific instance of a more general
6
0.0001
0.001
0.01
0.1
1 10 100
Ratio Matrix
Count Wins
Rank Centrality
ML estimate
0.001
0.01
0.1
0.1 1
Ratio Matrix
Count Wins
Rank Centrality
ML estimate
Dw(Ïƒ)
k d/n
Figure 1: Average error Dw(Ïƒ) of orderings from four rank aggregation algorithms, averaged over 20 in-
stances. In the figure on the right we assume that d and n are fixed while we increase k. The figure on the right
takes k = 32 fixed and lets d increase.
lemma that we state below, which shows that our algorithm enjoys convergence properties that
result in useful upper bounds. The lemma is made general and uses standard techniques of spectral
theory. The main difficulty arises in establishing that the Markov chain P satisfies certain properties
that we will discuss below. In order to show that these properties hold we must rely on the specific
model that allows us to ultimately establish error bounds that hold with high probability. In what
follows we present the lemma and omit the proofs of certain technical details to the longer version
of the paper.
4.1 Algorithm convergence
In this section, we characterize the error rate achieved by our ranking algorithm. Given the random
Markov chain P, where the randomness comes from the outcome of the comparisons, we will show
that it does not deviate too much from its expectation PÌƒ, where we recall is defined as
PÌƒij =
(
1
dmax
wj
wi+wj
if i 6= j ,
1 âˆ’ 1
dmax
P
`6=i
w`
wi+w`
if i = j
for all (i, j) âˆˆ E and PÌƒij = 0 otherwise.
Recall from the discussion following equation (2) that the transition matrix P used in our ranking
algorithm has been carefully chosen such that the corresponding expected transition matrix PÌƒ has
two important properties. First, the stationary distribution of PÌƒ, which we denote with Ï€Ìƒ is propor-
tional to the weight vectors w. Furthermore, when the graph is connected and has self loops (which
at least one exists), this Markov chain is irreducible and aperiodic so that the stationary distribution
is unique. The next important property of PÌƒ is that it is reversibleâ€“ Ï€Ìƒ(i)PÌƒij = Ï€Ìƒ(j)PÌƒji. This obser-
vation implies that the operator PÌƒ is symmetric in an appropriate defined inner product space. The
symmetry of the operator PÌƒ will be crucial in applying ideas from spectral analysis to prove our
main results.
Let âˆ† denote the fluctuation of the transition matrix around its mean, such that âˆ† â‰¡ P âˆ’ PÌƒ. The
following lemma bounds the deviation of the Markov chain after t steps in terms of two important
quantities: the spectral radius of the fluctuation kâˆ†k2 and the spectral gap 1 âˆ’ Î»max(PÌƒ), where
Î»max(PÌƒ) â‰¡ max{Î»2(PÌƒ), âˆ’Î»n(PÌƒ)} .
Lemma 4.1. For any Markov chain P = PÌƒ + âˆ† with a reversible Markov chain PÌƒ, let pt be the
distribution of the Markov chain P when started with initial distribution p0. Then,
pt âˆ’ Ï€Ìƒ
kÏ€Ìƒk
â‰¤ Ït kp0 âˆ’ Ï€Ìƒk
kÏ€Ìƒk
r
Ï€Ìƒmax
Ï€Ìƒmin
+
1
1 âˆ’ Ï
kâˆ†k2
Ï€Ìƒmax
Ï€Ìƒmin
. (4)
where Ï€Ìƒ is the stationary distribution of PÌƒ, Ï€Ìƒmin = mini Ï€Ìƒ(i), Ï€Ìƒmax = maxi Ï€Ìƒ(i), and Ï =
Î»max(PÌƒ) + kâˆ†k2
p
Ï€Ìƒmax/Ï€Ìƒmin.
7
The above result provides a general mechanism for establishing error bounds between an estimated
stationary distribution Ï€ and the desired stationary distribution Ï€Ìƒ. It is worth noting that the result
only requires control on the quantities kâˆ†k2 and 1 âˆ’ Ï. We may now state two technical lemmas
that provide control on the quantities kâˆ†k2 and 1 âˆ’ Ï, respectively.
Lemma 4.2. Under the assumptions of Theorem 1, we have that the error matrix âˆ† = P âˆ’ PÌƒ
satisfies
kâˆ†k2 â‰¤ C
r
log n
kd
for some positive universal constant C with probability at least 1 âˆ’ 3nâˆ’4
The next lemma provides our desired bound on 1 âˆ’ Ï.
Lemma 4.3. Under the assumptions of Theorem 1, the spectral radius satisfies
1 âˆ’ Ï â‰¥ C0
/b2
with probability at least 1 âˆ’ nâˆ’c
, for some positive universal constant C0
and c. The constant c can
be made as large as we want by increasing the constant C in d â‰¥ C log n.
With the above results in hand we may now proceed with the proof of Theorem 1.
When there is a positive spectral gap Ï < 1 the first term in (4) vanishes as t grows. The rest of the
first term is bounded and independent of t. Formally, we have
Ï€Ìƒmax/Ï€Ìƒmin â‰¤ b , kÏ€Ìƒk â‰¥ 1/
âˆš
n , and kp0 âˆ’ Ï€Ìƒk â‰¤ 2 ,
by the assumption that maxi,j wi/wj â‰¤ b and the fact that Ï€Ìƒ(i) = wi/(
P
j wj). Hence, the error
between the distribution at the tth
iteration pt
and the true stationary distribution Ï€Ìƒ is dominated by
the second term in equation (4). Therefore, in order to finish the proof of Theorem 1 we require
bounds on kâˆ†k2 and 1 âˆ’ Ï.
We recall that by Lemma 4.2 we have kâˆ†k2 â‰¤ C
p
log n/(kd) and from Lemma 4.3 that there
is a positive spectral gap 1 âˆ’ Ï â‰¥ C0
/b2
for some numerical constants C and C0
. Given these
observations the dominant second term in equation (4) is bounded by
lim
tâ†’âˆ
pt âˆ’ Ï€Ìƒ
kÏ€Ìƒk
â‰¤ C b3
r
log n
kd
.
This finishes the proof of Theorem 1.
5 Discussion
In this paper, we developed a novel iterative rank aggregation algorithm for discovering scores of
objects given pairwise comparisons. The algorithm has a natural random walk interpretation over
the graph of objects with edges present between two objects if they are compared; the scores turn out
to be the stationary probability of this random walk. In lieu of recent works on network centrality
which are graph score functions primarily based on random walks, we call this algorithm Rank
Centrality. The algorithm is model independent.
We also established the efficacy of the algorithm by analyzing its performance when data is gen-
erated as per the popular Bradley-Terry-Luce (BTL) model. We have obtained an analytic bound
on the finite sample error rates between the scores assumed by the BTL model and those estimated
by our algorithm. As shown, these lead to order-optimal dependence on the number of samples re-
quired to learn the scores well by our algorithm. The experimental evaluation show that our (model
independent) algorithm performs as well as the Maximum Likelihood Estimator of the BTL model
and outperforms other known competitors included the recently proposed algorithm by Ammar and
Shah [1]. Given the simplicity of the algorithm, analytic guarantees and wide utility of the problem
of rank aggregation, we believe that this algorithm will be of great practical value.
8
References
[1] A. Ammar and D. Shah. Communication, control, and computing (allerton), 2011, 49th annual
allerton conference on. pages 776â€“783, September 2011.
[2] E. J. CandeÌ€s and B. Recht. Exact matrix completion via convex optimization. Foundations of
Computational Mathematics, 9(6):717â€“772, 2009.
[3] R.H. Keshavan, A. Montanari, and S. Oh. Matrix completion from a few entries. Information
Theory, IEEE Transactions on, 56(6):2980 â€“2998, june 2010.
[4] S. Negahban and M. J. Wainwright. Restricted strong convexity and (weighted) matrix com-
pletion: Optimal bounds with noise. Journal of Machine Learning Research, 2012. To appear;
posted at http://arxiv.org/abs/1009.2118.
[5] M. Condorcet. Essai sur lâ€™application de lâ€™analyse aÌ€ la probabiliteÌ des deÌcisions rendues aÌ€ la
pluraliteÌ des voix. lâ€™Imprimerie Royale, 1785.
[6] K. J. Arrow. Social Choice and Individual Values. Yale University Press, 1963.
[7] M. Braverman and E. Mossel. Noisy sorting without resampling. In Proceedings of the nine-
teenth annual ACM-SIAM symposium on Discrete algorithms, SODA â€™08, pages 268â€“276.
Society for Industrial and Applied Mathematics, 2008.
[8] R. A. Bradley and M. E. Terry. Rank analysis of incomplete block designs: I. the method of
paired comparisons. Biometrika, 39(3/4):324â€“345, 1955.
[9] D. R. Luce. Individual Choice Behavior. Wiley, New York, 1959.
[10] D. McFadden. Conditional logit analysis of qualitative choice behavior. Frontiers in Econo-
metrics, pages 105â€“142, 1973.
[11] K. T. Talluri and G. Van Ryzin. The Theory and Practice of Revenue Management. springer,
2005.
[12] M. Adler, P. Gemmell, M. Harchol-Balter, R. M. Karp, and C. Kenyon. Selection in the
presence of noise: the design of playoff systems. In Proceedings of the fifth annual ACM-
SIAM symposium on Discrete algorithms, SODA â€™94, pages 564â€“572. Society for Industrial
and Applied Mathematics, 1994.
[13] M. E. J. Newman. Networks: An Introduction. Oxford University Press, 2010.
[14] S. Brin and L. Page. The anatomy of a large-scale hypertextual web search engine. In Seventh
International World-Wide Web Conference (WWW 1998), 1998.
[15] S. D. Kamvar, M. T. Schlosser, and H. Garcia-Molina. The eigentrust algorithm for reputation
management in p2p networks. In Proceedings of the 12th international conference on World
Wide Web, WWW â€™03, pages 640â€“651, New York, NY, USA, 2003. ACM.
[16] R. Salakhutdinov and N. Srebro. Collaborative filtering in a non-uniform world: Learning with
the weighted trace norm. Technical Report abs/1002.2780v1, Toyota Institute of Technology,
2010.
[17] J. C. Duchi, L. Mackey, and M. I. Jordan. On the consistency of ranking algorithms. In
Proceedings of the ICML Conference, Haifa, Israel, June 2010.
[18] L. R. Ford Jr. Solution of a ranking problem from binary comparisons. The American Mathe-
matical Monthly, 64(8):28â€“33, 1957.
[19] T. L. Saaty. Decision-making with the ahp: Why is the principal eigenvector necessary. Euro-
pean Journal of Operational Research, 145:pp. 85â€“91, 2003.
9
