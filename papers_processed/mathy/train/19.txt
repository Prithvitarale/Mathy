FairnessinLearning:ClassicandContextualBandits∗MatthewJosephMichaelKearnsJamieMorgensternAaronRoth†November8,2016AbstractWeintroducethestudyoffairnessinmulti-armedbanditproblems.Ourfairnessdefinitioncanbeinterpretedasdemandingthatgivenapoolofapplicants(say,forcollegeadmissionormortgages),aworseapplicantisneverfavoredoverabetterone,despitealearningalgorithm’suncertaintyoverthetruepayoffs.Weproveresultsoftwotypes:First,intheimportantspecialcaseoftheclassicstochasticbanditsproblem(i.e.inwhichtherearenocontexts),weprovideaprovablyfairalgorithmbasedonchainedconfidenceinter-vals,andproveacumulativeregretboundwithacubicdependenceonthenumberofarms.Wefurthershowthatanyfairalgorithmmusthavesuchadependence.Whencombinedwithregretboundsforstandardnon-fairalgorithmssuchasUCB,thisprovesastrongseparationbetweenfairandunfairlearning,whichextendstothegeneralcontextualcase.Inthegeneralcontextualcase,weproveatightconnectionbetweenfairnessandtheKWIK(KnowsWhatItKnows)learningmodel:aKWIKalgorithmforaclassoffunctionscanbetransformedintoaprovablyfaircontextualbanditalgorithm,andconverselyanyfaircontextualbanditalgorithmcanbetransformedintoaKWIKlearningalgorithm.ThistightconnectionallowsustoprovideContents1Introduction31.1FairnessandLearning................................1IntroductionAutomatedtechniquesfromstatisticsandmachinelearningareincreasinglybeingusedtomakedecisionsthathaveimportantconsequencesonpeople’slives,includinghiring[Miller,2015],lending[Byrnes,2016],policing[Rudin,2013],andevencriminalsentencing[Barry-Jesteretal.,jasrepresentingdifferentpopulations(e.g.differentethnicgroups,cultures,orotherdivisionswithinsociety),andviewthecontextxtjatroundtasrepresentinginformationaboutaparticularindividualfromthatpopulation.Eachpopulationhasitsownunderlyingfunctionfjwhichmapscontextstoexpectedpayoff2.Ateachtimestept,thealgorithmisaskedtochoosebetweenspecificmembersofeachpopulation,representedbythecontextsxtj.ThequalityofanindividualisthusexactlyEhrtji=fj(xtj).Ourfairnessconditiontranslatesthus:foranypairofarmsj,j0attimet,iffj(xtj)≥fj0(xtj0),thenanalgorithmissaidtobediscriminatoryifitpreferentiallychoosesthelowerqualityarmj0.Saidanotherway,analgorithmisfairifitguaranteesthefollowing:withhighprobability,overallroundst,andforallpairsofarmsj,j0,wheneverfj(xtj)≥fj0(xtj0),thealgorithmchoosesarmjwithprobabilityatleastthatwithwhichitchoosesarmj03.Itisworthnotingthatthisdefinitionoffairness(formalizedinthepreliminaries)isentirelyconsistentwiththeoptimalpolicy,whichcansimplychooseateachroundtoplayuniformlyatrandomfromthearmsargmaxjEhrtjiwhichmaximizetheexpectedreward.Thisisbecause–itseems–thegoaloffairnessasenunciatedaboveisentirelyconsistentwiththegoalofmaximizingexpectedreward.Indeed,thefairnessconstraintexactlystatesthatthealgorithmcannotfavorlowrewardarms!Ourmainconceptualresultisthatthisintuitionisincorrectinthefaceofunknownrewardfunctions.Eventhoughtheconstraintoffairnessisconsistentwithimplementingtheoptimalpolicy,itisnotnecessarilyconsistentwithlearningtheoptimalpolicy.Weshowthatfairnessalwayshasacost,intermsoftheachievablelearningrateofthealgorithm.Forsomeproblems,thecostismild,butforothers,thecostislarge.1.2OurResultsWedivideourresultsintotwoparts.First,westudytheclassicstochasticmulti-armedbanditproblem[LaiandRobbins,1985,KatehakisandRobbins,1995].Inthiscase,therearenocontexts,andeacharmihasafixedbutunknownaveragerewardµi.Notethatthisisaspecialcaseofthecontextualbanditprobleminwhichthecontextsarethesameeveryday.Inthissetting,ourfairnessconstraintspecializestorequirethatwithprobability1−δ,foranypairofarmsi,jforwhichµi≥µj,atnoroundtdoesthealgorithmplayarmjwithprobabilityhigherthanthatwithwhichitplaysarmi.Notethateventhisspecialcasemodelsinterestingscenariosfromthepointofviewoffairnessinlearning.Itmodels,forexample,thecaseinwhichchoicesaremadebyaloanofficerafterapplicantshavebeencategorizedintokinternallyindistinguishableequivalenceclassesbasedontheirapplications.Withoutafairnessconstraint,itisknownthatitispossibletoguaranteenon-trivialregrettotheoptimalpolicyafteronlyT=O(k)manyrounds[Aueretal.,2002].InSection3,wegiveanalgorithmthatsatisfiesourfairnessconstraintandisabletoguaranteenon-trivialregretafterT=O(k3)rounds.WethenshowinSection4thatitisnotpossibletodobetter–any2Itisnaturalthatdifferentpopulationsshouldhavedifferentunderlyingfunctions–forexample,inacollegeadmissionssetting,thefunctionmappingapplicationstocollegesuccessprobabilitymightweightSATscoreslessinawealthypopulationthatemploysSATtutors,andmoreinaworking-classpopulationthatdoesnot–seeDworketal.[2012]formorediscussionofthisissueandMunozetal.[2016]forexamples.3Notethatthedefinitiondoesnotrequireequalityofoutcomesonapopulationwidebasis,alsoknownasstatisticalparity.Ifsomepopulationjislesscredit-worthyonaveragethananotherpopulationj0,wedonotnecessarilysaythatanalgorithmisdiscriminatoryifitendsupgivingfewerloanstoindividualsfrompopulationj.Ournotionofdiscriminationisonanindividualbasis–itrequiresthatevenifpopulationjislesscreditworthyonaveragethanpopulationj0,ifithappensthatonsomeday,anindividualappearsfromfairlearningalgorithmcanbeforcedtoendureconstantper-roundregretforT=Ω(k3)rounds.Thus,wetightlycharacterizetheoptimalregretattainablebyfairalgorithmsinthissetting,andformallyseparateitfromtheregretattainablebyalgorithmsabsentafairnessconstraint.Notethatthisalreadyshowsaseparationbetweenthebestpossiblelearningratesforcontextualbanditlearningwithandwithoutthefairnessconstraint–thestochasticmulti-armedbanditproblemisaspecialcaseofeverycontextualbanditproblem,andforgeneralcontextualbanditproblems,itisalsoknownhowtogetnon-trivialregretafteronlyT=O(k)manyrounds[Agarwaletal.,2014,Beygelzimeretal.,2011,Chuetal.,2011].Wethenmoveontothegeneralcontextualbanditsettingandproveabroad1.3OtherRelatedWorkSeveralpapersstudytheproblemoffairnessinmachinelearning.Onelineofworkaimstogivealgorithmsforbatchclassificationwhichachievegroupfairnessotherwiseknownasequalityofoutcomes,statisticalparity–oralgorithmsdefinedasfollows,whereπtrepresentsA’sdistributiononarmsatroundt:XtEit∗∼π∗(xt)hfit∗(xtit∗)i−Eit∼πt"Xtfit(xtit)#=Regret(x1,...,xT).WehereafterrefertothisastheregretofA.Theoptimalpolicyπ∗pullsarmswithhighestexpectationwithunknownmeanµj.AlearningalgorithmAchoosesanarmitinroundt,andobservestherewardrtit∼Ditforthearmthatitchose.Leti∗∈[k]bethearmwithhighestexpectedreward:i∗∈argmaxi∈[k]µi.Thepseudo-regretofanalgorithmAonD1,...,Dkisnowjust:T·µi∗−Eit∼πtX0≤t≤Tµit=Regret(T,D1,...,Dk)Letht∈([k]×[0,1])t−1denotearecordofthet−1roundsexperiencedbythealgorithmsofar,representedbyt−12-tuplesencodingthepreviousarmschosenandrewardsobserved.Wewriteπtj|httodenotetheprobabilitythatAchoosesarmjgivenhistoryht.Again,wewilloftendropthesuperscripttonthehistorywhenreferringtothedistributionoverarms:πtj|h:=πtj|ht.δ-fairnessintheclassicbanditsettingspecializesasfollows:Definition2(δ-fairnessintheclassicbanditssetting).Aisδ-fairif,foralldistributionsD1,...,Dk,withprobabilityatleast1−δoverthehistoryh,forallt∈[T]andallj,j0∈[k]:πtj|h>πtj0|honlyifµj>µj0.3FairClassicStochasticBandits:AnAlgorithmInthissection,wedescribeasimpleandintuitivemodificationofthestandardUCBalgorithm[Aueretal.,2002],calledFairBandits,provethatitisfair,andanalyzeitsregretbound.Thealgorithmanditsanalysishighlightakeyideathatisimportanttothedesignoffairalgorithmsinthissetting:thatofchainingconfidenceintervals.Intuitively,asaδ-fairalgorithmexploresdifferentarmsitmustplaytwoarmsj1andj2withequalprobabilityuntilithassufficientdatatodeduce,withconfidence1−δ,eitherthatµj1>µj2orviceversa.FairBanditsdoesthisbymaintainingempiricalestimatesofthemeansofbotharms,togetherwithconfidenceintervalsaroundthosemeans.Tobesafe,thealgorithmmustplaythearmswithequalprobabilitywhiletheirconfidenceintervalsoverlap.Thesamereasoningappliessimultaneouslytoeverypairofarms.Thus,iftheconfidenceintervalsofeachpairofarmsjiandji+1overlapforeachi∈[k],thealgorithmisforcedtoplayallarmsjwithequalprobability.Thisisthecaseeveniftheconfidenceintervalsaroundarmjkandarmj1arefarfromoverlapping–i.e.whenthealgorithmcanbeconfidentthatµj1>µjk.Thisapproachinitiallyseemsnaive:inanattempttoachievefairness,itseemsoverlyconser-vativewhenrulingoutarms,andcanbeforcedtoplayarmsuniformlyatrandomforlongperiodsoftime.Thisisreflectedinitsregretbound,whichisonlynon-trivialafterTk3,whereastheUCBalgorithm[Aueretal.,2002]achievesnon-trivialregretafterT=O(k)rounds.However,ourlowerboundinSection4showsthatanyfairalgorithmmustsufferconstantper-roundregretforTk3roundsonsomeinstances.WenowgiveanoverviewofthebehaviorofFairBandits.Ateveryroundt,FairBanditsidentifiesthearmit∗=argmaxiutithathasthelargestupperconfidenceintervalamongsttheactivearms.Ateachroundt,wesayiislinkedtojif[`ti,uti]∩[`tj,utj]6=∅,andiischainedtojifiandjareinthesamecomponentofthetransitiveclosureofthelinkedrelation.FairBanditsplaysuniformlyatrandomamongallactivearmschainedtoarmit∗.Initially,theactivesetcontainsallarms.Theactivesetofarmsateachsubsequentroundisdefinedtobethesetofarmsthatarechainedtothearmwitharmwiththehighestupperconfidenceboundatanyroundhavemeansthatarelowerthanthemeansofanychainedarms,andhencesucharmscanbesafelyremovedfromtheactiveset,nevertobeplayedagain.ThisFigure1:ConfidenceintervalsovertimeforthelowerboundinstanceoutlinedinSection4fork=10.LinescorrespondtoupperandlowerconfidenceboundsforeacharmandcutoffattheroundinwhichthearmLemma3.Consideranyroundtandanyarmi∈St.Conditiononnti≥tk−rtln(2kt2δ)2.Then,uti−`ti≤2vuuuutln(π·t)2/3δ2·tk−rtln(2kt2δ)2=η(t).Finally,weprovetheboundonthetotalregretofthealgorithm,usingtheboundTheorem3.ThereisadistributionPoverk-arminstancesofthestochasticmulti-armedbanditproblemsuchthatanyfairalgorithmrunonPexperiencesconstantper-roundregretforatleastT=Ωk3ln1δLemma4.Considerthefollowingtwoexperiments:Inthefirst,letµi∼Piandr1i,...,rti∼B(µi),andWdenotethejointdistributionon(µWenowcalculateunderwhatconditionseither(a)X≤δ01−δ0,or(b)X≥1−δ0δ0.Oneofthesemustholdifiisδ0-distinguished.Beforewedoso,weProofofTheorem3.AssumeAissomeδ-fairalgorithmwhereδ<1/8.FixT;weclaimthatwithprobabilityatleast12,foranyt=o(k3ln1δ),t≤T,πtj|ht=1kforallj.Sincethepayoffforuniformlyrandomplayis≤12+1k,whilethebestarmhaspayoff≥23,inanyroundtwhereπti|ht=πti0|htforalli,i0∈[k],thealgorithmsuffersΩ(1)regretinthatround.Lemma6impliesthat,withprobabilityatleast12overthedistributionoverhistoriesht,either(a)πt0i|ht0=πt0i0|ht0foralli,i0∈[k],t0≤tor(b)htmust√2δ-distinguishsomearmi.Case(a)impliesourclaim.Incase(b),Lemma7statesthananarmiis√2δ-distinguishableonlyifTi=Ω(k2ln1δ).Wenowarguethatunlesst=Ω(k3ln1δ),Ti=o(k2ln1δ),whichwillimplyourclaimforcase(b).Fixsomei,t.Welower-boundtforwhich,withprobabilityatleast1−δ0koverhistoriesht,itwillbethecasethatnti≥c·k2ln1δwhenπt0i|ht0=πt0i0|ht0foralli,i0∈[k],t0≤t.LetX1,...,Xtbeindicatorvariablesofarmibeingplayedinroundt0≤t.Notethatforallt0≤t,E[Xt0]=1k,sinceinallroundspriortot,wehaveallarmsareplayedwithequalprobability.Forany∈[0,1],asnt0iarenondecreasingint0,anadditiveChernoffboundimpliesP∃t0≤t:nt0i≥tk+t≤PXt0≤tXt0>tk+t≤e−2t2which,fort=qtln2kδ02,becomesPhPt0≤tXt0>tk+ti≤δ0k.So,usingaunionboundoverallkarms,withprobability1−δ0,forsomefixedtandalli,nti≤tk+qtln2kδ02.Weconditionontheeventthatntisatisfiesthisinequalityforafixedtandalli.Ifnti≥c·k2ln1δ,thisimpliestk+stln2kδ02≥c·k2ln1δ⇒t≥−kstln2kδ02+c·k3ln1δ.Ifkqtln2kδ02≤c2·k3ln1δ,thent≥c2·k3ln1δ;ifnot,thent≥c22k4ln21δln2kδ0.Thus,nti<c·k2ln1δwithprobability1−δ0foralliunlesst≥minc2·k3ln1δ,c22k4ln21δln2kδ0=Ω(k3ln1δ)forδ0∈[12,1].5KWIKLearnabilityImpliesFairBanditLearnabilityInthissection,weshowifaclassoffunctionsisKWIKlearnable,thenthereisafairalgorithmforlearningthesameclassoffunctionsinthecontextualbanditsetting,witharegretboundpolynomiallyrelatedtothefunctionclass’KWIKbound.Intuitively,KWIK-learnabilityofaclassoffunctionsguaranteeswecanlearnthefunction’sbehaviortoahighdegreeofaccuracywithahighdegreeofconfidence.Asfairnessconstrainsanalgorithmmostbeforethealgorithmhasdeterminedthepayofffunctions’behavioraccurately,thisguaranteeenablesustolearnfairlywithoutincurringmuchadditionalregret.Formally,weprovethefollowingpolynomialrelationship.Theorem4.Foraninstanceofthecontextualmulti-armedbanditproblemwherefj∈Cforallj∈[k],ifCis(,δ)-KWIKlearnablewithboundm(,δ),KWIKToFair(δ,T)isδ-fairandachievesregretbound:R(T)=Omaxk2·m∗,min(δ,1/T)T2k,k3lnkδforδ≤1√Twhere∗=argminFirst,weconstructanalgorithmKWIKToFair(δ,T)thatusestheKWIKlearningalgorithmasasubroutine,andprovethatitisδ-fair.AcalltoKWIKToFair(δ,T)willinitializeaKWIKlearnerforeacharm,andineachWenowusetheKWIKboundsoftheKWIKlearnerstoupper-boundtheregretofKWIKTo-Fair(δ,T).Lemma9.KWIKToFair(δ,T)achievesregretO(max(k2·m(∗,δ∗),k3lnTkδ)).Proof.Wefirstconditionontheeventthatboth(a)and(b)fromLemma8holdforallt,i,whichholdswithprobability1−min(δ,1T),andboundtheregretwhentheybothhold.ChooseanarbitraryroundtinOurpresentationofKWIKToFair(δ,T)hasaknowntimehorizonT.ItsguaranteesextendtothecaseinwhichTisunknownviathestandard“doublingtrick”toproveTheorem4inAppendixC.Animportantinstanceofplayedwithequalprobability,oneofthosecontextswillforceAtosuffer∗regret,sowecontinuethesimulationofAononeofthoseinstancesselectedatrandom,forcingatleast∗/2regretinexpectation,andatthesametimehaveBreturn⊥.Breceivesf∗(xt)onsucharound,whichisusedtoconstructfeedbackforA.Otherwise,Amusttransitionfromplayingarm1withstrictlyhigherprobabilitytoplaying2withstrictlyhigherIfpt,`1≤pt,`2forall`,since|Et|≤1,eitherpt,01<pt,02orpt,11<pt,12,whichwehaveconditionedonimplyingthateitherf∗(xt)<f(x(0))=0orf∗(xt)<f(x(1))=∗.Sincef∗(xt)≥0,thisimpliesf∗(xt)∈[0,∗)=[ˆ`∗,∗)=[ŷt,ŷt+∗).Otherwise,wehavethatpt,ˆ`1>pt,ˆ`2,andpt,`1≤pt,`2forall`>ˆ`.If(a)ˆ`=d1∗e,thenf∗(xt)>1,acontradiction,soˆ`<d1∗e.If(b)ˆ`=d1∗e−1,thenf∗(xt)>f(x(ˆ`))=(d1∗e−1)∗andsof∗(xt)∈((d1∗e−1)∗,1]=(ˆyt,ŷt+∗],soˆytis∗-accurate.Ifneither(a)nor(b),then(c)itmustbeˆ`<d1∗e−1.Since|Et|≤1,forsome`∈{ˆ`+1,ˆ`+2},weknowthatpt,`1<pt,`2;thus,f∗(xt)<f(x(`))≤(ˆ`+2)∗andthereforef∗(xt)∈(ˆ`∗,(ˆ`+Lemma12.SupposeAisaδ-fairalgorithmforthecontextualbanditproblemovertheclassCofconjunctionsondvariables.IfAhasregretboundR(T,δ)thenforδ0=2Tδ,FairToKWIKisan(0,ToonCaldersandSiccoVerwer.Threenaivebayesapproachesfordiscrimination-freeclassification.DataMiningandKnowledgeDiscovery,21(2):277–292,2010.WeiChu,LihongLi,LevReyzin,andRobertE.Schapire.Contextualbanditswithlinearpayofffunctions.InProceedingsoftheFourteenthInternationalConferenceonArtificialIntelligenceandStatistics,AISTATS2011,FortLauderdale,USA,April11-13,2011,pages208–214,2011.CaryCoglianeseandDavidLehr.Regulatingbyrobot:Administrativedecision-makinginthemachine-learningera.GeorgetownLawJournal,2016.Forthcoming.CynthiaDwork,MoritzHardt,ToniannPitassi,OmerReingold,andRichardZemel.Fairnessthroughawareness.InProceedingsofthe3rdInnovationsinTheoreticalComputerScienceConference,pages214–226.ACM,2012.MichaelFeldman,SorelleA.Friedler,JohnMoeller,CarlosScheidegger,andSureshVenkatasubramanian.Certifyingandremovingdisparateimpact.InProceedingsofthe21thACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandDataMining,Sydney,NSW,Australia,August10-13,2015,pages259–268,2015.BenjaminFish,JeremyKun,andÁdámDLelkes.Aconfidence-basedapproachforbalancingfairnessandaccuracy.SIAMInternationalSymposiumonDataMining,2016.FTCCommisionerJulieBrill.Navigatingthe“tracklessocean”:Fairnessinbigdataresearchanddecisionmaking.KeynoteAddressattheColumbiaUniversityDataScienceInstitute,April2015.ToshihiroKamishima,ShotaroAkaho,andJunSakuma.Fairness-awarelearningthroughregularizationapproach.InDataMiningWorkshops(ICDMW),2011IEEE11thInternationalConferenceon,pages643–650.IEEE,2011.AMissingProofsfortheClassicStochasticBanditsUpperBoundWebeginbyprovingLemma1,usedinSection3toprovethefairnessoftheFairBanditsalgo-rithm.ProofofLemma1.ChooseanarbitraryarmiandroundA.1MissingDerivationofR(T)forTheorem2R(T)≤TXt:0min(1,k·η(t))+1+π2δT≤TXt:0k·min(1,η(t))+1+πThesecondexperimenthasjointprobability:P(µ0i,r1i,...,rti)∼W0(µ0i,r1i,...,rti)=(m,d1,Thus,withprobabilityatleast12overthedistributionoverhistoriesandmeans,Pµ0∼P|htht∈unfair(A,µ0)≤2δ.However,Equation4showsthisdoesnotholdforanyhtwhichdoesnot√2δ-distinguishanyarmbutforwhichπt0i|ht06=1kforsomei∈[k],t0≤t.Thus,foratleast12ofallprobabilitymassoverhistories,eitherπt0i|ht0=1kforalli,t0≤t,orhtmust√2δ-distinguishsomearm.CMissingProofsfortheContextualBanditSettingWebeginbyprovingtworesultsrelatedtoKWIKToFair.Thefirst,Lemma8,wasusedinSection5toprovethatKWIKToFairisδ-fairinTheorem5.ProofofLemma8.Wewillrefertoaviolationofeither(a)or(b)asafailureoflearnerLi.ForeachLi,thesetofqueriesaskedofitarepairs(hi,xti),historiesalongwithnewcontexts.ThereareatmostTcontextsqueried,andatmostThistoriesonwhichLiisqueriedforafixedrunofouralgorithm(namely,prefixesofLi’sfinalhistory).Thus,thereareatmostT2queriesforLi.Thus,byaunionboundovertheseT2queriesforlearnerLi,bytheKWIKguarantee,P[Lifailsinsomeround]≤T2δ∗=3:fort=1,2,...do4:St←∅.Initializeactivesetofarms5:forj=1,2,...,kdo6:if∧m∈C∗jxFinally,weproveLemma12,whichweusedinSection6.1totranslatebetweenfairandKWIKlearningonconjunctions.ProofofLemma12.WemimicthestructureoftheproofofTheorem6,onceagainusingFair-ToKWIKto