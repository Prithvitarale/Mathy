FairnessinLearning:ClassicandContextualBanditsâˆ—MatthewJosephMichaelKearnsJamieMorgensternAaronRothâ€ November8,2016AbstractWeintroducethestudyoffairnessinmulti-armedbanditproblems.Ourfairnessdefinitioncanbeinterpretedasdemandingthatgivenapoolofapplicants(say,forcollegeadmissionormortgages),aworseapplicantisneverfavoredoverabetterone,despitealearningalgorithmâ€™suncertaintyoverthetruepayoffs.Weproveresultsoftwotypes:First,intheimportantspecialcaseoftheclassicstochasticbanditsproblem(i.e.inwhichtherearenocontexts),weprovideaprovablyfairalgorithmbasedonchainedconfidenceinter-vals,andproveacumulativeregretboundwithacubicdependenceonthenumberofarms.Wefurthershowthatanyfairalgorithmmusthavesuchadependence.Whencombinedwithregretboundsforstandardnon-fairalgorithmssuchasUCB,thisprovesastrongseparationbetweenfairandunfairlearning,whichextendstothegeneralcontextualcase.Inthegeneralcontextualcase,weproveatightconnectionbetweenfairnessandtheKWIK(KnowsWhatItKnows)learningmodel:aKWIKalgorithmforaclassoffunctionscanbetransformedintoaprovablyfaircontextualbanditalgorithm,andconverselyanyfaircontextualbanditalgorithmcanbetransformedintoaKWIKlearningalgorithm.ThistightconnectionallowsustoprovideContents1Introduction31.1FairnessandLearning................................1IntroductionAutomatedtechniquesfromstatisticsandmachinelearningareincreasinglybeingusedtomakedecisionsthathaveimportantconsequencesonpeopleâ€™slives,includinghiring[Miller,2015],lending[Byrnes,2016],policing[Rudin,2013],andevencriminalsentencing[Barry-Jesteretal.,jasrepresentingdifferentpopulations(e.g.differentethnicgroups,cultures,orotherdivisionswithinsociety),andviewthecontextxtjatroundtasrepresentinginformationaboutaparticularindividualfromthatpopulation.Eachpopulationhasitsownunderlyingfunctionfjwhichmapscontextstoexpectedpayoff2.Ateachtimestept,thealgorithmisaskedtochoosebetweenspecificmembersofeachpopulation,representedbythecontextsxtj.ThequalityofanindividualisthusexactlyEhrtji=fj(xtj).Ourfairnessconditiontranslatesthus:foranypairofarmsj,j0attimet,iffj(xtj)â‰¥fj0(xtj0),thenanalgorithmissaidtobediscriminatoryifitpreferentiallychoosesthelowerqualityarmj0.Saidanotherway,analgorithmisfairifitguaranteesthefollowing:withhighprobability,overallroundst,andforallpairsofarmsj,j0,wheneverfj(xtj)â‰¥fj0(xtj0),thealgorithmchoosesarmjwithprobabilityatleastthatwithwhichitchoosesarmj03.Itisworthnotingthatthisdefinitionoffairness(formalizedinthepreliminaries)isentirelyconsistentwiththeoptimalpolicy,whichcansimplychooseateachroundtoplayuniformlyatrandomfromthearmsargmaxjEhrtjiwhichmaximizetheexpectedreward.Thisisbecauseâ€“itseemsâ€“thegoaloffairnessasenunciatedaboveisentirelyconsistentwiththegoalofmaximizingexpectedreward.Indeed,thefairnessconstraintexactlystatesthatthealgorithmcannotfavorlowrewardarms!Ourmainconceptualresultisthatthisintuitionisincorrectinthefaceofunknownrewardfunctions.Eventhoughtheconstraintoffairnessisconsistentwithimplementingtheoptimalpolicy,itisnotnecessarilyconsistentwithlearningtheoptimalpolicy.Weshowthatfairnessalwayshasacost,intermsoftheachievablelearningrateofthealgorithm.Forsomeproblems,thecostismild,butforothers,thecostislarge.1.2OurResultsWedivideourresultsintotwoparts.First,westudytheclassicstochasticmulti-armedbanditproblem[LaiandRobbins,1985,KatehakisandRobbins,1995].Inthiscase,therearenocontexts,andeacharmihasafixedbutunknownaveragerewardÂµi.Notethatthisisaspecialcaseofthecontextualbanditprobleminwhichthecontextsarethesameeveryday.Inthissetting,ourfairnessconstraintspecializestorequirethatwithprobability1âˆ’Î´,foranypairofarmsi,jforwhichÂµiâ‰¥Âµj,atnoroundtdoesthealgorithmplayarmjwithprobabilityhigherthanthatwithwhichitplaysarmi.Notethateventhisspecialcasemodelsinterestingscenariosfromthepointofviewoffairnessinlearning.Itmodels,forexample,thecaseinwhichchoicesaremadebyaloanofficerafterapplicantshavebeencategorizedintokinternallyindistinguishableequivalenceclassesbasedontheirapplications.Withoutafairnessconstraint,itisknownthatitispossibletoguaranteenon-trivialregrettotheoptimalpolicyafteronlyT=O(k)manyrounds[Aueretal.,2002].InSection3,wegiveanalgorithmthatsatisfiesourfairnessconstraintandisabletoguaranteenon-trivialregretafterT=O(k3)rounds.WethenshowinSection4thatitisnotpossibletodobetterâ€“any2Itisnaturalthatdifferentpopulationsshouldhavedifferentunderlyingfunctionsâ€“forexample,inacollegeadmissionssetting,thefunctionmappingapplicationstocollegesuccessprobabilitymightweightSATscoreslessinawealthypopulationthatemploysSATtutors,andmoreinaworking-classpopulationthatdoesnotâ€“seeDworketal.[2012]formorediscussionofthisissueandMunozetal.[2016]forexamples.3Notethatthedefinitiondoesnotrequireequalityofoutcomesonapopulationwidebasis,alsoknownasstatisticalparity.Ifsomepopulationjislesscredit-worthyonaveragethananotherpopulationj0,wedonotnecessarilysaythatanalgorithmisdiscriminatoryifitendsupgivingfewerloanstoindividualsfrompopulationj.Ournotionofdiscriminationisonanindividualbasisâ€“itrequiresthatevenifpopulationjislesscreditworthyonaveragethanpopulationj0,ifithappensthatonsomeday,anindividualappearsfromfairlearningalgorithmcanbeforcedtoendureconstantper-roundregretforT=â„¦(k3)rounds.Thus,wetightlycharacterizetheoptimalregretattainablebyfairalgorithmsinthissetting,andformallyseparateitfromtheregretattainablebyalgorithmsabsentafairnessconstraint.Notethatthisalreadyshowsaseparationbetweenthebestpossiblelearningratesforcontextualbanditlearningwithandwithoutthefairnessconstraintâ€“thestochasticmulti-armedbanditproblemisaspecialcaseofeverycontextualbanditproblem,andforgeneralcontextualbanditproblems,itisalsoknownhowtogetnon-trivialregretafteronlyT=O(k)manyrounds[Agarwaletal.,2014,Beygelzimeretal.,2011,Chuetal.,2011].Wethenmoveontothegeneralcontextualbanditsettingandproveabroad1.3OtherRelatedWorkSeveralpapersstudytheproblemoffairnessinmachinelearning.Onelineofworkaimstogivealgorithmsforbatchclassificationwhichachievegroupfairnessotherwiseknownasequalityofoutcomes,statisticalparityâ€“oralgorithmsdefinedasfollows,whereÏ€trepresentsAâ€™sdistributiononarmsatroundt:XtEitâˆ—âˆ¼Ï€âˆ—(xt)hfitâˆ—(xtitâˆ—)iâˆ’Eitâˆ¼Ï€t"Xtfit(xtit)#=Regret(x1,...,xT).WehereafterrefertothisastheregretofA.TheoptimalpolicyÏ€âˆ—pullsarmswithhighestexpectationwithunknownmeanÂµj.AlearningalgorithmAchoosesanarmitinroundt,andobservestherewardrtitâˆ¼Ditforthearmthatitchose.Letiâˆ—âˆˆ[k]bethearmwithhighestexpectedreward:iâˆ—âˆˆargmaxiâˆˆ[k]Âµi.Thepseudo-regretofanalgorithmAonD1,...,Dkisnowjust:TÂ·Âµiâˆ—âˆ’Eitâˆ¼Ï€tï£®ï£°X0â‰¤tâ‰¤TÂµitï£¹ï£»=Regret(T,D1,...,Dk)Lethtâˆˆ([k]Ã—[0,1])tâˆ’1denotearecordofthetâˆ’1roundsexperiencedbythealgorithmsofar,representedbytâˆ’12-tuplesencodingthepreviousarmschosenandrewardsobserved.WewriteÏ€tj|httodenotetheprobabilitythatAchoosesarmjgivenhistoryht.Again,wewilloftendropthesuperscripttonthehistorywhenreferringtothedistributionoverarms:Ï€tj|h:=Ï€tj|ht.Î´-fairnessintheclassicbanditsettingspecializesasfollows:Definition2(Î´-fairnessintheclassicbanditssetting).AisÎ´-fairif,foralldistributionsD1,...,Dk,withprobabilityatleast1âˆ’Î´overthehistoryh,foralltâˆˆ[T]andallj,j0âˆˆ[k]:Ï€tj|h>Ï€tj0|honlyifÂµj>Âµj0.3FairClassicStochasticBandits:AnAlgorithmInthissection,wedescribeasimpleandintuitivemodificationofthestandardUCBalgorithm[Aueretal.,2002],calledFairBandits,provethatitisfair,andanalyzeitsregretbound.Thealgorithmanditsanalysishighlightakeyideathatisimportanttothedesignoffairalgorithmsinthissetting:thatofchainingconfidenceintervals.Intuitively,asaÎ´-fairalgorithmexploresdifferentarmsitmustplaytwoarmsj1andj2withequalprobabilityuntilithassufficientdatatodeduce,withconfidence1âˆ’Î´,eitherthatÂµj1>Âµj2orviceversa.FairBanditsdoesthisbymaintainingempiricalestimatesofthemeansofbotharms,togetherwithconfidenceintervalsaroundthosemeans.Tobesafe,thealgorithmmustplaythearmswithequalprobabilitywhiletheirconfidenceintervalsoverlap.Thesamereasoningappliessimultaneouslytoeverypairofarms.Thus,iftheconfidenceintervalsofeachpairofarmsjiandji+1overlapforeachiâˆˆ[k],thealgorithmisforcedtoplayallarmsjwithequalprobability.Thisisthecaseeveniftheconfidenceintervalsaroundarmjkandarmj1arefarfromoverlappingâ€“i.e.whenthealgorithmcanbeconfidentthatÂµj1>Âµjk.Thisapproachinitiallyseemsnaive:inanattempttoachievefairness,itseemsoverlyconser-vativewhenrulingoutarms,andcanbeforcedtoplayarmsuniformlyatrandomforlongperiodsoftime.Thisisreflectedinitsregretbound,whichisonlynon-trivialafterTk3,whereastheUCBalgorithm[Aueretal.,2002]achievesnon-trivialregretafterT=O(k)rounds.However,ourlowerboundinSection4showsthatanyfairalgorithmmustsufferconstantper-roundregretforTk3roundsonsomeinstances.WenowgiveanoverviewofthebehaviorofFairBandits.Ateveryroundt,FairBanditsidentifiesthearmitâˆ—=argmaxiutithathasthelargestupperconfidenceintervalamongsttheactivearms.Ateachroundt,wesayiislinkedtojif[`ti,uti]âˆ©[`tj,utj]6=âˆ…,andiischainedtojifiandjareinthesamecomponentofthetransitiveclosureofthelinkedrelation.FairBanditsplaysuniformlyatrandomamongallactivearmschainedtoarmitâˆ—.Initially,theactivesetcontainsallarms.Theactivesetofarmsateachsubsequentroundisdefinedtobethesetofarmsthatarechainedtothearmwitharmwiththehighestupperconfidenceboundatanyroundhavemeansthatarelowerthanthemeansofanychainedarms,andhencesucharmscanbesafelyremovedfromtheactiveset,nevertobeplayedagain.ThisFigure1:ConfidenceintervalsovertimeforthelowerboundinstanceoutlinedinSection4fork=10.LinescorrespondtoupperandlowerconfidenceboundsforeacharmandcutoffattheroundinwhichthearmLemma3.ConsideranyroundtandanyarmiâˆˆSt.Conditiononntiâ‰¥tkâˆ’rtln(2kt2Î´)2.Then,utiâˆ’`tiâ‰¤2vuuuutln(Ï€Â·t)2/3Î´2Â·tkâˆ’rtln(2kt2Î´)2=Î·(t).Finally,weprovetheboundonthetotalregretofthealgorithm,usingtheboundTheorem3.ThereisadistributionPoverk-arminstancesofthestochasticmulti-armedbanditproblemsuchthatanyfairalgorithmrunonPexperiencesconstantper-roundregretforatleastT=â„¦k3ln1Î´Lemma4.Considerthefollowingtwoexperiments:Inthefirst,letÂµiâˆ¼Piandr1i,...,rtiâˆ¼B(Âµi),andWdenotethejointdistributionon(ÂµWenowcalculateunderwhatconditionseither(a)Xâ‰¤Î´01âˆ’Î´0,or(b)Xâ‰¥1âˆ’Î´0Î´0.OneofthesemustholdifiisÎ´0-distinguished.Beforewedoso,weProofofTheorem3.AssumeAissomeÎ´-fairalgorithmwhereÎ´<1/8.FixT;weclaimthatwithprobabilityatleast12,foranyt=o(k3ln1Î´),tâ‰¤T,Ï€tj|ht=1kforallj.Sincethepayoffforuniformlyrandomplayisâ‰¤12+1k,whilethebestarmhaspayoffâ‰¥23,inanyroundtwhereÏ€ti|ht=Ï€ti0|htforalli,i0âˆˆ[k],thealgorithmsuffersâ„¦(1)regretinthatround.Lemma6impliesthat,withprobabilityatleast12overthedistributionoverhistoriesht,either(a)Ï€t0i|ht0=Ï€t0i0|ht0foralli,i0âˆˆ[k],t0â‰¤tor(b)htmustâˆš2Î´-distinguishsomearmi.Case(a)impliesourclaim.Incase(b),Lemma7statesthananarmiisâˆš2Î´-distinguishableonlyifTi=â„¦(k2ln1Î´).Wenowarguethatunlesst=â„¦(k3ln1Î´),Ti=o(k2ln1Î´),whichwillimplyourclaimforcase(b).Fixsomei,t.Welower-boundtforwhich,withprobabilityatleast1âˆ’Î´0koverhistoriesht,itwillbethecasethatntiâ‰¥cÂ·k2ln1Î´whenÏ€t0i|ht0=Ï€t0i0|ht0foralli,i0âˆˆ[k],t0â‰¤t.LetX1,...,Xtbeindicatorvariablesofarmibeingplayedinroundt0â‰¤t.Notethatforallt0â‰¤t,E[Xt0]=1k,sinceinallroundspriortot,wehaveallarmsareplayedwithequalprobability.Foranyâˆˆ[0,1],asnt0iarenondecreasingint0,anadditiveChernoffboundimpliesPâˆƒt0â‰¤t:nt0iâ‰¥tk+tâ‰¤Pï£®ï£°Xt0â‰¤tXt0>tk+tï£¹ï£»â‰¤eâˆ’2t2which,fort=qtln2kÎ´02,becomesPhPt0â‰¤tXt0>tk+tiâ‰¤Î´0k.So,usingaunionboundoverallkarms,withprobability1âˆ’Î´0,forsomefixedtandalli,ntiâ‰¤tk+qtln2kÎ´02.Weconditionontheeventthatntisatisfiesthisinequalityforafixedtandalli.Ifntiâ‰¥cÂ·k2ln1Î´,thisimpliestk+stln2kÎ´02â‰¥cÂ·k2ln1Î´â‡’tâ‰¥âˆ’kstln2kÎ´02+cÂ·k3ln1Î´.Ifkqtln2kÎ´02â‰¤c2Â·k3ln1Î´,thentâ‰¥c2Â·k3ln1Î´;ifnot,thentâ‰¥c22k4ln21Î´ln2kÎ´0.Thus,nti<cÂ·k2ln1Î´withprobability1âˆ’Î´0foralliunlesstâ‰¥minc2Â·k3ln1Î´,c22k4ln21Î´ln2kÎ´0=â„¦(k3ln1Î´)forÎ´0âˆˆ[12,1].5KWIKLearnabilityImpliesFairBanditLearnabilityInthissection,weshowifaclassoffunctionsisKWIKlearnable,thenthereisafairalgorithmforlearningthesameclassoffunctionsinthecontextualbanditsetting,witharegretboundpolynomiallyrelatedtothefunctionclassâ€™KWIKbound.Intuitively,KWIK-learnabilityofaclassoffunctionsguaranteeswecanlearnthefunctionâ€™sbehaviortoahighdegreeofaccuracywithahighdegreeofconfidence.Asfairnessconstrainsanalgorithmmostbeforethealgorithmhasdeterminedthepayofffunctionsâ€™behavioraccurately,thisguaranteeenablesustolearnfairlywithoutincurringmuchadditionalregret.Formally,weprovethefollowingpolynomialrelationship.Theorem4.Foraninstanceofthecontextualmulti-armedbanditproblemwherefjâˆˆCforalljâˆˆ[k],ifCis(,Î´)-KWIKlearnablewithboundm(,Î´),KWIKToFair(Î´,T)isÎ´-fairandachievesregretbound:R(T)=Omaxk2Â·mâˆ—,min(Î´,1/T)T2k,k3lnkÎ´forÎ´â‰¤1âˆšTwhereâˆ—=argminFirst,weconstructanalgorithmKWIKToFair(Î´,T)thatusestheKWIKlearningalgorithmasasubroutine,andprovethatitisÎ´-fair.AcalltoKWIKToFair(Î´,T)willinitializeaKWIKlearnerforeacharm,andineachWenowusetheKWIKboundsoftheKWIKlearnerstoupper-boundtheregretofKWIKTo-Fair(Î´,T).Lemma9.KWIKToFair(Î´,T)achievesregretO(max(k2Â·m(âˆ—,Î´âˆ—),k3lnTkÎ´)).Proof.Wefirstconditionontheeventthatboth(a)and(b)fromLemma8holdforallt,i,whichholdswithprobability1âˆ’min(Î´,1T),andboundtheregretwhentheybothhold.ChooseanarbitraryroundtinOurpresentationofKWIKToFair(Î´,T)hasaknowntimehorizonT.ItsguaranteesextendtothecaseinwhichTisunknownviathestandardâ€œdoublingtrickâ€toproveTheorem4inAppendixC.Animportantinstanceofplayedwithequalprobability,oneofthosecontextswillforceAtosufferâˆ—regret,sowecontinuethesimulationofAononeofthoseinstancesselectedatrandom,forcingatleastâˆ—/2regretinexpectation,andatthesametimehaveBreturnâŠ¥.Breceivesfâˆ—(xt)onsucharound,whichisusedtoconstructfeedbackforA.Otherwise,Amusttransitionfromplayingarm1withstrictlyhigherprobabilitytoplaying2withstrictlyhigherIfpt,`1â‰¤pt,`2forall`,since|Et|â‰¤1,eitherpt,01<pt,02orpt,11<pt,12,whichwehaveconditionedonimplyingthateitherfâˆ—(xt)<f(x(0))=0orfâˆ—(xt)<f(x(1))=âˆ—.Sincefâˆ—(xt)â‰¥0,thisimpliesfâˆ—(xt)âˆˆ[0,âˆ—)=[Ë†`âˆ—,âˆ—)=[yÌ‚t,yÌ‚t+âˆ—).Otherwise,wehavethatpt,Ë†`1>pt,Ë†`2,andpt,`1â‰¤pt,`2forall`>Ë†`.If(a)Ë†`=d1âˆ—e,thenfâˆ—(xt)>1,acontradiction,soË†`<d1âˆ—e.If(b)Ë†`=d1âˆ—eâˆ’1,thenfâˆ—(xt)>f(x(Ë†`))=(d1âˆ—eâˆ’1)âˆ—andsofâˆ—(xt)âˆˆ((d1âˆ—eâˆ’1)âˆ—,1]=(Ë†yt,yÌ‚t+âˆ—],soË†ytisâˆ—-accurate.Ifneither(a)nor(b),then(c)itmustbeË†`<d1âˆ—eâˆ’1.Since|Et|â‰¤1,forsome`âˆˆ{Ë†`+1,Ë†`+2},weknowthatpt,`1<pt,`2;thus,fâˆ—(xt)<f(x(`))â‰¤(Ë†`+2)âˆ—andthereforefâˆ—(xt)âˆˆ(Ë†`âˆ—,(Ë†`+Lemma12.SupposeAisaÎ´-fairalgorithmforthecontextualbanditproblemovertheclassCofconjunctionsondvariables.IfAhasregretboundR(T,Î´)thenforÎ´0=2TÎ´,FairToKWIKisan(0,ToonCaldersandSiccoVerwer.Threenaivebayesapproachesfordiscrimination-freeclassification.DataMiningandKnowledgeDiscovery,21(2):277â€“292,2010.WeiChu,LihongLi,LevReyzin,andRobertE.Schapire.Contextualbanditswithlinearpayofffunctions.InProceedingsoftheFourteenthInternationalConferenceonArtificialIntelligenceandStatistics,AISTATS2011,FortLauderdale,USA,April11-13,2011,pages208â€“214,2011.CaryCoglianeseandDavidLehr.Regulatingbyrobot:Administrativedecision-makinginthemachine-learningera.GeorgetownLawJournal,2016.Forthcoming.CynthiaDwork,MoritzHardt,ToniannPitassi,OmerReingold,andRichardZemel.Fairnessthroughawareness.InProceedingsofthe3rdInnovationsinTheoreticalComputerScienceConference,pages214â€“226.ACM,2012.MichaelFeldman,SorelleA.Friedler,JohnMoeller,CarlosScheidegger,andSureshVenkatasubramanian.Certifyingandremovingdisparateimpact.InProceedingsofthe21thACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandDataMining,Sydney,NSW,Australia,August10-13,2015,pages259â€“268,2015.BenjaminFish,JeremyKun,andAÌdaÌmDLelkes.Aconfidence-basedapproachforbalancingfairnessandaccuracy.SIAMInternationalSymposiumonDataMining,2016.FTCCommisionerJulieBrill.Navigatingtheâ€œtracklessoceanâ€:Fairnessinbigdataresearchanddecisionmaking.KeynoteAddressattheColumbiaUniversityDataScienceInstitute,April2015.ToshihiroKamishima,ShotaroAkaho,andJunSakuma.Fairness-awarelearningthroughregularizationapproach.InDataMiningWorkshops(ICDMW),2011IEEE11thInternationalConferenceon,pages643â€“650.IEEE,2011.AMissingProofsfortheClassicStochasticBanditsUpperBoundWebeginbyprovingLemma1,usedinSection3toprovethefairnessoftheFairBanditsalgo-rithm.ProofofLemma1.ChooseanarbitraryarmiandroundA.1MissingDerivationofR(T)forTheorem2R(T)â‰¤TXt:0min(1,kÂ·Î·(t))+1+Ï€2Î´Tâ‰¤TXt:0kÂ·min(1,Î·(t))+1+Ï€Thesecondexperimenthasjointprobability:P(Âµ0i,r1i,...,rti)âˆ¼W0(Âµ0i,r1i,...,rti)=(m,d1,Thus,withprobabilityatleast12overthedistributionoverhistoriesandmeans,PÂµ0âˆ¼P|hthtâˆˆunfair(A,Âµ0)â‰¤2Î´.However,Equation4showsthisdoesnotholdforanyhtwhichdoesnotâˆš2Î´-distinguishanyarmbutforwhichÏ€t0i|ht06=1kforsomeiâˆˆ[k],t0â‰¤t.Thus,foratleast12ofallprobabilitymassoverhistories,eitherÏ€t0i|ht0=1kforalli,t0â‰¤t,orhtmustâˆš2Î´-distinguishsomearm.CMissingProofsfortheContextualBanditSettingWebeginbyprovingtworesultsrelatedtoKWIKToFair.Thefirst,Lemma8,wasusedinSection5toprovethatKWIKToFairisÎ´-fairinTheorem5.ProofofLemma8.Wewillrefertoaviolationofeither(a)or(b)asafailureoflearnerLi.ForeachLi,thesetofqueriesaskedofitarepairs(hi,xti),historiesalongwithnewcontexts.ThereareatmostTcontextsqueried,andatmostThistoriesonwhichLiisqueriedforafixedrunofouralgorithm(namely,prefixesofLiâ€™sfinalhistory).Thus,thereareatmostT2queriesforLi.Thus,byaunionboundovertheseT2queriesforlearnerLi,bytheKWIKguarantee,P[Lifailsinsomeround]â‰¤T2Î´âˆ—=3:fort=1,2,...do4:Stâ†âˆ….Initializeactivesetofarms5:forj=1,2,...,kdo6:ifâˆ§mâˆˆCâˆ—jxFinally,weproveLemma12,whichweusedinSection6.1totranslatebetweenfairandKWIKlearningonconjunctions.ProofofLemma12.WemimicthestructureoftheproofofTheorem6,onceagainusingFair-ToKWIKto