HilbertSpaceEmbeddingsofHiddenMarkovModelsLeSonglesong@cs.cmu.eduByronBootsbeb@cs.cmu.eduSchoolofComputerScience,CarnegieMellonUniversity,Pittsburgh,PA15213,USASajidM.Siddiqisiddiqi@google.comGoogle,Pittsburgh,PA15213,USAGeoffreyGordonggordon@cs.cmu.eduSchoolofComputerScience,HilbertSpaceEmbeddingsofHiddenMarkovModelsorstructured;thespectralalgorithmdoesnotapplytosuchdatawithoutdiscretizationandflattening.So,thegoalofthecurrentpaperistoprovideanewkernel-basedrepresentationandkernelizedspectralHilbertSpaceEmbeddingsofHiddenMarkovModelsThenaturalquestionishowtochooseSsuchthatb1,b∞andBxcanbecomputedbasedpurelyonobserva-tionsequences,x1:t.Hsuetal.HilbertSpaceEmbeddingsofHiddenMarkovModelspropertyholdsformanycommonlyusedkernels(eg.theGaussianandLaplacekernelswhenX=Rd).Asaspecialcaseofthemeanmap,themarginalproba-bilityvectorofadiscretevariableXisaHilbertspaceembedding,i.e.(P(X=i))Mi=1=µX.Heretheker-nelisthedeltafunctionk(x,x0)=I[x=x0],andthefeaturemapisthe1-of-Mrepresentationfordiscretevariables(seesection2.2).Givenmi.i.d.observationsxlml=1,anestimateofthemeanmapisstraightforward:µ̂X:=1mPml=1ϕ(xl)=1mΥ1m,whereΥ:=(ϕ(x1),...,ϕ(xm))isaconceptualarrangementoffeaturemapsintocolumns.Further-more,thisestimatecomputesanapproximationwithinanerrorofOp(m−1/2)(Smolaetal.,2007).3.2.CovarianceoperatorsThecovarianceoperatorisageneralizationoftheco-variancematrix.GivenajointdistributionP(X,Y)overtwovariablesXonXandYonY1,theuncen-teredcovarianceoperatorCXYis(Baker,1973)CXY:=EXY[ϕ(X)⊗φ(Y)],(13)where⊗denotestensorproduct.Alternatively,CXYcansimplybeviewedasanembeddingofjointdis-tributionP(X,Y)usingjointfeaturemapψ(x,y):=ϕ(x)⊗φ(y)(intensorproductRKHSG⊗F).Fordis-cretevariablesXandYwithdeltakernelsonbothdo-mains,thecovarianceoperatorwillcoincidewiththejointprobabilitytable,i.e.(P(X=i,Y=j)Mi,j=1=CXY(alsoseesection2.2).Givenmpairsofi.i.d.observations(xl,yl)ml=1,wedenotebyΥ=ϕ(x1),...,ϕ(xm)andΦ=φ(y1),...,φ(ym).Conceptually,thecovarianceop-eratorCXYcanthenbeestimatedasˆCXY=1mΥΦ>.ThisestimatealsocomputesanapproximationwithinanerrorofOp(m−1/2)(Smolaetal.,2007).3.3.ConditionalembeddingoperatorsByanalogywiththeembeddingofmarginaldistribu-tions,theconditionaldensityP(Y|x)canalsoberep-resentedasanRKHSelement,µY|x:=EY|x[φ(Y)].WeemphasizethatµY|xnowtracesoutafamilyofembeddingsinG,witheachelementcorrespondingtoaparticularvalueofx.TheseconditionalembeddingscanbedefinedviaaconditionalembeddingoperatorCY|X:F7→G(Songetal.,2009),µY|x=CY|Xϕ(x):=CYXC−1XXϕ(x).(14)Fordiscretevariableswithdeltakernels,condi-tionalembeddingoperatorscorrespondexactlyto1akernell(y,y0)=hφ(y),φ(y0)iGisdefineonYwithassociatedRKHSG.conditionalprobabilitytables(CPT),i.e.(P(Y=i|X=j))Mi,j=1=CY|X,andeachindividualcondi-tionalembeddingcorrespondstoonecolumnoftheCPT,i.e.(P(Y=i|X=x))Mi=1=µY|x.Givenmi.i.d.pairs(xl,yl)ml=1fromP(X,Y),theconditionalembeddingoperatorcanbeestimatedasˆCY|X=ΦΥ>m(ΥΥ>m+λI)−1=Φ(K+λmI)−1Υ>(15)wherewehavedefinedthekernelmatrixK:=Υ>Υwith(i,j)thentryk(xi,xj).Theregularizationpa-rameterλistoavoidoverfitting.Songetal.(2009)alsoshowedµ̂Y|x−µY|xG=Op(λ1/2+(λm)−1/2).3.4.HilbertspaceobservablerepresentationWewillfocusontheembeddingµXt+1|x1:tforthepre-dictivedensityP(Xt+1|x1:t)ofaHMM.Analoguetothediscretecase,wefirstexpressµXt+1|x1:tasasetofHilbertspace‘observableoperators’Ax.Specifically,letthekernelsontheobservationsandhiddenstatesbek(x,x0)=hϕ(x),ϕ(x0)iFandl(h,h0)=hφ(h),φ(h0)iGrespectively.ForrichRKHSs,wedefinealinearoper-atorAx:G7→GsuchthatAxφ(ht)=P(Xt=x|ht)EHt+1|ht[φ(Ht+1)].(16)Then,byapplyingvariableelimination,wehaveµXt+1|x1:t=EHt+1|x1:tEXt+1|Ht+1[ϕ(Xt+1)]=CXt+1|Ht+1EHt+1|x1:t[φ(Ht+1)]=CXt+1|Ht+1AxtEHt|x1:t−1[φ(Ht)]=CXt+1|Ht+1Ytτ=1AxτµH1.(17)whereweusedthefollowingrecursiverelationEHt+1|x1:t[φ(Ht+1)]=EHt|x1:t−1P(Xt=xt|Ht)EHt+1|Ht[φ(Ht+1)]=AxtEHt|x1:t−1[φ(Ht)].(18)IfweletT:=CXt|Ht,O:=CXHilbertSpaceEmbeddingsofHiddenMarkovModelswherewehavedefinedC3,1|2:=CXt+2Xt|Xt+1.First,weexaminetherelationbetweentheseobservablequanti-tiesandtheunobservedO,Tandπ:µ1=EHtEXt|Ht[ϕ(Xt)]=CXt|HtEHt[φ(Ht)]=Oπ(22)C2,1=EHtEXt+1Ht+1|Ht[ϕ(Xt+1)]⊗EXt|Ht[ϕ(Xt)]=CXt+1|Ht+1CHt+1|HtCHtHtC>Xt|Ht=OTCHtHtO>(23)C3,x,1=EHtOAxTφ(Ht)⊗EXt|Ht[ϕ(Xt)]=OAxTCHtHtO>(24)In(24),wepluggedinthefollowingexpansionEXt+2Ht+2Ht+1(Xt+1=x)|Ht[ϕ(Xt+2)]=EHt+1|HtP(x|Ht+1)EHt+2|Ht+1EXt+2|Ht+2[ϕ(Xt+2)]=OAxTφ(Ht)(25)Second,analogoustothediscretecase,weperforma‘thin’SVDofthecovarianceoperatorC2,1,andtakeitstopNleftsingularvectorsU,suchthattheoper-atorU>Oisinvertible.Somesimplealgebraicmanip-ulationsestablishtherelationbetweenobservableandunobservablequantitiesβ1:=U>µ1=(U>O)π(26)β∞:=C2,1(U>C2,1)†=O(U>O)−1(27)Bx:=(U>C3,x,1)(U>C2,1)†=(UO)Ax(UO)−1.(28)Withβ1,β∞andBxt:1,µXt+1|x1:tcanbeexpressedasthemultiplicationofobservablequantitiesµXt+1|x1:t=β∞Bxt:1β1(29)Inpractice,C3,x,1(inequation(24))isdifficulttoes-timate,sinceitrequirespartitioningthetrainingsam-plesaccordingtoXt+1=x.Intead,weuseC3,1|2ϕ(x)whichdoesnotrequiresuchpartitioning,andisonlyafixedmultiplicativescalarP(x)awayfromC3,x,1.WedefineB̄x:=(U>(C3,1|2ϕ(x)))(U>C2,1)†,andwehaveµXt+1|x1:t∝β∞B̄xt:1β1.Wemaywanttopredictistepsintofuture,i.e.obtainembeddingsµXt+i|xt:1insteadofµXt+1|xt:1.Thiscanbeachievedbydefiningani-stepcovarianceoperatorCi+1,1:=EXt+iXt[ϕ(Xt+i)⊗ϕ(Xt)]andreplacingC2,1inβ∞(equation(27))byCi+1,1.WethenobtaintheembeddingµXt+i|xt:1∝βi∞B̄xt:1β1whereweuseβi∞todenoteCi+1,1(U>C2,1)†.3.5.KernelspectralalgorithmforHMMsGivenasampleofmi.i.d.triplets(xl1,xl2,xl3)ml=1fromaHMM,thekernelspectralalgorithmforHMMsproceedsbyfirstperforminga‘thin’SVDofthesamplecovarianceˆC2,1.Specifically,wedenotefea-turematricesΥ=(ϕ(x11),...,ϕ(xm1))andΦ=Algorithm1KernelSpectralAlgorithmforHMMsIn:mi.i.d.triples(xl1,xl2,xl3)ml=1,asequencex1:t.Out:µ̂Xt+1|xt:11:DenotefeaturematricesΥ=(ϕ(x11),...,ϕ(xm1)),Φ=(ϕ(x12)...ϕ(xm2))andΨ=(ϕ(x13)...ϕ(xm3)).2:ComputekernelmatricesK=Υ>Υ,L=Φ>Φ,G=Φ>ΥandF=Φ>Ψ.3:ComputetopNgeneralizedeigenvectorsαiusingLKLαi=ωiLαi(ωi∈Randαi∈Rm).4:DenoteA=(α1,...,αN),Ω=diag(ω1,...,ωN)andD=diag(α>1Lα1)−1/2,...,(α>NLαN)−1/2.5:β̂1=1mD>A>G1m6:β̂∞=ΦQwhereQ=KLADΩ−17:B̂xτ=P(xτ)mD>A>Fdiag(L+λI)−1Φ>ϕ(xτ)Q,forτ=1,...,t.8:µ̂Xt+1|xt:1=β̂∞B̂xt:1β̂1(ϕ(x12),...,ϕ(xm2)),andestimateˆC2,1=1mΦΥ>.Thentheleftsingularvectorv=Φα(α∈Rm)canbeestimatedasfollowsΦΥ>ΥΦ>v=ωv⇔ΦKLα=ωΦα⇔LKLα=ωLα,(α∈Rm,ω∈R)(30)whereK=Υ>ΥandL=Φ>Φarethekernelmatri-ces,andαisthegeneralizedeigenvector.Afternor-malization,wehavev=1√α>LαΦα.ThentheUoper-atorinequation(26),(27)and(28)isthecolumncon-catenationoftheNtopleftsingularvectors,i.e.Û=(v1,...,vN).IfweletA:=(α1,...,αN)∈Rm×NbethecolumnconcatenationoftheNtopαi,andD:=diag(α>1Lα1)−1/2,...,(α>NLαN)−1/2∈RN×N,wecanconciselyexpressÛ=ΦAD.Nextweestimateµ̂1=1mΥ1m,andaccordingto(26)β̂1=1mD>A>Φ>Υ1m.Similarly,accordingto(27)β̂∞=1mΦΥ>D>A>Φ>1mΦΥ>†=ΦKLADΩ−1,wherewehavedefinedΩ:=diag(ω1,...,ωN),andusedtherelationLKLA=LAΩandA>LA=D−2.LastdenoteΨ=ϕ(x13),...,ϕ(xm3),thenˆC3,1|2(·)=Ψdiag(L+λI)−1Φ>(·)KLADΩ−1in(21).ThekernelspectralalgorithmforHMMscanbesum-marizedinAlgorithm1.Notethatinthealgorithm,weassumethatthemarginalprobabilityP(xτ)(τ=1...t)isprovidedtothealgorithm.Inpractice,thisquantityisneverexplicitlyestimated.Therefore,thealgorithmreturnsβ̂∞B̄xHilbertSpaceEmbeddingsofHiddenMarkovModelslar,wewanttoinvestigatehowthedifferencebetweentheestimatedembeddingµ̂Xt+1|x1:tanditspopulationcounterpartscaleswithrespecttothenumbermoftrainingsamplesandHilbertSpaceEmbeddingsofHiddenMarkovModelsA.ExampleImagesEnvironmentPathB.0102030405060708090100345678x106PredictionHorizonAvg.PredictionErr.RR-HMMLDSHMMMeanLast2Embedded91Figure2.Robotvisiondata.(A)Sampleimagesfromtherobot’scamera.Thefigurebelowdepictsthehallwayenvi-ronmentwithacentralobstacle(black)andthepaththattherobottookthroughtheenvironment(theredcounter-clockwiseellipse).(B)Squarederrorforpredictionwithdifferentestimatedmodelsandbaselines.(underimperfecthumancontrol)(Figure2(A))and1500frameswereusedastrainingdataforeachmodel.Eachframefromthetrainingdatawasreducedto100dimensionsviaSVDonsingleobservations.Thegoalofthisexperimentwastolearnamodelofthenoisyvideo,and,afterfiltering,topredictfutureimageob-servations.Wetraineda50-dimensional2embeddedHMMus-ingAlgorithm1withsequencesof20consecutiveob-servations(Section3.8).GaussianRBFkernelsareusedandthebandwidthparameterissetwiththemedianofsquareddistancebetweentrainingpoints(mediantrick).Theregularizationparameterλissetof10−4.Forcomparison,a50-dimensionalRR-HMMwithParzenwindowsisalsolearnedwithsequencesof20observations(Siddiqietal.,2009);a50-dimensionalLDSislearnedusingSubspaceIDwithHankelmatri-cesof20timesteps;andfinallya50-statediscreteHMMandaxis-alignedGaussianobservationmodelsislearnedusingEMalgorithmrununtilconvergence.Foreachmodel,weperformedfiltering3fordifferentHilbertSpaceEmbeddingsofHiddenMarkovModelsCoefficients(MFCC)obtainedfromshortclipsofrawaudiodatarecordedusingaportablesensordevice.Sixclassesoflabeledaudioclipswerepresentinthedata,onebeingHumanspeech.ForthisexperimentwegroupedthelatterfiveclassesintoasingleclassofNon-humansoundstoformulateabinaryHumanvs.Non-humanclassificationtask.SincetheoriginaldatahadadisproportionatelylargeamountofHumanSpeechsamples,thisgroupingresultedinamorebal-anceddatasetwith40minutes11secondsofHumanand28minutes43secondsofNon-humanaudiodata.Toreducenoiseandtrainingtimeweaveragedthedataevery100timesteps(equivalentto1second).Foreachofthetwoclasses,wetrainedembeddedHMMswith10,20,.