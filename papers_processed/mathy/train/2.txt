JMLR:WorkshopandConferenceProceedingsvol23(2012)33.1â€“33.3425thAnnualConferenceonLearningTheoryAMethodofMomentsforMixtureModelsandHiddenMarkovModelsAnimashreeAnandkumarA.ANANDKUMAR@UCI.EDUUniversityofCalifornia,IrvineDanielANANDKUMARHSUKAKADEofstatisticalconsistencyundermildconditions.Unfortunately,themethodoftenrunsintotroublewithlargemixturesofhigh-dimensionaldistributions.Thisisbecausetheequationsdeterminingtheparametersaretypicallybasedonmomentsoforderequaltothenumberofmodelparameters,andhigh-ordermomentsareexceedinglydifficulttoestimateaccuratelyduetotheirlargevariance.Thisworkdevelopsacomputationallyefficientmethodofmomentsbasedononlylow-ordermomentsthatcanbeusedtoestimatetheparametersofabroadAMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSentlearningobjective)canbethoughtofasmodernimplementationsofthemethodofmoments,andtheirexponentialdependenceonkisnotsurprisinggiventheliteratureonothermomentmethodsformixturemodels.Inparticular,anumberofmomentmethodsforbothdiscreteandcontinuousmixturemodelshavebeendevelopedusingtechniquessuchastheVandermondedecompositionsofHankelmatrices(Lindsay,1989;LindsayandBasak,1993;Boleyetal.,1997;Gravinetal.,2012).Inthesemethods,followingthespiritofPearsonâ€™soriginalsolution,themodelparame-tersarederivedfromtherootsofpolynomialswhosecoefficientsarebasedonmomentsuptotheâ„¦(k)-thorder.Theaccurateestimationofsuchmomentsgenerallyhascomputationalandsamplecomplexityexponentialink.Spectralapproachtoparameterestimationwithlow-ordermoments.Thepresentworkisbasedonanotableexceptiontotheabovesituation,namelyChangâ€™sspectraldecompositiontechniquefordiscreteMarkovmodelsofevolution(Chang,1996)(seealsoMosselandRoch(2006)andHsuetal.(2009)foradaptationstootherdiscretemixturemodelssuchasdiscreteHMMs).Thisspectraltechniquedependsonlyonmomentsuptothethird-order;consequently,theresultingalgorithmshavecomputationalandsamplecomplexitythatscalesonlypolynomiallyinthenumberofmixturecomponentsk.Thesuccessofthetechniquedependsonacertainrankconditionofthetransitionmatrices;butthisconditionismuchmilderthanseparationconditionsofclusteringworks,anditremainssufficientevenwhenthedimensionoftheobservationspaceisverylarge(Hsuetal.,2009).Inthiswork,weextendChangâ€™sspectraltechniquetodevelopageneralmethodofmomentsapproachtoparameterestimation,whichisapplicabletoalargeclassofmixturemodelsandHMMswithbothdiscreteandcontinuouscomponentdistributionsinhigh-dimensionalspaces.LikethemomentmethodsofMoitraandValiant(2010)andBelkinandSinha(2010),ouralgorithmdoesnotrequireaseparationcondition;butunlikethosepreviousmethods,thealgorithmhascomputationalandsamplecomplexitypolynomialink.Somepreviousspectralapproachesforrelatedlearningproblemsonlyusesecond-ordermo-ments,buttheseapproachescanonlyestimateasubspacecontainingtheparametervectorsandnottheparametersthemselves(McSherry,2001).Indeed,itisknownthattheparametersofevenverysimplediscretemixturemodelsarenotgenerallyidentifiablefromonlysecond-ordermo-ments(Chang,1996)1.Wenotethatmomentsbeyondthesecond-order(specifically,fourth-ordermoments)havebeenexploitedinthemethodsofFriezeetal.(1996)andNguyenandRegev(2009)fortheproblemoflearningaparallelepipedfromrandomsamples,andthatthesemethodsareveryrelatedtotechniquesusedforindependentcomponentanalysis(HyvaÌˆrinenandOja,2000).Adapt-ingthesetechniquesforotherparameterestimationproblemsisanenticingpossibility.Multi-viewlearning.Thespectraltechniqueweemploydependsontheavailabilityofmultipleviews,andsuchamulti-viewassumptionhasbeenexploitedinpreviousworksonlearningANANDKUMARHSUKAKADEliterature(Dasgupta,1999;VempalaandWang,2002;ChaudhuriandRao,2008;Feldmanetal.,2005,2006);thecombinationofthisandanon-degeneracyassumptioniswhatallowsustoavoidthesamplecomplexitylowerboundofMoitraandValiant(2010)forGaussianmixturemodels.Themulti-viewassumptionalsonaturallyarisesinmanyapplications,suchasinmultimediadatawith(say)text,audio,andvideocomponents(BlaschkoandLampert,2008;Chaudhurietal.,2009);aswellasinlinguisticdata,wherethedifferentwordsinasentenceorparagraphareconsiderednoisypredictorsoftheunderlyingsemantics(Galeetal.,1992).Intheveinofthislatterexample,weconsiderestimationinasimplebag-of-wordsdocumenttopicmodelasawarm-uptoourgeneralmethod;eventhissimplermodelillustratesthepowerofpair-wiseandtriple-wise(i.e.,bigramandtrigram)statisticsthatwerenotexploitedbypreviousworksonmulti-viewlearning.1.2.OutlineSection2firstdevelopsthemethodofmomentsinthecontextofasimplediscretemixturemodelmotivatedbydocumenttopicmodeling;anexplicitalgorithmandconvergenceanalysisarealsoprovided.ThegeneralsettingisconsideredinSection3,wherethemainalgorithmanditsaccom-panyingcorrectnessandefficiencyguaranteearepresented.Applicationstolearningmulti-viewmixturesofGaussiansandHMMsarediscussedinSection4.Proofsandadditionaldiscussionareprovidedintheappendices.1.3.NotationsThestandardinnerproductbetweenvectors~uand~visdenotedbyh~u,~vi=~u>~v.Wedenotethep-normofavector~vbyk~vkp.ForamatrixAâˆˆRmÃ—n,weletkAk2denoteitsspectralnormkAk2:=sup~v6=~0kA~vk2/k~vk2,kAkFdenoteitsFrobeniusnorm,Ïƒi(A)denotethei-thlargestsingularvalue,andÎº(A):=Ïƒ1(A)/Ïƒmin(m,n)(A)denoteitsconditionnumber.Letâˆ†nâˆ’1:={(p1,p2,...,pn)âˆˆRn:piâ‰¥0âˆ€i,Pni=1pi=1}denotetheprobabilitysimplexinRn,andletSnâˆ’1:={~uâˆˆRn:k~uk2=1}denotetheunitsphereinRn.Let~eiâˆˆRddenotethei-thcoordinatevectorwhosei-thentryis1andtherestarezero.Finally,forapositiveintegern,let[n]:={1,2,...,n}.2.Warm-up:bag-of-wordsdocumenttopicmodelingWefirstdescribeourmethodofmomentsinthesimplercontextofbag-of-wordsmodelsfordocu-ments.ProofsoflemmasandtheoremsinthissectionaregiveninAppendixA.2.1.SettingSupposeadocumentcorpuscanbepartitionedbytopic,witheachdocumentbeingassignedasingletopic.Further,supposethewordsinadocumentaredrawnindependentlyfromamultinomialdistributioncorrespondingtothedocumentâ€™stopic.Letkbethenumberofdistincttopicsinthecorpus,dbethenumberofdistinctwordsinthevocabulary,and`â‰¥3bethenumberofwordsineachdocument(sothedocumentsmaybequiteshort).Thegenerativeprocessforadocumentisgivenasfollows:1.Thedocumentâ€™stopicisdrawnaccordingtothemultinomialdistributionspecifiedbytheprobabilityvector~w=(w1,w2AMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSvariablehsuchthatPr[h=j]=wj,jâˆˆ[k].2.Giventhetopich,thedocumentâ€™s`wordsaredrawnindependentlyANANDKUMARHSUKAKADE2.3.ObservableoperatorsandtheirspectralpropertiesThepair-wiseandtriple-wiseprobabilitiescanberelatedinawaythatessentiallyrevealsthecon-ditionalprobabilitymatrixM.Thisisachievedthroughamatrixcalledanâ€œobservableoperatorâ€.Similarobservableoperatorswerepreviouslyusedtocharacterizemultiplicityautomata(SchuÌˆtzenberger,1961;Jaeger,2000)and,morerecently,forlearningdiscreteHMMs(viaanoperatorparameteriza-tion)(Hsuetal.,2009).Lemma2AssumeCondition1.LetUâˆˆRdÃ—kandVâˆˆRdÃ—kbematricessuchthatbothU>MandV>Mareinvertible.ThenU>PairsVisinvertible,andforall~Î·âˆˆRd,theâ€œobservableoperatorâ€B(~Î·)âˆˆRkÃ—k,givenbyB(~Î·):=(U>Triples(~Î·)V)(U>PairsV)âˆ’1,satisfiesB(~Î·)=(U>M)diag(M>~Î·)(U>M)âˆ’1.ThematrixB(~Î·)iscalledâ€œobservableâ€becauseitisonlyafunctionoftheobservablevariablesâ€™jointprobabilities(e.g.,Pr[~x1=~ei,~x2=~ej]).Inthecase~Î·=~exforsomexâˆˆ[d],thematrixB(~ex)issimilar(inAMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSAlgorithmA1.Obtainempiricalfrequenciesofwordpairsandtriplesfromagivensampleofdocuments,andformthetables[PairsâˆˆRdÃ—dANANDKUMARHSUKAKADEDefinetheconditionalmeanvectorsas~Âµv,j:=E[~xv|h=j],vâˆˆ[`],jâˆˆ[k],andletMvâˆˆRdÃ—kbethematrixwhosej-thAMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSLemma6ConsiderthesettinganddefinitionsfromLemma5.LetÎ˜âˆˆRkÃ—kbeaninvertiblematrix,andlet~Î¸>iâˆˆRkbeitsi-throw.Moreover,foralliâˆˆ[k],letÎ»i,1,Î»i,2,...,Î»i,kdenotethekeigenvaluesofB1,2,3(U3~Î¸i)intheorderspecifiedbythematrixofANANDKUMARHSUKAKADECondition3ThereexistpositivescalarsN0,C1,2,C1,3,C1,2,3,andafunctionf(N,Î´)(decreasinginNandÎ´)suchthatforanyNâ‰¥N0andÎ´âˆˆ(0,1),1.PrhkPÌ‚a,bâˆ’Pa,bk2â‰¤Ca,bÂ·f(N,Î´)iâ‰¥1âˆ’Î´for{a,b}âˆˆ{{1,2},{1,3}},2.âˆ€~vâˆˆRd,PrhkPÌ‚1,2,3(~v)âˆ’P1,2,3(~v)k2â‰¤C1,2,3Â·k~vk2Â·f(N,Î´)iâ‰¥1âˆ’Î´.Moreover(fortechnicalconvenience),PÌ‚1,3isindependentofPÌ‚1,2,3(whichmaybeachieved,say,bysplittingasampleofsize2N).ForthediscretemodelssuchasthedocumenttopicmodelofSection2.1anddiscreteHMMs(Mos-selandRoch,2006;Hsuetal.,2009),Condition3holdswithN0=C1,2=C1,3=C1,2,3=1,andf(N,Î´)=(1+pln(1/Î´))/âˆšN.Usingstandardtechniques(e.g.,Chaudhurietal.(2009);Vershynin(2012)),theconditioncanalsobeshowntoholdformixturesofvariouscontinuousdistributionssuchasmultivariateGaussians.Nowwearereadytopresentthemaintheoremofthissection.Theorem7ThereexistsaconstantC>0suchthatthefollowingholds.Assumethethree-viewmixturemodelsatisfiesCondition2andCondition3.Pickanyâˆˆ(0,1)andÎ´âˆˆ(0,Î´0).Further,assumeÎ˜âˆˆRkÃ—kisanindependentrandomrotationmatrixdistributeduniformlyovertheStiefelmanifold{QâˆˆRkÃ—k:Q>Q=I}.IfthenumberofsamplesNsatisfiesNâ‰¥N0andf(N,Î´/k)â‰¤CÂ·mini6=jkM3(~eiâˆ’~ej)k2Â·Ïƒk(P1,2)C1,2,3Â·k5Â·Îº(M1)4Â·Î´ln(k/Î´)Â·,f(N,Î´)â‰¤CÂ·min(mini6=jkM3(~eiâˆ’~ej)k2Â·Ïƒk(P1,2)2C1,2Â·kP1,2,3k2Â·k5Â·Îº(M1)4Â·Î´ln(k/Î´),Ïƒk(P1,3)C1,3)Â·wherekP1,2,3k2:=max~v6=~0kP1,2,3(~v)k2,thenwithprobabilityatleast1âˆ’5Î´,AlgorithmBreturnsMÌ‚3=[ÂµÌ‚3,1|ÂµÌ‚3,2|Â·Â·Â·|ÂµÌ‚3,k]withthefollowingguarantee:thereexistsapermutationÏ„on[k]suchthatforeachjâˆˆ[k],kÂµÌ‚3,jâˆ’~Âµ3,Ï„(j)k2â‰¤maxj0âˆˆ[k]k~Âµ3,j0k2Â·.4.ApplicationsInadditiontothedocumentclusteringmodelfromSection2,anumberofnaturallatentvariablemodelsfitintothismulti-viewframework.Wedescribetwosuchcasesinthissection:GaussianmixturemodelsandHMMs,bothofwhichhavebeen(atleastpartially)studiedAMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSdistributionoftheobservedrandomvector~xgivenhisamultivariateGaussianwithmean~ÂµhandcovarianceÎ£h.Themulti-viewANANDKUMARHSUKAKADEandtheparametersoftheresultingthree-viewmixturemodelon(h,~x1,~x2,~x3)are~w:=T~Ï€,M1:=AMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSJ.Feldman,R.Oâ€™Donnell,andR.Servedio.PAClearningmixturesofaxis-alignedGaussianswithnoseparationassumption.InCOLT,2006.A.M.Frieze,M.Jerrum,andR.Kannan.Learninglineartransformations.InFOCS,1996.W.A.Gale,K.W.Church,andD.Yarowsky.Onesenseperdiscourse.In4thDARPASpeechandNaturalLanguageWorkshop,1992.N.Gravin,J.Lasserre,D.Pasechnik,andS.Robins.Theinversemomentproblemforconvexpolytopes.DiscreteandComputationalGeometry,2012.Toappear.H.Hotelling.Themostpredictablecriterion.JournalofEducationalPsychology,26(2):139â€“142,1935.D.Hsu,S.M.Kakade,andT.Zhang.AspectralalgorithmforlearninghiddenMarkovmodels.InCOLT,2009.D.Hsu,S.M.Kakade,andT.Zhang.AspectralalgorithmforlearninghiddenMarkovmodels.JournalofComputerandSystemSciences,2012.Toappear.A.HyvaÌˆrinenandE.Oja.Independentcomponentanalysis:algorithmsandapplications.NeuralNetworks,13(4â€“5):411â€“430,2000.H.Jaeger.Observableoperatormodelsfordiscretestochastictimeseries.NeuralComputation,12(6),2000.A.T.Kalai,A.Moitra,andG.Valiant.EfficientlylearningmixturesoftwoGaussians.InSTOC,2010.R.Kannan,H.Salmasian,andS.Vempala.Thespectralmethodforgeneralmixturemodels.InCOLT,2005.B.G.Lindsay.Momentmatrices:applicationsinmixtures.AnnalsofStatistics,17(2):722â€“740,1989.B.G.Lindsay.Mixturemodels:theory,geometryandapplications.AmericanStatisticalAssocia-tion,1995.B.G.LindsayandP.Basak.Multivariatenormalmixtures:afastconsistentmethod.JournaloftheAmericanStatisticalAssociation,88(422):468â€“476,1993.F.McSherry.Spectralpartitioningofrandomgraphs.InFOCS,ANANDKUMARHSUKAKADEh~x1~x2Â·Â·Â·~x`h1h2Â·Â·Â·h`~x1~x2~x`(a)(b)FigureAMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSsoPairs=Mdiag(~w)M>.Moreover,writing~Î·=(Î·1,Î·2,...,Î·d),Triples(~Î·)i,j=dXx=1Î·xPr[~x1=~ei,~x2=~ej,~x3=~ex]=dXx=1kXt=1Î·xÂ·Mi,tÂ·Mj,tÂ·Mx,tÂ·wt=kXt=1Mi,tÂ·Mj,tÂ·wtÂ·(M>~Î·)tsoTriples(~Î·)=Mdiag(M>~Î·)diag(~w)M>.A.2.ProofofLemma2Sincediag(~w)0byCondition1andU>PairsV=(U>M)diag(~w)M>VbyLemma1,itfollowsthatU>PairsVisinvertiblebytheassumptionsonUandV.Moreover,alsobyLemma1,B(~Î·)=(U>Triples(~Î·)V)(U>PairsV)âˆ’1=(U>Mdiag(M>~Î·)diag(~w)M>V)(U>PairsV)âˆ’1=(U>M)diag(M>~Î·)(U>M)âˆ’1(U>Mdiag(~w)M>V)(U>PairsV)âˆ’1=(U>M)diag(M>~Î·)(U>M)âˆ’1.A.3.AccuracyofmomentestimatesLemma9FixÎ´âˆˆ(0,1).Let[PairsbetheempiricalaverageofNindependentcopiesof~x1âŠ—~x2,andlet\TriplesbetheempiricalaverageofNindependentcopiesof(~x1âŠ—~x2)h~Î·,~x3i.Then1.Pr"k[Pairsâˆ’PairskFâ‰¤1+pln(1/Î´)âˆšN#â‰¥1âˆ’Î´,and2.Pr"âˆ€~Î·âˆˆRd,k\Triples(~Î·)âˆ’Triples(~Î·)kFâ‰¤k~Î·k2(1+pln(1/Î´))âˆšN#â‰¥1âˆ’Î´.ProofThefirstclaimfollowsfromapplyingLemma24tothevectorizationsof[PairsandPairs(whereupontheFrobeniusnormistheEuclideannormofthevectorizedmatrices).ForthesecondANANDKUMARHSUKAKADENowconditiononthisevent.Forany~Î·=(Î·1,Î·2,...,Î·d)âˆˆRd,k\Triples(~Î·)âˆ’Triples(~AMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSandÎº(R)â‰¤Îº(UÌ‚>M)2â‰¤k(1âˆ’Îµ21)Â·Ïƒk(M)2.(7)TheANANDKUMARHSUKAKADEBÌ‚(~eformat)BÌ‚(~egod)BÌ‚(~ekey)BÌ‚(~epolygon)BÌ‚(~eteam)BÌ‚(~etoday)sourcegodkeypolygonwingamefindwritebittimegametigerpostjesuschipsaverunbitimagechristiansystemreferteamrunfealchristencryptbookyearpitchintersectpeoplecarsourcedondayemailtimerepositorymanwatchteamrpiaprveroutinegoodtruetimesinpublicnetcomscorelotproblembibleAMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSB.2.ProofofLemma5WehaveU>1P1,2U2=(U>1M1)diag(~w)(M>2U2)byLemma4,whichisinvertiblebytheassump-tionsonUvandCondition2.Moreover,alsobyLemma4,B1,2,3(~Î·)=(U>1P1,2,3(~Î·)U2)(U>1P1,2U2)âˆ’1=(U>1M1diag(M>3~Î·)diag(~w)M>2U2)(U>1P1,2U2)âˆ’1=(U>1M1)diag(M>3~Î·)(U>1M1)âˆ’1(U>1M1diag(~w)M>2U2)(U>1P1,2U2)âˆ’1=(U>1M1)diag(M>3~Î·)(U>1M1)âˆ’1(U>1P1,2U2)(U>1P1,2U2)âˆ’1=(U>1M1)diag(M>3~Î·)(U>1M1)âˆ’1.B.3.ProofofLemma6ByLemma5,(U>1M1)âˆ’1B1,2,3(U3~Î¸i)(U>1M1)=diag(M>3U3~Î¸i)=diag(h~Î¸i,U>3M3~e1i,h~Î¸i,U>3M3~e2i,...h~Î¸i,U>3M3~eki)=diag(Î»i,1,Î»i,2,...,Î»i,k)foralliâˆˆ[k],andthereforeL=ï£®ï£¯ï£¯ï£¯ï£°h~Î¸1,U>3M3~e1ih~Î¸1,U>3M3~e2iÂ·Â·Â·h~Î¸1,U>3M3~ekih~Î¸2,U>3M3~e1ih~Î¸2,U>3M3~e2iÂ·Â·Â·h~Î¸2,ANANDKUMARHSUKAKADEB.5.EstimatingthemixingweightsGiventheestimateofMÌ‚3,onecanobtainanestimateof~wusingwÌ‚:=MÌ‚â€ 3EÌ‚[~x3]whereAâ€ denotestheMoore-PenrosepseudoinverseofA(thoughothergeneralizedinversesmayworkaswell),andEÌ‚[~x3]istheempiricalaverageof~x3.Thisestimatorisbasedonthefollowingobservation:E[~x3]=E[E[~x3|h]]=M3E[~eh]=M3~wandthereforeMâ€ 3E[~x3]=Mâ€ 3M3~w=~wsinceM3hasfullcolumnrank.B.6.ProofofTheorem7TheproofissimilartothatofTheorem3,sowejustdescribetheessentialdifferences.Asbefore,mostperturbationargumentsaredeferredtoAppendixC.First,letE1betheeventinwhichkPÌ‚1,2âˆ’P1,2k2â‰¤C1,2Â·f(N,Î´),kPÌ‚1,3âˆ’P1,3k2â‰¤C1,3Â·f(N,Î´)andkPÌ‚1,2,3(UÌ‚3~Î¸i)âˆ’P1,2,3(UÌ‚3~Î¸i)k2â‰¤C1,2,3Â·f(N,Î´/k)foralliâˆˆ[k].ThereforebyCondition3andaunionbound,wehavePr[E1]â‰¥1âˆ’3Î´.Second,letE2betheeventinwhichÎ³:=miniâˆˆ[k]minj6=j0|h~Î¸i,UÌ‚>3M3(~ejâˆ’~ej0)i|>minj6=j0kUÌ‚>3M3(~ejâˆ’~ej0)k2Â·Î´âˆšekk2kandÎ»max:=maxi,jâˆˆ[k]|h~Î¸i,UÌ‚>3M3~eji|â‰¤maxjâˆˆ[k]kM3~ejk2âˆšk1+p2ln(k2/Î´).Sinceeach~Î¸iisdistributeduniformlyoverSkâˆ’1,itfollowsfromLemma15andaunionboundthatPr[E2|E1]â‰¥1âˆ’2Î´.ThereforePr[E1âˆ©E2]â‰¥(1âˆ’3Î´)(1âˆ’2Î´)â‰¥1âˆ’5Î´.LetU3âˆˆRdÃ—kbethematrixoftopkorthonormalleftsingularvectorsofM3.ByLemma10andtheconditionsonN,wehaveÏƒk(UÌ‚>3U3)â‰¥1/2,andthereforeÎ³â‰¥mini6=i0kM3(~eiâˆ’~ei0)k2Â·Î´2âˆšekk2kandÎ»maxÎ³â‰¤âˆšek3(1+p2ln(k2/Î´))Î´Â·Îº0(M3)whereÎº0(M3AMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSLet~Î·i:=UÌ‚3~Î¸iforiâˆˆ[k].ByLemma10,UÌ‚>1P1,2UÌ‚2isinvertible,sowemaydefineBÌƒ1,2,3(~Î·i):=(UÌ‚>1P1,2,3(~Î·i)UÌ‚2)(UÌ‚>1P1,2UÌ‚2)âˆ’1.ByLemma5,BÌƒ1,2,3(~Î·i)=(UÌ‚>1M1)diag(M>3~Î·i)(UÌ‚>1M1)âˆ’1.AlsodefineR:=UÌ‚>1M1diag(kUÌ‚>1M1~e1k2,kUÌ‚>1MANANDKUMARHSUKAKADEAppendixC.PerturbationanalysisforobservableoperatorsThefollowinglemmaestablishestheaccuracyofapproximatingthefundamentalsubspaces(i.e.,therowandcolumnspaces)ofamatrixXbycomputingthesingularvaluedecompositionAMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSProofLetSÌ‚:=UÌ‚>XÌ‚VÌ‚andSÌƒ:=UÌ‚>XVÌ‚.ByLemma10,UÌ‚>XÌ‚VÌ‚isinvertible,Ïƒk(SÌƒ)â‰¥Ïƒk(UÌ‚>U)Â·Ïƒk(X)Â·Ïƒk(VÌ‚>V)â‰¥(1âˆ’Îµ21)Â·Ïƒk(X)(soSÌƒisalsoinvertible),andkSÌ‚âˆ’SÌƒk2â‰¤ANANDKUMARHSUKAKADErowofRÌ‚âˆ’1.Fixaparticulariâˆˆ[k].Since{~Î¾1,~Î¾2,...,~Î¾k}formsabasisforRk,wecanwriteË†Î¾i=Pkj=1ci,j~Î¾jforsomecoefficientsci,1,ci,2,...,ci,kâˆˆR.Wemayassumeci,iâ‰¥0(orelsewereplaceË†Î¾iwithâˆ’Ë†Î¾i).ThefactthatkË†Î¾ik2=k~Î¾jk2=1foralljâˆˆ[k]andthetriangleinequalityimply1=kË†Î¾ik2â‰¤ci,ik~Î¾ik2+Pj6=i|ci,j|k~Î¾jk2=ci,i+Pj6=i|ci,j|,andthereforekË†Î¾iâˆ’~Î¾ik2â‰¤|1âˆ’ci,i|k~Î¾ik2+Xj6=i|ci,jk~Î¾jk2â‰¤2Xj6=i|ci,j|againbythetriangleinequality.Therefore,itsufficestoshow|ci,j|â‰¤2kRâˆ’1k2Â·Îµ3forj6=itoprovethesecondclaim.ObservethatAË†Î¾i=A(Pki0=1ci,i0~Î¾i0)=Pki0=1ci,i0Î»i0~Î¾i0,andthereforekXi0=1ci,i0Î»i0~Î¾i0+(AÌ‚âˆ’A)Ë†Î¾i=AÌ‚Ë†Î¾i=Î»Ì‚iË†Î¾i=Î»ikXi0=1ci,i0~Î¾i0+(Î»Ì‚iâˆ’Î»i)Ë†Î¾i.Multiplyingthroughtheaboveequationby~Î¶>j,andusingthefactthat~Î¶>j~Î¾i0=1{j=i0}givesci,jÎ»j+~Î¶>i(AÌ‚âˆ’A)Ë†Î¾i=Î»ici,j+(Î»Ì‚iâˆ’Î»i)~Î¶>jË†Î¾i.Theaboveequationrearrangesto(Î»jâˆ’Î»i)ci,j=(Î»Ì‚iâˆ’Î»i)~Î¶>jË†Î¾i+~Î¶>j(Aâˆ’AÌ‚)Ë†Î¾iandtherefore|ci,j|â‰¤k~Î¶jk2Â·(|Î»Ì‚iâˆ’Î»i|+k(AÌ‚âˆ’A)Ë†Î¾ik2)|Î»jâˆ’Î»i|â‰¤kRâˆ’1k2Â·(|Î»Ì‚iâˆ’Î»i|+kAÌ‚âˆ’Ak2)|Î»jâˆ’Î»i|bytheCauchy-Schwarzandtriangleinequalitiesandthesub-multiplicativepropertyofthespectralnorm.Thebound|ci,j|â‰¤2kRâˆ’1k2Â·Îµ3thenfollowsfromthefirstclaim.Thethirdclaimfollowsfromstandardcomparisonsofmatrixnorms.ThenextlemmagivesperturbationboundsforestimatingtheeigenvaluesofsimultaneouslydiagonalizablematricesA1,A2,...,Ak.TheeigenvectorsRÌ‚aretakenfromaperturbationofthefirstmatrixA1,andarethensubsequentlyusedtoapproximatelydiagonalizetheperturbationsoftheremainingmatricesA2,...,Ak.Inpractice,onemayuseJacobi-likeprocedurestoapproximatelysolvethejointeigenvalueproblem.Lemma13LetA1,A2,...,AkâˆˆRkÃ—kbediagonalizablematricesthatarediagonalizedbythesamematrixinvertibleRâˆˆRkÃ—kwithunitlengthcolumnskR~ejk2=1,suchthateachAihaskdistinctrealeigenvalues:Râˆ’1AiR=diag(Î»i,1,Î»i,2,...,Î»i,k).LetAÌ‚1,AÌ‚2,...,AÌ‚kâˆˆRkÃ—kbegiven.DefineA:=maxikAÌ‚iâˆ’Aik2,Î³A:=miniminj6=j0|Î»i,jâˆ’Î»i,j0|,Î»max:=maxi,j|Î»i,j|,Îµ3:=Îº(R)Â·AÎ³A,andÎµ4:=4k1.5Â·kRâˆ’1k22Â·Îµ3.AssumeÎµ3<12andÎµ4<1.ThenthereexistsapermutationÏ„on[k]suchthatthefollowingholds.1.ThematrixAÌ‚1haskdistinctrealeigenvaluesÎ»Ì‚1,1,Î»Ì‚1,2,...,Î»Ì‚1,kâˆˆR,and|Î»Ì‚1,jâˆ’Î»1,Ï„AMETHODOFMOMENTSFORMIXTUREMODELSANDHMMS2.ThereexistsamatrixRÌ‚âˆˆRkÃ—kwhosej-thcolumnisarighteigenvectorcorrespondingtoÎ»Ì‚1,j,scaledsokRÌ‚~ejk2=1foralljâˆˆ[k],suchthatkRÌ‚âˆ’RÏ„k2â‰¤Îµ4kRâˆ’1k2,whereRÏ„isthematrixobtainedbypermutingthecolumnsofRwithÏ„.3.ThematrixRÌ‚isinvertibleanditsinversesatisfieskRÌ‚âˆ’1âˆ’Râˆ’1Ï„k2â‰¤kRâˆ’1k2Â·Îµ41âˆ’Îµ4;4.Foralliâˆˆ{2,3,...,k}andalljâˆˆ[k],the(j,j)-thelementofRÌ‚âˆ’1AÌ‚iRÌ‚,denotedbyÎ»Ì‚i,j:=~e>jRÌ‚âˆ’1AÌ‚iRÌ‚~ej,satisfies|Î»Ì‚i,jâˆ’Î»i,Ï„(j)|â‰¤1+Îµ41âˆ’Îµ4Â·1+Îµ4âˆškÂ·Îº(R)Â·Îµ3Â·Î³A+Îº(R)Â·11âˆ’Îµ4+1âˆškÂ·Îº(R)+1âˆškÂ·Îµ41âˆ’Îµ4Â·Îµ4Â·Î»max.IfÎµ4â‰¤12,then|Î»Ì‚i,jâˆ’Î»i,Ï„(j)|â‰¤3Îµ3Â·Î³A+4Îº(R)Â·Îµ4Â·Î»max.ProofThefirstandsecondclaimsfollowfromapplyingLemma12ANANDKUMARHSUKAKADEcontinuingfrom(13),|Î»Ì‚i,jâˆ’Î»i,Ï„(j)|isboundedas|Î»Ì‚i,jâˆ’Î»i,Ï„(j)|â‰¤kRâˆ’1k2Â·kRk2Â·A+kRâˆ’1k2Â·AÂ·4kÂ·kRâˆ’1k2Â·Îµ3+kRâˆ’1k2Â·Îµ41âˆ’Îµ4Â·AÂ·kRk2+kRâˆ’1k2Â·Îµ41âˆ’Îµ4Â·AÂ·4kÂ·kRâˆ’1k2Â·Îµ3+Î»maxÂ·kRâˆ’1k2Â·Îµ41âˆ’Îµ4Â·kRk2+Î»maxÂ·kRâˆ’1k2Â·4kÂ·kRâˆ’1kAMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSForthesecondclaim,applyLemma25withÎ²:=1+tandt:=p2ln(m/Î´)toobtainPr|h~Î¸,A~eii|â‰¥kA~eik2âˆšmÂ·(1+t)â‰¤exp121âˆ’(1+t)2+2ln(1+t)â‰¤exp121âˆ’(1+t)2+2t=eâˆ’t2/2=Î´/m.Thereforethesecondclaimfollowsbytakingaunionboundoveralliâˆˆ[m].AppendixD.ProofsanddetailsfromSection4Inthissection,weprovideomittedproofsanddetailsfromSection4.D.1.LearningmixturesofproductdistributionsInthissection,weshowhowtouseAlgorithmBwithmixturesofproductdistributionsinRnthatsatisfyanincoherenceconditiononthemeans~Âµ1,~Âµ2,...,~ÂµkâˆˆRnofkcomponentdistributions.Notethatproductdistributionsarejustaspecialcaseofthemoregeneralclassofmulti-viewdistri-butions,whicharedirectlyhandledbyAlgorithmB.Thebasicideaistorandomlypartitionthecoordinatesinto`â‰¥3â€œviewsâ€,eachofroughlythesamedimension.Undertheassumptionthatthecomponentdistributionsareproductdistributions,themulti-viewassumptionissatisfied.Whatremainstobecheckedisthatthenon-degeneracycondition(Condition2)issatisfied.Theorem16(below)showsthatitsufficesthattheoriginalmatrixofcomponentmeanshaverankkandsatisfythefollowingincoherencecondition.Condition4(Incoherencecondition)LetÎ´âˆˆ(0,1),`âˆˆ[n],andM=[~Âµ1|~Âµ2|Â·Â·Â·|~Âµk]âˆˆRnÃ—kbegiven;letM=USV>bethethinsingularvaluedecompositionofM,whereUâˆˆRnÃ—kisamatrixoforthonormalcolumns,S=diag(Ïƒ1(M),Ïƒ2(M),...,Ïƒk(M))âˆˆRkÃ—k,andVâˆˆRkÃ—kisorthogonal;andletcM:=maxjâˆˆ[n]nkÂ·kU>~ejk22.Thefollowinginequalityholds:cMâ‰¤932Â·bn/`ckÂ·ln`Â·kÎ´.NotethatcMisalwaysintheinterval[1,n/k];itissmallestwhentheleftsingularvectorsinUhaveÂ±1/âˆšnentries(asinaHadamardbasis),andlargestwhenthesingularvectorsarethecoordinateaxes.Roughlyspeaking,theincoherenceconditionrequiresthatthenon-degeneracyofamatrixMbewitnessedbymanyverticalblocksofM.Whentheconditionissatisfied,thenwithhighprobability,arandompartitioningofthecoordinatesinto`groupsinducesablockpartitioningofMinto`matricesM1,M2,...,M`(withroughlyequalnumberofrows)suchthatthek-thlargestsingularvalueofMvisnotmuchsmallerthanthatofM(foreachvâˆˆ[`]).ChaudhuriandRao(2008)showthatunderasimilarcondition(whichtheycallaspreadingcon-dition),arandompartitioningofthecoordinatesintotwoANANDKUMARHSUKAKADEthemeansofkcomponentdistributions.Theythenfollowthispreprocessingwithaprojectionbasedonthecorrelationsacrossthetwoviews(similartoCCA).However,theiroverallalgorithmrequiresaminimumseparationconditiononthemeansofthecomponentdistributions.Incontrast,AlgorithmBdoesnotrequireaminimumseparationconditionatallinthissetting.Theorem16AssumeCondition4holds.Withprobabilityatleast1âˆ’Î´,auniformlychosenrandompartitioningof[n]into`disjointsets[n]=I1âˆªI2âˆªÂ·Â·Â·âˆªI`,eachofsizeatleast|Iv|â‰¥329Â·cMÂ·kÂ·ln`Â·kÎ´,hasthefollowingproperty:foreachvâˆˆ[`],thematrixMvâˆˆR|Iv|Ã—kformedbyselectingtherowsofMindexedbyIvandscalingbypn/|Iv|,satisfiesÏƒk(Mv)â‰¥Ïƒk(M)/2.ProofFollowsfromLemma17(below)togetherwithaunionbound.Lemma17AssumeCondition4holds.Considerarandomsubset{J1,J2,...,Jd}âŠ†[n]ofsizedchosenuniformlyatrandomwithoutreplacement,andletfMbetherandomdÃ—kmatrixgivenbyfM:=rndÂ·ï£®ï£¯ï£¯ï£¯ï£°~e>J1M~e>J2M...~e>JdMï£¹ï£ºï£ºï£ºï£».Ifdâ‰¥329Â·cMÂ·kÂ·lnkÎ´,thenPrhÏƒk(fM)â‰¥Ïƒk(M)/2iâ‰¥1âˆ’Î´.ProofLet{I1,I2,...,Id}âŠ†[n]bearandomsubsetofsizedchosenuniformlyatrandomwithreplacement,andletcMbetherandomdÃ—kmatrixgivenbycM:=rndÂ·ï£®ï£¯ï£¯ï£¯ï£°~e>I1M~e>I2M...~e>IdMï£¹ï£ºï£ºï£ºï£».ByProposition18,foranyÏ„>0,Pr[Ïƒk(fM)<Ï„]â‰¤Pr[Ïƒk(cM)<AMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSNotethatÏƒk(cM)=qÎ»min(cM>cM).Foreachjâˆˆ[d],letXj:=nÂ·(U>~eIj)âŠ—(U>~eIj),socM>cM=nddXj=1(M>~eIj)âŠ—(M>~eIj)=VS1ddXj=1XjSV>andÎ»min(cM>cM)â‰¥Î»min(S)2Â·Î»min1ddXj=1Xj=Ïƒk(M)2Â·Î»min1ddXj=1Xj.ObservethatE[Xj]=nXi=1Pr[Ij=i]Â·nÂ·(U>~ei)âŠ—(U>~ei)=IandthatÎ»max(Xj)â‰¤nÂ·maxiâˆˆ[n]{kU>~eik22}=cMÂ·k,almostsurely.ByLemma26(aChernoffboundonextremaleigenvaluesofrandomsymmetricmatrices),Pr"Î»min1ddXj=1Xjâ‰¤14#â‰¤kÂ·eâˆ’d(3/4)2/(2cMk)â‰¤Î´.Theclaimfollows.Proposition18(Reductiontosamplingwithreplacement)ConsideranymÃ—nmatrixA.Foranytâˆˆ[m],leteAtbearandomtÃ—nsubmatrixofAformedbychoosingarandomsubsetoftrowsofAuniformlyatrandomwithoutreplacement;andletbAtbearandomtÃ—nsubmatrixofAformedbychoosingarandomsubsetoftrowsofAuniformlyatrandomwithreplacement.Fixanytâˆˆ[m]andÏ„>0.ThenPr[Ïƒn(eAt)<Ï„]â‰¤Pr[Ïƒn(bAt)<Ï„].ProofThisargumentissimilartoonegivenbyRecht(2009).WefirstprovethatPr[Ïƒn(eAt)<Ï„]isnon-increasingint.Foranyt0â‰¤t,considerthefollowingcouplingbetweeneAtandeAt0:1.First,sampletrowindicesin[m]uniformlyatrandomwithoutreplacement,andselectthoserowsinAtoformeAt.2.Then,giventhesetrowindices,choosetâˆ’t0ofthemuniformlyatrandomwithoutreplace-ment,andremovethemtoformeAt0.SinceÏƒn(eAt0)â‰¤Ïƒn(eAt),Ïƒn(eAt)<Ï„=â‡’Ïƒn(eAt0)<Ï„,andconsequentlyPr[Ïƒn(eAt)<Ï„]â‰¤Pr[Ïƒn(eAt0)<Ï„ANANDKUMARHSUKAKADENowweprovetheproposition.LetUniquetâˆˆ[t]bethenumberofdistinctrowindicesselectedtoformbAt.ThenPr[bAt<Ï„]=tAMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSwherecov(~x|h=j):=E[(~xvâˆ’E[~xv|h=j])âŠ—(~xvâˆ’E[~xv|h=j])|h=j]isassumedtobepositivedefinite.Usingstandardtechniques(e.g.,Vershynin(2012)),Condition3canbeshowntoholdundertheaboveconditionswiththefollowingparameters(forsomeuniversalconstantc>0):wmin:=minjâˆˆ[k]wjN0:=cÂ·Î±3/2(d+log(1/Î´))wminlogÎ±3/2(d+log(1/Î´))wminCa,b:=cÂ·maxnkcov(~xv|h=j)k1/22,kE[~xv|h=j]k2:vâˆˆ{a,b},jâˆˆ[k]o2C1,2,3:=cÂ·maxkcov(~xv|h=j)k1/22,kE[~xv|h=j]k2:vâˆˆ[3],jâˆˆ[k]o3f(N,Î´):=rk2log(1/Î´)N+sÎ±3/2plog(N/Î´)(d+log(1/Î´))wminN.D.4.RecoveringthecomponentcovariancesWhileAlgorithmBrecoversjustthemeansofthemixturecomponents,weremarkthataslightvariationcanbeusedtorecoverthecovariancesaswell.NotethatE[~xvâŠ—~xv|h]=(Mv~eh)âŠ—(Mv~eh)+Î£v,h=~Âµv,hâŠ—~Âµv,h+Î£v,hforallvâˆˆ[`].Forapairofvectors~Ï†âˆˆRdand~ÏˆâˆˆRd,definethematrixQ1,2,3(~Ï†,~Ïˆ)âˆˆRdÃ—doffourth-ordermomentsbyQ1,2,3(~Ï†,~Ïˆ):=E[(~x1âŠ—~x2)h~Ï†,~x3ih~Ïˆ,~x3i].Proposition19UnderthesettingofLemma5,thematrixgivenbyF1,2,3(~Ï†,~Ïˆ):=(U>1Q1,2,3(~Ï†,~Ïˆ)U2)(U>1P1,2U2)âˆ’1satisfiesF1,2,3(~Ï†,~Ïˆ)=(U>1M1)diag(h~Ï†,~Âµ3,tih~Ïˆ,~Âµ3,ti+h~Ï†,Î£3,t~Ïˆi:tâˆˆ[k])(U>1M1)âˆ’1andhenceisdiagonalizable(infact,bythesamematricesasB1,2,3(~Î·)).ProofAsintheproofofLemma4,itiseasytoshowthatQ1,2,3(~Ï†,~Ïˆ)=E[E[~x1|h]âŠ—E[~x2|h]h~Ï†,E[~x3âŠ—~x3|h]~Ïˆi]=M1E[~ehâŠ—~ehh~Ï†,(~Âµ3,hâŠ—~Âµ3,h+Î£3,h)~Ïˆi]M>2=M1diag(h~Ï†,~Âµ3,tih~Ïˆ,~Âµ3,ti+h~Ï†,Î£3,t~Ïˆi:tâˆˆ[k])diag(~w)M>2.TheclaimthenfollowsfromthesameargumentsusedintheproofofLemma5.D.5.ProofofProposition8TheconditionalindependencepropertiesfollowfromtheHMMconditionalindependenceassump-tions.Tochecktheparameters,observefirstthatPr[h1=i|h2=j]=Pr[h2=j|h1=i]Â·Pr[h1=i]Pr[h2=j]=Tj,iÏ€i(T~Ï€)ANANDKUMARHSUKAKADEbyBayesâ€™rule.ThereforeM1~ej=E[~x1|h2=j]=OE[~eh1|h2=j]=Odiag(~Ï€)T>diag(T~Ï€)âˆ’1~ej.Therestoftheparametersaresimilartoverify.AppendixE.GeneralresultsfrommatrixperturbationtheoryThelemmasinthissectionarestandardresultsfrommatrixperturbationtheory,takenfromStewartandSun(1990).Lemma20(Weylâ€™stheorem)AMETHODOFMOMENTSFORMIXTUREMODELSANDHMMSAppendixF.ProbabilityinequalitiesLemma24(Accuracyofempiricalprobabilities)Fix~Âµ=(Âµ1,Âµ2,...,ÂµnANANDKUMARHSUKAKADE1.~1>Q=~1>;2.MQâˆ’1,Qdiag(~w)M>diag(M~w)âˆ’1,andQ~whavenon-negativeentries;3.Qdiag(~w)Q>isadiagonalmatrix.Thenthemarginaldistributionover(x1,x2)isidenticaltothatinthecasewherethemodelhasparametersMÌƒ:=MQâˆ’1andwÌƒ:=Q~w.Asimpleexampleford=k=2canbeobtainedfromM:=p1âˆ’p1âˆ’pp,~w:=1/21/2,Q:=ï£®ï£°p1+âˆš1+4p(1âˆ’p)21âˆ’p1âˆ’âˆš1+4p(1âˆ’p)2ï£¹ï£»forsomepâˆˆ(0,1).Wetakep=0.25,inwhichcaseQsatisfiestheconditionsofProposition27,andM=0.250.750.750.25,~w=0.50.5,MÌƒ=MQâˆ’1â‰ˆ0.66140.11290.33860.8871,wÌƒ=Q~wâ‰ˆ0.70570.2943.Inthiscase,both(M,~w)and(MÌƒ,wÌƒ)giverisetothesamepair-wiseprobabilitiesMdiag(~w)M>=MÌƒdiag(wÌƒ)MÌƒ>â‰ˆ0.31250.18750.18750.3125.However,thetriple-wiseprobabilities,forÎ·=(1,0),differ:for(M,~w),wehaveMdiag(M>Î·)diag(~w)M>â‰ˆ0.21880.09380.09380.0938;whilefor(MÌƒ,