TechnicalReportUW-CSE-2018-12-02Technology-EnabledDisinformation:Summary,Lessons,andRecommendationsDecember2018JohnAkersGaganBansalGabrielCadamuroChristineChenQuanzeChenLucyLinPhoebeMulcaireRajalakshmiNandakumarMatthewRockettLucySimkoJohnTomanTongshuangWuEricZengBillZornFranziskaRoesner(franzi@cs.washington.edu)PaulG.AllenSchoolofComputerScience&EngineeringUniversityofWashingtonAbstractTechnologyisincreasinglyused—unintentionally(mis-information)orintentionally(disinformation)—tospreadfalseinformationatscale,withpotentiallybroad-reachingsocietaleffects.Forexample,technologyenablesincreas-inglyrealisticfalseimagesandvideos,andhyper-personaltargetingmeansdifferentpeoplemayseedifferentversionsofreality.ThisreportistheculminationofaPhD-levelspe-cialtopicscourse1inComputerScience&EngineeringattheUniversityofWashington’sPaulG.AllenSchoolinthefallof2018.Thegoalsofthiscourseweretostudy(1)howtechnologiesandtoday’stechnicalplatformsenableandsup-portthecreationandspreadofsuchmis-anddisinformation,aswellas(2)howtechnicalapproachescouldbeusedtomit-igatetheseissues.Inthisreport,wesummarizethespaceoftechnology-enabledmis-anddisinformationbasedonourin-vestigations,andthensurfaceourlessonsandrecommenda-tionsfortechnologists,researchers,platformdesigners,pol-icymakers,andusers.1IntroductionMisinformationisfalseinformationthatissharedwithnoin-tentionofharm.Disinformation,ontheotherhand,isfalseinformationthatissharedwiththeintentionofdeceivingtheconsumer[49,110].Thisphenomenon,alsoreferredtoasinformationpollution[110]orfalseorfakenews[54],isacriticalandcurrentissue.Thoughpropaganda,rumors,mis-leadingreporting,andsimilarissuesareage-old,ourcurrenttechnologicaleraallowsthesetypesofcontenttobecreatedeasilyandrealistically,andtospreadwithunprecedentedspeedandscale.Theconsequencesareseriousandfar-reaching,includingpotentialeffectsonthe2016U.S.elec-tion[33],distrustinvaccinations[9],murdersinIndia[16],andimpactsonthelivesofindividuals[50].1https://courses.cs.washington.edu/courses/cse599b/18au/Inthisreport,whichistheculminationofaPhD-levelspe-cialtopicscourse1inComputerScience&EngineeringattheUniversityofWashington’sPaulG.AllenSchoolinthefallof2018,weconsiderthephenomenonofmis/disinformationfromtheperspectiveofcomputerscience.Theoverallspaceiscomplicatedandwillrequirestudyfrom,andcollabora-tionsamong,researchersfrommanydifferentareas,includ-ingcognitivescience,economics,neuroscience,politicalsci-ence,psychology,publichealth,andsociology,justtonameafew.Astechnologists,wefocusedinthecourse,andthusinthisreport,onthetechnology.Weask(ed):whatistheroleoftechnologyintherecentplagueofmis-anddisinformation?Howhavetechnologiesandtechnicalplatformsenabledandsupportedthespreadofthiskindofcontent?And,critically,howcantechnicalapproachesbeusedtomitigatetheseis-sues—orhowdotheyfallshort?InSection2,wesummarizethestateoftechnologyinthemis/disinformationspace,includingreflectingonwhatisnewanddifferentfrompriorinformationpollutioncam-paigns(Section2.1),surveyingworkthatstudiescurrentmis/disinformationecosystems(Section2.2),andsummariz-ingtheunderlyingenablingtechnologies(specifically,falsevideo,targetingandtracking,andbots,inSection2.3),aswellasexistingeffortstocurbtheeffectivenessorspreadofmis/disinformation(Section2.4).Wethenstepbacktosummarizethelessonswelearnedfromourexploration(Sec-tion3.1)andthenmakerecommendationsparticularlyfortechnologists,researchers,andtechnicalplatformdesigners,aswellasforpolicymakersandusers(Section3.2).Ouroverarchingconclusionsaretwo-fold.First,astech-nologists,wemustbeconsciousofthepotentialnegativeim-pactsofthetechnologieswecreate,recognizethattheirde-signsarenotneutral,andtakeresponsibilityforunderstand-ingworktogetherwithexpertsinotherfieldstomakeprogressinaspacewheretheredonotseemtobeeasyanswers.2UnderstandingMis-andDisinformationAkeygoalofthisreportistoprovideanoverviewoftechnology-enabledmis/disinformation—whatisnew,whatishappening,howtechnologyenablesit,andhowtech-nologymaybeabletodefendagainstit—whichwedointhissection.Othershavealsowrittenrelatedandvalu-ablesummariesthatcontributedtoourunderstandingofthespaceandthatwerecommendtheinterestedreadercross-reference[49,54,63,110].2.1WhatIsNew?Whilepropagandaanditsilkarenotanewproblem,itisbecomingincreasinglyclearthattheriseoftechnologyhasservedtocatalyzethecreation,dissemination,andconsump-tionofmis/disinformationatscale.Herewebrieflydetail,fromatechnologystandpoint,themajorfactorsthathavecontributedtoourcurrentsituation:1.Democratizationofcontentcreation.Anyonecanstartawebsite,blog,Facebookpage,Twitteraccount,orsimilardiscussedhowthesecognitivebiasescanbeexploitedviatechnology,andsuchstrategiesarecommoninmarket-ing[89]andtraditionalpropaganda.Acommonsuchbiasis“confirmationbias”,bywhichpeoplepaymoreattentionandlendmorecredencetoinformationthatconfirmssome-thingtheyarealreadyinclinedtobelieve.Anotherexamplethatwillrecurinthisreportisthe“backfireeffect”,whichsuggeststhatwhenconfrontedwithfactsintendedtochangeaperson’sopinionorbeliefaboutsomething,thisconfronta-tioncanhavetheoppositeeffect,causingpeopletomorestronglyholdtheiroriginalbelief[59,70].Afullsurveyoftheseexploitablehumancognitive“vulnerabilities”,thoughoutsidethescopeofthisreport,isanimportantcomponentofunderstandingwhymis/disinformationcampaignsareef-fectiveandhow(not)tocombatthem.2.2MeasuringtheProblemWebeginbysurveyingworkthathasstudiedtoday’smis/disinformationecosystemsdirectly,attemptingtoquantita-tivelyandqualitativelyunderstandtheproblem.Understand-ingtheproblem—whoaretheadversaries,whoarethetar-gets,whatarethetechniquesused,andwhyaretheyeffec-tive—iscrucialforultimatelydevelopingeffectivedefenses.2.2.1EcosystemStudiesAnumberofacademicstudieshavenowexaminedvariousaspectsofthemis/disinformationecosystem.Manyofthesestudiesarecasestudiesfocusingonaparticularissue,cam-paign,ortimespan(e.g.,[4,40,92]).Somemoregeneralstudiesorsurveysexistaswell(e.g.,[63,97,115]).Wesum-marizesomeofthekeyfindingsfromthisworkhere.Techniques.Onerepeatedthemeinthisresearchisthatsourcesofmis/disinformationrelyonarangeoftechniquesintermsofsophistication.Forexample,astudyofdis-informationcampaignsembeddedinTwitterconversationsaroundBlackLivesMattersuggestedthatsocialmediaaccountsthatspreadmis/disinformationrangefromlow-effortspambots,toslightlymorehuman-seeming,semi-automatedaccountswithsomedegreeofhumansupervi-sion,topurelyhuman-runaccountsthatbuildlargefol-lowingsbeforeexploitingthetrustofthosesociallinkstospreadmis/disinformationwidely[4].Supportingthesere-sultsmorebroadly,Marwicketal.[63]provideapartialsur-veyofgroupsandmovementsthathavebeenparticularlyef-fectiveinmanipulatingthemediatospreadtheirmessages,usingmethodssuchas:impersonationofactiviststoexploitthetrustaspectofsocialnetworks,botpromotionofastoryonsocialmedia,andgovernment-fundedmediaoutlets.Structure.Understandinghowmis/disinformationcontentorinformationecosystemsdifferfromotherinformationecosystemscanpotentiallyhelpdetectthem.Forexample,astudyofalternatenewsmediacoverageoftheSyrianWhiteHelmetsfoundthatthesemediaoftencopycontentwithoutattribution;clustersofsourceswhichsharedarticlesrevealadensely-linkedalternativemediaclusterwhichislargelydisconnectedfromreputablenewsmedia[92].Consumers.Inadditiontounderstandingdisinformationcampaigns,ecosystemsstudiescanhelpusunderstandthebehaviorsofhumanconsumers.Forexample,astudyofthegeographicandtemporaltrendsoffakenewsconsumptionduringthe2016U.S.electionfoundacorrelationofaggre-gatevotingbehaviorwithconsumptionoffakenewsacrossstates[40](thoughthecausalityis,ofcourse,unclear).Moregenerally,evidencesuggests[97]thatusersbasetheirtrustinanarticleontheirtrustofthefriendwhotheysawshareit,i.e.,informationlocaltothem,ratherthanthesourceorupstreamlinksinthechainofshares.Further,peoplemistakenlybelievethattheytakethetrustworthinessofthesourceintoaccountmorethantheyactuallydo[63].Onsomeplatforms,designchoicesmeanthatmessagesmayspreadinawaythatobscuresthesource(e.g.,WhatsApp)orconcealsintermediatelinksinthechainbetweensourceandsharer(e.g.,Twitter).Thesedesignchoicesmaycontributetothespreadofmis/disinformationandcanmakeitdifficultforexternalresearcherstostudytheecosystem.2.2.2ToolsforMeasurementAmajorchallengeinconductingmeasurementstudiesofmis/disinformation,orofattemptingtocounteritbyfact-checkingindividualstories,isthatitrequiressignificantmanualeffort.Tohelpwiththisprocess,severaltools—forresearchers,journalists,and/orendusers—havebeendevel-opedtosurfacethesourcesandtrajectoriesofsharedcontentortofacilitatefactcheckingdirectly.Forexample,Hoaxy[71]isatoolthatcollectsandtracksmis/disinformationandcorrespondingfactcheckingeffortsonTwitter.Astudybyitscreators[84]foundthat,per-hapsunsurprisingly,factcheckingcontentissharedsignif-icantlylessthantheoriginalarticle.Inanotherstudy[85],itscreatorsusedHoaxytodemonstratethecentralroleofso-cialspambotsinthemis/disinformationecosystem—avalu-ableconclusion,asitsuggeststhatcurbingthesebotsmaybecrucialinthefightagainstmis/disinformation(seeSec-tion2.3.3).TwitterTrails[38]isarelatedtoolthatprovidesinforma-tionregardingtheorigin,burstcharacteristics,andpropaga-tionofcontentonTwitter.Theresultingvisualizationsarediscontinuedreal-timerumortracker)sufferfrombeingin-sufficientlyautomated.Additionally,insomecases,itisnotdirectlyclearhowthesurfacedinformationshouldbeusedbyresearchersorendusers,andworse,maybemisunder-stood[2].Finally,thesetoolsarealltargetedatTwitterbe-causeofitspublicnature;closedplatformslikeFacebookdonotsupportsimilarefforts.Theselimitationsarenotduetothelackofeffortorintentionbythetools’creatorsbutratherduetothereexistsnofullyreliablewayforuserstoavoidtracking.Targeting.Trackingcanbeandoftenisultimatelylever-agedtotargetparticularcontentatauser,e.g.,viaadver-tisementsonFacebookorembeddedinotherwebsites(e.g.,newssites).Researchershavefoundthatevenwhenadver-tisingplatformslikeFacebookprovidesometransparencyforusersaboutwhycertainadsaretargetedatthem,thein-formationprovidedisoverlybroadandvague[3],failingtoimproveusers’understandingreducethespreadandinfluenceoffakenews,and(2)readerstoselectreliablesourcesofinformation.Fakenewsdetectionisaspacewhereitistemptingtotrytojust“throwsomemachinelearningattheproblem”(e.g.,[18,73]).However,ourexplorationofthespacesug-geststhatbreakingfakenewsdetectiondownintomorecare-fullydefinedsub-problemsmaybemorerealisticandmean-ingfulatthispoint.Definition.Todetectfakenews,wefirstneedaformal,sultsoffakenewsdetectionbestbeincorporatedintotoolsorinterfacesforendusers?2.4.2UI/UXInterventionsResearchersandsocialmediaplatformshaveproposeduserexperienceinterventionstohelpusersdetectonlinemis/disinformationandreducetherateatwhichitspreads.Someofthesechangeshavealreadybeendeployedtousers,aswedescribehere.However,itisuncleartotheresearchcommunitywhethertheseinterventionshavebeeneffective.Labelingpotentialmis/disinformation.Oneapproachistousetheoutputof3.1LessonsDisinformationstemsfromavarietyofmotivationsandadversarialgoals,whichmaynecessitatedifferentsolutions.Therearemanydifferentmanifestationsofmis/disinformation,andmanydifferentactorincentivesandintentions[110].Thus,differentsolutionsmayberequiredfordifferentactorsormanifestations.Forexample,actorswithfinancialincentivesmaysharedisinformationtoin-creaseclick-throughprofitability,asinthecaseofFacebookclickbait[28]orfakenewsenterprisesinMacedonia[88].Identifyingthismotiveenablescombatingitbydemonetiz-ing3.2RecommendationsFinally,wesurfaceourrecommendations,organizedbystakeholder.3.2.1RecommendationsforTechnologistsandOtherDefendersBespecificaboutthegoalsthataparticulartechnicalso-lutionisintendingtoachieve.Ifone’sgoalistosolveaproblem,thenoneshouldfocusonthegoal,notthetechnol-ogyusedtosolveit.Agoodgoalisbothusefulandpos-sibletoachieve.AusefulexampleistheworkofStarbirdetal.[92],whichidentifiedausefultask(investigatingtheecosystem)andpublishedvaluabledataandinsightsasare-sult.AnotherpossiblyinstructivecomparisonisbetweentheFakeNewsChallenge[44],whichpushedforwardthestateoftheartonaspecificproblem(stancedetection)andother,moregeneralattemptsatfakenewsdetectionwithmachinelearning[18,73],whosegeneralapplicabilityandultimatelyeffectivenessmaybelimited.Doworkonsolvingtechnology-relatedsub-problems.Thoughtechnologyalonecannotsolvethewholeproblem,asdiscussed,therearetechnology-relatedsub-problemsthatareuseful.Exampletechnology-baseddirectionstoinvesti-gate(thoughnotanexhaustivelist)mayinclude:•Falsenewsdetectionbasedonprecisedefinitionsofuseful,solvablesub-problems;combiningthesesub-problemsintoalargerdetectionpipeline;andleverag-ingtheresultsofthisdetection(e.g.,tomeasureecosys-temsoreffectivelysurfaceinformationtoendusers).•“Chainofcustody”approachesforinformation.Forex-ample,forphotos,seeProofMode[42],TruePic[101],andPhotoProof[68].•Platform-basedorotherUI/UXinterventions:bothfor-mativeresearchtounderstandwhatis(not)effectiveandhowexistingdesignsdriveuserbehaviors,andde-velopingandevaluatingnewdesigns.•Continuedworkonbotdetectionandcharacterization,andonstrategiesforuserverification.Continuemeasurementstudiestounderstandtheecosys-tem.Successfuldefensesrequireadeepunderstandingoftheunderlyingecosystemscreating,spreading,andreactingtomis/disinformation.Tailorsolutionstospecifictypesofusers,content,and/oradversaries.Differentpartsofthespacemaynecessitatedifferentsolutions,asdiscussedabove.Considerwhatalternateincentiveormonetarystruc-turesforthewebmightbe,andhowtomakethoseareality.Thefinancialincentivesdrivingplatformprovidersandmanyadversariesarealsocoretothefunctioningofthemodernweb,e.g.,thesupportingoffreecontentandservicesviatargetedadvertisements.Thoughchallenging,wemustconsideralternatemodelsthatwillde-incentivizefinancially-basedmis/disinformationandbetteralignthein-centivesofplatformproviders,users,contentcreators,andmis/disinformationdefenders.Investinandstudyusereducationefforts.Skillslikecriticalthinkingandtheabilitytofactcheckaregoodde-fensesagainstmis/disinformationingeneral,butapplyingthembecomesmorechallengingastechnologyenablesmoresophisticatedandsubtlemis/disinformation.Weshouldex-plorehowtoeffectivelyteachusershowcurrenttechnologiescouldbeexploited,andhowtospottheseissues.Forexam-ple,thiscouldinclude:•Teachinguserstospotadsversusorganiccontent.•Teachinguserstobeawareofwhattechnologyiscapa-bleof(e.g.,screenshotscanbeeasilyfabricated,fakeportraitsandvideosmade,accountshacked).•Teachinguserstolookformarkersofbotaccountsandlow-credibilitystoriesandsources.•Teachinguserstospotmis/disinformationviaagame.•Balancingteachingskepticismwithteachinghowtobuildupknowledge.Theendgoalshouldnotbeforuserstosimplydistrusteverything.•Bringingdiscussionsofthistopicandpossibleinter-ventionsintothe“publicsquare”,suchasviatelevisionshows.Theremaybemodelsforthistypeofengage-mentand/orlessonstolearnfromotherattempts,suchastheLatvian“TheoryofLies”showonuncoveringdisinformation[23]orthebilingual“StopFake”showintheUkraine[93].Wealsorecommendfollowingascientificprocesstodevelopandevaluateeducationalinterventions.Researchersandoth-ersshouldtestandevaluatewhichspecificeducationalinter-ventionsactuallyhaveapositiveeffect.Avoidplacingtoomuchburdenonusers.Thougheduca-tionandsurfacingmoreinformationtouserscanbeapartofthesolution,itcancertainlynotbetheentiresolution.Tak-inglessonsfrom,forexample,theusablecomputersecuritycommunity(e.g.,[113]),solutionsthatincreasetheburdenontheuserandgetinthewayofauser’sprimarytask(inthiscase,interactingwiththeirsocialnetworkandconsumingin-formation)maybecircumvented,ignored,and/orultimatelyineffective.Thus,maybenefitallusers.Wediscussspecificsuggestionsfor(particularlysocialmedia)platformdesignersinthenextsection.Additionally,differentgeographicordemographicusergroupsmayinteractdifferentlywithmis/disinformationandinterventions.3.2.2RecommendationsforPlatformDesignersAcknowledgethatplatformdesignsarenotneutral.De-signersshouldrecognizethatsomedesignpatterns(whileusefulforuserengagement)couldhaveunintendedconse-quencesandleaveopeningsformis/disinformation.Mostprominently,patternsforgeneratingrevenue(tracking,adtargeting,andsoon)canandaremisusedbymaliciouspar-ties.Asanotherexample,Twitter’semphasisonausernameinsteadoftheunique“@handle”enablesattacksinwhichcompromised“verified”accountscanbeusedtomasquer-adeasotherprominentusers[46].PlatformdesignersareinauniquepositiontodirectlyFoundationalscienceisstillneededtounderstandthesepo-tentialdifferencesandtheirimpacts.3.2.4RecommendationsforPolicymakersConsiderpoliciesorregulationsthatmighthelpaligntheincentivesofplatformdeveloperstocombatingthemis/disinformation2016.https://www.bbc.com/news/blogs-trending-38156985.[6]BENSON,B.Cognitivebiascheatsheet,Sept.2016.https://betterhumans.coach.me/cognitive-bias-cheat-sheet-55a472476b18.[7]BOGHARDT,T.SovietBlocIntelligenceandItsAIDSDis-informationCampaign.StudiesinIntelligence53,4(2009).[8]BRAVE.Bravebrowser.https://brave.com/.[9]BRONIATOWSKI,D.A.,JAMISON,A.,QI,S.,ALKULAIB,L.,CHEN,T.,BENTON,A.,QUINN,S.C.,ANDDREDZE,M.WeaponizedHealthCommunication:TwitterBotsandRussianTrollsAmplifytheVaccineDebate.AmericanJour-nalofPublicHealth10810(2018),1378–1384.[10]CHESNEY,R.,ANDCITRON,D.K.DeepFakes:ALoom-ingChallengeforPrivacy,Democracy,andNationalSecu-rity.107CaliforniaLawReview(2019,Forthcoming);UofTexasLaw,PublicLawResearchPaperNo.692;UofMary-landLegalStudiesResearchPaperNo.2018-21(2018).[11]COLUMBIACOLLEGE.Realvs.fakenews:Detectinglies,hoaxesandclickbait.https://columbiacollege-ca.libguides.com/fake_news/avoiding.[12]CONFESSORE,N.,ANDDANCE,G.J.BattlingFakeAccounts,TwittertoSlashMillionsofFollowers,July2018.https://www.nytimes.com/2018/07/11/technology/twitter-fake-followers.html.[13]CRESCI,S.,PIETRO,R.D.,PETROCCHI,M.,SPOG-NARDI,A.,ANDTESCONI,M.Theparadigm-shiftofsocialspambots:Evidence,theories,andtoolsforthearmsrace.InInternationalConferenceonWorldWideWeb(WWW)(2017).[14]CYBENKO,G.,GIANI,A.,ANDTHOMPSON,P.Cognitivehacking:Abattleforthemind.IEEEComputer35(2002),[33]FARIS,R.M.,ROBERTS,H.,ETLING,B.,BOURASSA,N.,ZUCKERMAN,E.,ANDBENKLER,Y.Partisanship,Propaganda,andDisinformation:OnlineMediaandthe2016U.S.PresidentialElection.Tech.rep.,BerkmanKleinCenterforInternet&SocietyResearchPaper,2017.[34]FAZZINI,K.HowtheRussiansbrokeintotheDemocrats’email,andhowitcouldhavebeenavoided,July2018.https://www.cnbc.com/2018/07/16/how-russians-broke-into-democrats-email-mueller.html.[35]FEINSTEIN,D.Botdisclosureandaccountabil-ityactof2018.S.3127-115thCongress,June2018.https://www.congress.gov/bill/115th-congress/senate-bill/3127.[36]FERRARA,E.,VAROL,O.,DAVIS,C.A.,MENCZER,F.,ANDFLAMMINI,A.Theriseofsocialbots.Communica-tionsoftheACM59(2016),96–104.[37]FERREIRA,W.,ANDVLACHOS,A.Emergent:Anoveldata-setforstanceclassification.InNAACL-HLT(2016).[38]FINN,S.,METAXAS,P.T.,ANDMUSTAFARAJ,E.Inves-tigatingRumorPropagationwithTwitterTrails.Tech.rep.,arXiv:1411.3550,2014.[39]FLAXMAN,S.,GOEL,S.,ANDRAO,J.M.Filterbubbles,echochambers,andonlinenewsconsumption.PublicOpin-ionQuarterly80,S1(2016),298–320.[40]FOURNEY,A.,RÁCZ,M.Z.,R[60]MA,J.,GAO,W.,ANDWONG,K.-F.Detectrumorsinmi-croblogpostsusingpropagationstructureviakernellearn-ing.InACL(2017).[61]MALLONEE,L.Thatflag-burningNFLphotoisn’tfakenews,it’sameme,Oct.2017.https://www.wired.com/story/that-flag-burning-nfl-photo-isnt-fake-news-its-a-meme/.[62]MARCHAL,N.,NEUDERT,L.-M.,KOLLANYI,B.,HOWARD,P.N.,ANDKELLY,J.Polarization,Partisan-shipandJunkNewsConsumptionon[89]SMITH,J.67waystoincreaseconversionwithcog-nitivebiases.https://www.neurosciencemarketing.com/blog/articles/cognitive-biases-cro.htm#.[90]SNOPESMEDIAGROUP.Snopes.https://www.snopes.com/.[91]SOCIALSCIENCEONE.