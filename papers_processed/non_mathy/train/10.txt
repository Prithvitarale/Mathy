LayoutParser:AUnifiedToolkitforDeepLearningBasedDocumentImageAnalysisZejiangShen1,RuochenZhang2,MelissaDell3,BenjaminCharlesGermainLee4,JacobCarlson3,andWeining2Shenetal.classification[10,33],layoutdetection[34,19],tabledetection[22],andscenetextdetection[3].Ageneralizedlearning-basedframeworkdramaticallyreducestheneedforthemanualspecificationofcomplicatedrules,whichisthestatusquowithtraditionalmethods.IthasthepotentialtotransformtheDIApipelineandbenefitabroadspectrumoflarge-scaledocumentdigitizationprojects.However,thereareseveralpracticaldifficultiesfortakingadvantagesofrecentadvancesinDL-basedmethods:1)DLmodelsarenotoriouslyLayoutParser:AUnifiedToolkitforDL-BasedDIA3projectsthatrequireprecision,efficiency,androbustness,aswellassimpleandlight-weightdocumentprocessingtasksfocusingonefficacyandflexibility(Section5).LayoutParserisbeingactively4Shenetal.EfficientDataAnnotationCustomizedModelTrainingModelCustomizationDIAModelHubDIAPipelineSharingCommunityPlatformLayoutDetectionModelsDocumentImagesTheCoreLayoutParserLibraryOCRModuleStorage&VisualizationLayoutDataStructureFig.1:TheoverallarchitectureofLayoutParser.Foraninputdocumentimage,thecoreLayoutParserlibraryprovidesasetofoff-the-shelftoolsforlayoutdetection,OCR,visualization,andstorage,backedbyacarefullydesignedlayoutdatastructure.LayoutParseralsosupportshighlevelcustomizationviaefficientlayoutannotationandmodeltrainingfunctions.Theseimprovemodelaccuracyonthetargetsamples.ThecommunityplatformenablestheeasysharingofDIAmodelsandwholedigitizationpipelinestopromotereusabilityandreproducibility.Acollectionofdetaileddocumentation,tutorialsandexemplarprojectsmakeLayoutParsereasytolearnanduse.andTensorFlowHub[1].ItenablesthesharingofpretrainedmodelsaswellasfulldocumentprocessingpipelinesthatareuniquetoDIAtasks.Therehavebeenavarietyofdocumentdatacollectionstofacilitethedevel-opmentofDLmodels.SomeexamplesincludePRImA[2](magazinelayouts),PubLayNet[34](academicpaperlayouts),TableBank[16](tablesinacademicpapers),NewspaperNavigatorDataset[14,15](newspaperfigurelayouts)andHJDataset[27](historicalJapanesedocumentlayouts).AspectrumofmodelstrainedonthesedatasetsarecurrentlyavailableintheLayoutParsermodelzootosupportdifferentusecases.3TheCoreLayoutParserLibraryAtthecoreofLayoutParserisanoff-the-shelftoolkitthatstreamlinesDL-baseddocumentimageanalysis.Fivecomponentssupportasimpleinterfacewithcomprehensivefunctionalities:1)Thelayoutdetectionmodelsenableusingpre-trainedorself-trainedDLmodelsforlayoutdetectionwithjustfourlinesofcode.2)Thedetectedlayoutinformationisstoredinthecarefullyengineeredlayoutdatastructures,whichareoptimizedforefficiencyandversatility.3)Whennecessary,userscanemployexistingorcustomizedOCRmodelsviatheunifiedAPIprovidedintheOCRmodule.4)LayoutParsercomeswithasetofLayoutParser:AUnifiedToolkitforDL-BasedDIA5DatasetBaseModelLargeModelNotesPubLayNet[34]F/MMLayoutsofmodernscientificdocumentsPRImA[2]M-Layoutsofscannedmodernmagazinesand6Shenetal.Fig.2:Therelationshipbetweenthethreetypesoflayoutdatastructures.Coordinatesupportsthreekindsofvariation;TextBlockconsistsoftheco-ordinateinformationandextrafeatureslikeblocktext,LayoutParser:AUnifiedToolkitforDL-BasedDIA7OperationNameDescriptionblock.pad(top,bottom,right,left)Enlargethecurrentblockaccordingtotheinputblock.scale(fx,fy)Scalethecurrentblockgiventheratioinxandydirectionblock.shift(dx,dy)Movethecurrentblockwiththeshiftdistancesinxandydirectionblock1.isin(block2)Whetherblock1isinsideofblock2block1.intersect(block2)Returntheintersectedregionofblock1andblock2.Coordinatetypetobedeterminedbasedontheinputs.block1.union(block2)Returntheunionregionofblock1andblock2.Coordinatetypetobedeterminedbasedontheinputs.block1.relativeto(block2)Converttheabsolutecoordinatesofblock1torelativecoordinatestoblock2block1.conditionon(block2)Calculatetheabsolutecoordinatesofblock1giventhecanvasblock2’sabsolutecoordinatesblock.cropimage(image)Obtainthe8Shenetal.3.3OCRLayoutParserprovidesaunifiedinterfaceforexistingOCRtools.ThoughtherearemanyOCRtoolsavailable,theyareusuallyconfigureddifferentlywithdistinctAPIsorprotocolsforusingthem.LayoutParser:AUnifiedToolkitforDL-BasedDIA9Fig.3:LayoutdetectionandOCRresultsvisualizationgeneratedbytheLayoutParserAPIs.ModeIdirectlyoverlaysthelayoutregionboundingboxesandcategoriesovertheoriginalimage.ModeIIrecreatestheoriginaldocumentviadrawingtheOCR’dtextsattheircorrespondingpositionsontheimagecanvas.Inthisfigure,tokensintextualregionsarefilteredusingtheAPIanddisplayed.canalsobehighlysensitiveandnotsharablepublicly.Toovercomethesechal-lenges,LayoutParserisbuiltwithrichfeaturesforefficientdataannotationandcustomizedmodeltraining.LayoutParserincorporatesarecenttoolkitoptimizedforannotatingdocu-mentlayoutsusingobject-levelactivelearning[28].Withthehelpfromalayoutdetectionmodeltrainedalongwithlabeling,onlythemostimportantlayoutobjectswithineachimage,ratherthanthewholeimage,arerequiredforlabel-ing.Therestoftheregionsareautomaticallyannotatedwithhighconfidencepredictionsfromthelayoutdetectionmodel.Thisallowsalayoutdatasettobecreatedmoreefficientlywithonlyaround60%ofthelabelingbudget.Afterthetrainingdatasetiscurated,LayoutParsersupportsdifferentmodesfortrainingthelayoutmodels.Fine-tuningcanbeusedfortrainingmodelsonanewly-labeledsmalldatasetbyinitializingthemodelwithexistingpre-trainedweights.Trainingfromscratchcanbehelpfulwhenthesourcedatasetandtar-getaresignificantlydifferentandalargetrainingsetisavailable.However,assuggestedin[29],loadingpre-trainedweightsonlarge-scaledatasetslikeIma-geNet[4],evenfromtotallydifferentdomains,canstillboostmodelperformance.Throughtheintegrated10Shenetal.4LayoutParserCommunityPlatformAnotherfocusofLayoutParserispromotingthereusabilityoflayoutdetectionmodelsandthewholedigitizationpipeline.Similartomanyexistingdeeplearninglibraries,LayoutParsercomeswithLayoutParser:AUnifiedToolkitforDL-BasedDIA11Fig.4:IllustrationofahistoricalJapanesedocumentshowingthecolumnandtokenboundingboxesandcategories(color)detectedbythelayoutmodels.Fig.5:Illustrationofarecreateddocumentimagethatachievesamuchbettercharacterrecognitionrecallrate.Thereorganizationalgorithmrearrangesthetokensbasedonthetheirdetectedboundingboxesgivenamaximumallowedheight.Japanesefirmfinancialtableswithcomplicatedlayouts.ItappliestwolayoutmodelstoidentifydifferentlevelsofdocumentstructuresandtwocustomizedOCRenginesforoptimizedcharacterrecognitionaccuracy.AsshowninFigure4,thedocumentcontainscolumnsoftextwrittenverti-cally13,acommonstyleinJapanese.Duetoscanningnoiseandarchaicprintingtechnology,thecolumnscanbeskewedorhavevariablewidththatcannotbeeasilyidentifiedviarule-basedmethods.Withineachcolumn,wordsareseparatedbywhitespacesofvariablesize,andtheverticalpositionsofobjectscanbeanindicatorfortheirlayouttype.Todecipherthecomplicatedlayoutstructure,twoobjectdetectionmodelshavebeentrainedtorecognizeindividualcolumnsandtokens,respectively.Asmalltrainingset(400imageswithapproximately100annotationseach)iscuratedviatheactivelearningbasedannotationtool[28]inLayoutParser.Themodelslearntoidentifyboththecategoriesandregionsforeachcolumn(token)viatheirdistinctvisualfeatures.Thelayoutdatastructureenableseasygroupingofthetokenswithineachcolumn,andrearrangingcolumnstoachievethecorrectreadingordersbasedonthehorizontalposition.Errorsareidentifiedandrectifiedviacheckingtheconsistencyofthemodelpredictions.Therefore,thoughtrainedonasmalldataset,thepipelineachievesahighleveloflayoutdetectionaccuracy:itachievesa96.97AP[17]scoreacross5categoriesforthecolumndetectionmodel,anda89.23APacross4categoriesforthetokendetectionmodel.13Adocumentpageconsistsofeightrowslikethis.Forsimplicityweskiptherowsegmentationdiscussionandreferreaderstothesourcecodewhenavailable.12Shenetal.Acombinationofcharacterrecognitionmethodsisdevelopedtotackletheuniquechallengesinthisdocument.Inourexperiments,wefindthatirregularspacingbetweenthetokensleadstolowcharacterLayoutParser:AUnifiedToolkitforDL-BasedDIA13Fig.6:Thislightweighttabledetectorcanidentifytables(outlinedinred)andcells(shadedinblue)indifferentlocationsonapage.Inveryfewcases(d),itmightgenerateminorerrorpredictions,e.g,failingtocapturethetoptextlineofatable.PDFimage.MaskR-CNN[11]trainedonthePubLayNetdataset[34]fromtheLayoutParserModelZoocanbeusedfordetectingtableregions.Byfilteringoutmodelpredictions14Shenetal.References[1]Abadi,M.,Agarwal,A.,Barham,P.,Brevdo,E.,Chen,Z.,Citro,C.,Corrado,G.S.,Davis,A.,Dean,J.,Devin,M.,Ghemawat,S.,Goodfellow,I.,Harp,A.,Irving,G.,Isard,M.,Jia,Y.,Jozefowicz,R.,Kaiser,L.,Kudlur,M.,Levenberg,J.,Mané,D.,Monga,R.,Moore,S.,Murray,D.,Olah,C.,Schuster,M.,Shlens,J.,Steiner,B.,Sutskever,I.,Talwar,K.,Tucker,P.,Vanhoucke,V.,Vasudevan,V.,Viégas,F.,Vinyals,O.,Warden,P.,Wattenberg,M.,Wicke,M.,Yu,Y.,Zheng,X.:TensorFlow:Large-scalemachinelearningonheterogeneoussystems(2015),https://www.tensorflow.org/,softwareavailablefromtensorflow.org[2]Antonacopoulos,A.,Bridson,D.,Papadopoulos,C.,Pletschacher,S.:Arealisticdatasetforperformanceevaluationofdocumentlayoutanalysis.In:200910thInternationalConferenceonDocumentAnalysisandRecognition.pp.296–300.IEEE(2009)[3]Baek,Y.,Lee,B.,Han,D.,Yun,S.,Lee,H.:Characterregionawarenessfortextdetection.In:ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition.pp.9365–9374(2019)[4]Deng,J.,Dong,W.,Socher,R.,Li,L.J.,Li,K.,Fei-Fei,L.:ImageNet:ALarge-ScaleHierarchicalImageDatabase.In:CVPR09(2009)[5]Deng,Y.,Kanervisto,A.,Ling,J.,Rush,A.M.:Image-to-markupgenerationwithcoarse-to-fineattention.In:InternationalConferenceonMachineLearning.pp.980–989.PMLR(2017)[6]Ganin,Y.,Lempitsky,V.:Unsuperviseddomainadaptationbybackpropagation.In:Internationalconferenceonmachinelearning.pp.1180–1189.PMLR(2015)[7]Gardner,M.,Grus,J.,Neumann,M.,Tafjord,O.,Dasigi,P.,Liu,N.,Peters,M.,Schmitz,M.,Zettlemoyer,L.:Allennlp:Adeepsemanticnaturallanguageprocessingplatform.arXivpreprintarXiv:1803.07640(2018)[8]LukaszGarncarek,Powalski,R.,Stanislawek,T.,Topolski,B.,Halama,P.,Graliński,F.:Lambert:Layout-aware(language)modelingusingbertforin-formationextraction(2020)[9]Graves,A.,Fernández,S.,Gomez,F.,Schmidhuber,J.:Connectionisttemporalclassification:labellingunsegmentedsequencedatawithrecurrentneuralnetworks.In:Proceedingsofthe23rdinternationalconferenceonMachinelearning.pp.369–376(2006)[10]Harley,A.W.,Ufkes,A.,Derpanis,K.G.:Evaluationofdeepconvolutionalnetsfordocumentimageclassificationandretrieval.In:201513thInternationalConferenceonDocumentAnalysisandRecognition(ICDAR).pp.991–995.IEEE(2015)[11]He,K.,Gkioxari,G.,Dollár,P.,Girshick,R.:Maskr-cnn.In:ProceedingsoftheIEEEinternationalconferenceoncomputervision.pp.2961–2969(2017)[12]He,K.,Zhang,X.,Ren,S.,Sun,J.:Deepresiduallearningforimagerecognition.In:ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.pp.770–778(2016)[13]Kay,A.:Tesseract:Anopen-sourceopticalcharacterrecognitionengine.LinuxJ.2007(159),2(Jul2007)[14]Lee,B.C.,Weld,D.S.:Newspapernavigator:Openfacetedsearchfor1.5millionimages.In:AdjunctPublicationofthe33rdAnnualACMSym-posiumonUserInterfaceLayoutParser:AUnifiedToolkitforDL-BasedDIA15[15]Lee,B.C.G.,Mears,J.,Jakeway,E.,Ferriter,M.,Adams,C.,Yarasavage,N.,Thomas,D.,Zwaard,K.,Weld,D.S.:TheNewspaperNavigatorDataset:ExtractingHeadlinesandVisualContentfrom16MillionHistoricNewspaperPagesinChroniclingAmerica,p.3055–3062.AssociationforComputingMachinery,NewYork,NY,USA(2020),https://doi.org/10.1145/3340531.3412767[16]Li,M.,Cui,L.,Huang,S.,Wei,F.,Zhou,M.,Li,Z.:Tablebank:Tablebenchmarkforimage-basedtabledetectionandrecognition.arXivpreprintarXiv:1903.01949(2019)[17]Lin,T.Y.,Maire,M.,Belongie,S.,Hays,J.,Perona,P.,Ramanan,D.,Dollár,P.,Zitnick,C.L.:Microsoftcoco:Commonobjectsincontext.In:Europeanconferenceoncomputervision.pp.740–755.Springer(2014)[18]Long,J.,Shelhamer,E.,Darrell,T.:Fullyconvolutionalnetworksforsemanticsegmentation.In:ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.pp.3431–3440(2015)[19]Oliveira,S.A.,Seguin,B.,Kaplan,F.:dhsegment:Agenericdeep-learningapproachfordocumentsegmentation.In:201816thInternationalConferenceonFrontiersinHandwritingRecognition(ICFHR).pp.7–12.IEEE16Shenetal.[31]Wu,Y.,Kirillov,A.,Massa,F.,Lo,W.Y.,Girshick,R.:Detectron2.https://github.com/facebookresearch/detectron2(2019)[32]Xu,Y.,Xu,Y.,Lv,T.,Cui,L.,Wei,F.,Wang,G.,Lu,Y.,Florencio,