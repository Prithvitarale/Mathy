ModelTracker:RedesigningPerformanceAnalysisToolsforMachineLearningSaleemaAmershi,MaxChickering,StevenM.Drucker,BongshinLee,PatriceSimard,JinaSuhMicrosoftResearchRedmond,WA{samershi,dmax,sdrucker,bongshin,patrice,jinsuh}@microsoft.comABSTRACTModelbuildinginDebuggingmodelperformancetypicallyrequiresadisruptivecognitiveswitchfromtheprimarytaskofbuildingamodeltothetaskofanalyzingpredictionerrors(i.e.,exampleswhoseuser-providedlabelsarepredictedincorrectlybythemodel).Forexample,performanceanalysismayinvolvefirstlocatingerrorswithinlargedatasetsviasortingandfiltering(e.g.,sortingbymodelpredictionscores,filteringbyerrorstypes)andtheninspectingrawdatatoformhypothesesaboutpotentialcausesofthoseerrors.Manytoolshavealsobeencreatedtofacilitatedeepermodelanalysisanderrordebugging(e.g.,dimensionalityreduction[20,7,4]andscatterplotanalysis[12,6]).Suchtools,however,areoftenmorecomplexandheavyweightthaninspectingrawdata[7].Switchingbetweentheseextremesofviewingsummarystatisticstodebuggingmodelperformancebehaviorcanresultinalossofcontextanddisruptstheflowofmodelbuilding[18].Thesedisruptionscanbepartiallymitigatedwithintegratedenvironmentssupportingbothmodelbuildinganderroranalysistasks.However,existingintegratedenvironmentsonlysupportcoarsestatisticsandfine-grainedrawdatainspectiontools(e.g.,[16,21]),therebystillrequiringmodeswitchesbetweenmodelbuildingandperformanceanalysis.Inpractice,therefore,performanceanalysisanddebuggingisoftenperformedonlyaftertrial-and-errorstrategiesfailratherthantodrivesubsequentiterationsofmodelbuilding.Inthispaper,wepresentModelTracker(Figure1),aninteractivevisualizationdesignedtoencourageamoreinformedapproachtomodelbuildinginmachinelearning.ModelTrackersubsumesinformationcontainedwithinnumeroustraditionalsummarystatisticsandgraphswhiledisplayingexample-levelperformancewithinasinglecompactvisualization.Italsosupportsdirecterrorexaminationanddebugging,reducingdisruptioncausedbycontextaddition,focusingonindividualerrorscanresultinalossofcontext,makingitdifficultforuserstoprioritizeorgeneralizefromtheirobservations.Asimilarstrategyisdirectevaluation,whereusersprovidenewdataModelTrackerisnotalgorithmordatatypespecific,andthereforecanprovideaconsistentmeansforperformanceanalysisanddebuggingacrossavarietyofsupervisedmachinelearningtasks(asdiscussedfurtherinDiscussion).MODELBUILDINGorderingexamplesindicatedrelativepredictionscores(andthereforerelativeerrorseverity),usersalsowantedtounderstandthemagnitudeofseparationbetweenindividualexamplestobetterprioritizeeffortsindebuggingerrors,leadingtoourcurrentdisplay.DebuggingCommonErrorsInthissection,wedescribehowModelTrackersupportsinteractiveinspectionanddebuggingofthreecommonsourcesoferrorsinmachinelearning:mislabeleddata,inadequatefeaturestodistinguishbetweenconcepts,andinsufficientdataoccurinthetrainsetwhenthereisnotyetenoughexamplestoovercomesomebiasinthemodel(e.g.,inhighly-regularizedlinearmodels).Insufficientdataerrorsoftenmanifestasoutliers–isolatedexamplesverifywhetheranactiontakenresolvedasuspectedissue.Onecommentedthatit“wasrewardingornot[whentheactiondidnothelp].”Anothercommentedthatthearcs“helpedwhenitmatchedmyexpectations[aboutdifferenceinparticipantabilitytodebugorimprovemodelperformancebetweenthetwointerfaces.Weanalyzedourpost-conditionLikert-scalequestionsusingWilcoxonsigned-ranktests.Figure8showspreferencecountsandLikert-scalequestionmedians.10outmislabeleddatacanbequicklydiscovered,exampleswithfewneighborscanbebroughtforwardandexamined,andsituationswherenewfeaturesneedtobeidentifiedcanbecalledout.Evencloserintegrationallowsoverallmodel