RightfortheRightConcept:RevisingNeuro-SymbolicConceptsbyInteractingwiththeirExplanationsWolfgangStammer1,*PatrickSchramowski1,*KristianKersting1,21ComputerScienceDepartment,TUDarmstadt,Germany2CentreforCognitiveScience,TUDarmstadt,andHessianCenterforAI(hessian.AI){wolfgang.stammer,schramowski,kersting}@cs.tu-darmstadt.deMarch17,2021AbstractMostexplanationmethodsindeeplearningmapimportanceestimatesforamodel’spredictionbacktotheoriginalinputspace.These“visual”explanationsareofteninsufficient,asthemodel’sactualconceptremainselusive.Moreover,withoutinsightsintothemodel’ssemanticconcept,itisdifficult—ifnotimpossible—tointerveneonthemodel’sbehaviorviaitsexplanations,calledExplanatoryInteractiveLearning.Conse-quently,weproposetointerveneonaNeuro-Symbolicscenerepresentation,whichallowsonetorevisetheturn,allowsonetocomputeandinteractwithneuro-symbolicexplanations.WedemonstratetheadvantagesofNeSyXILonanewlycompiled,confoundeddataset,calledCLEVR-Hans.Itconsistsofscenesthatcanbeclassifiedbasedonspecificcombinationsofobjectattributesandrelations.Importantly,CLEVR-Hansencodesconfoundersinawaysothatthecon-foundingfactorsarenotseparableintheoriginalinputspace,incontrasttomanypreviousconfoundedcomputervisiondatasets.Tosumup,thisworkmakesthefollowingcontributions:(i)Weconfirmempiricallyonournewlycompiledconfoundedbenchmarkdataset,CLEVR-Hans,thatNeuro-Symboliccon-ceptlearners[34]mayshowClever-Hansmoments,too.(ii)Tothisend,wedeviseanovelNeuro-Symbolicconceptlearner,combiningSlotAttention[31]andSetTransformer[27]inImportantly,althoughthemodeliswrongfortherightrea-son,itisanon-trivialproblemofinteractingwiththemodeltoreviseitsdecisionusingXILsolelybasedontheseexplana-tions.Settingalosstermtocorrecttheexplanation(e.g.[46])oncolorchannelsisasnon-trivialandinconvenientasun-confoundingthedatasetwithcounterexamples[53].Kimetal.[18]describehowtounbiassuchadatasetifthebiasisknown,usingthemutualinformationbetweennetworkstrainedonseparatefeaturesofthedatasetinorderforthemainnetworknottofocusonbiasfeatures.Riegerelal.[45]pro-poseanexplanationpenalizationlosssimilarto[46,50,47],focusingonContextualDecomposition[38]asexplanationmethod.However,theutilizedpenalizationmethodistask-specificanddetachedfromthemodel’sexplanations,resultinginonlyaslightimprovementofafinal31%accuracy(usingtheinvertedColorMNISTsetting).4Neuro-SymbolicExplanatoryInter-activeLearningTheColor-MNISTexampleclearlyshowsthatalthoughtheinput-levelexplanationsofcurrentXAImethodsareanimpor-tantfirststeptowardstrueexplanationsofamodel’sbehavior,muchambiguityinamodel’sdecisionprocessremains.Us-ingXILonthesevisualexplanationsonly,itcanbedifficulttoproperlyinterveneonamodel.Whatwerequireisanun-derstandable,disentangledrepresentationlevel,whichtheusercanenquirefromandinterveneon.Neuro-SymbolicArchitecture.Forthispurpose,wecon-structanarchitectureconsistingoftwomodules,aconceptem-beddingandareasoningmodule.Theconceptmodule’staskistocreateadecomposedrepresentationoftheinputspacethatcanbemappedtohuman-understandablesymbols.Thetaskofthereasoningmoduleistomakepredictionsbasedonthissymbolicrepresentation.Fig.3givesanillustrativeoverviewofourapproach,whichweformulatemorepreciselyinthefollowing:Givenaninputimagexi∈X,wherebyX:=[x1,...,xN]∈RN×M,withXbeingdividedintosubsetsofNcclasses{X1,...,XNc}∈Xandwithground-truthclasslabelsdefinedasy∈[0,1]N×Nc,wehavetwomodules,theconceptembeddingmodule,h(xi)=ẑi,whichreceivestheinputsampleandencodesitintoasymbolicrepresentation,withẑ∈[0,1]N×D.Andthereasoningmodule,g(ẑi)=ŷi,whichproducesthepredictionoutput,ŷi∈[0,1]N×Nc,giventhesymbolicrepresentation.Theexactdetailsoftheg(ẑi)andh(xi)dependonthespe-cificimplementationsofthesemodules,andwillbediscussedfurtherinsectionsbelow.RetrievingNeuro-SymbolicExplanations.Giventhesetwomodules,wecanextractexplanationsfortheseparatetasks,i.e.themoregeneralinputrepresentationtaskandthereasoningtask.WewriteanexplanationfunctioninageneralnotationasE(m(·),o,s),whichretrievestheexplanationofaspecificmodule,m(·),giventhemodule’sinputs,andthemodule’soutputifitisthefinalmoduleortheexplanationofthefollowingmoduleifitisnot,bothsummarizedasohere.Forourapproach,wethushaveEg(g(·),ŷi,zi)=:êgiandEh(h(·),êgi,xi)=:êhi.Thesecanrepresentscalars,vectors,ormatrices,dependingonthegivenmoduleandoutput.êgirepresentstheexplanationofthereasoningmodulegiventhefinalpredictedoutputŷi,e.g.alogic-basedrule.êhipresentstheexplanationoftheconceptmodulegiventheexplanationofthereasoningmoduleêgi,e.g.avisualexplanationofalearnedconcept.Inthisway,theexplanationofthereasoningmod-uleispassedbacktotheconceptmoduleinordertoreceivetheexplanationsoftheconceptmodulethatcontributetotheexplanationofthereasoningmodule.ThisexplanationpassisdepictedbythegrayarrowsofFig.3.TheexactdefinitionofEgandEhusedinthisworkaredescribedbelow.RevisingNeuro-SymbolicConcepts.Asweshowinourexperimentsbelow,alsoNeuro-Symbolicmodelsarepronetofocusingonwrongreasons,e.g.confoundingfactors.Insuchacase,itisdesirableforausertointerveneonthemodel,e.g.viaXIL.Aserrorscanresultfromdifferentmodulesoftheconceptlearner,theusermustcreatefeedbacktailoredtotheindividualmodulethatisproducingtheerror.Auserthusreceivestheex-planationofamodule,e.g.êgi,andproducesanadequatefeed-backgivenknowledgeoftheinputsample,xi,thetrueclasslabel,yi,themodel’sclasspredictionŷiandpossibleinternalrepresentations,e.g.ẑi.Fortheusertointeractwiththemodel,theuser’sfeedbackmustbemappedbackintoarepresentationspaceofthemodel.Inthecaseofcreatingfeedbackforavisualexplanation,asin[46],[53]and[47],themappingisquiteclear:theusergivesvisualfeedbackdenotingwhichregionsoftheinputarerele-vantandwhicharenot.This“visual”feedbackistransferredtotheinputspaceintheformofbinaryimagemasks,whichwedenoteasAvi.Thesemanticuserfeedbackcanbeintheformofrelationalfunctions,ϕ,forinstance,“ifanimagebelongstoclass1thenoneobjectisalargecube”:∀img.isclass(img,1)⇒∃obj.[in(obj,img)∧size(obj,large)∧shape(obj,cube)],WedefineAsi:=WϕAϕi(ẑi|=ϕ)whichdescribesthedis-junctionoverallrelationalfeedbackfunctionswhichholdforthesymbolicrepresentation,ẑi,ofanimage,xi.Animportantcharacteristicofthesemanticuserfeedbackisthatitcandescribedifferentlevelsofgeneralizability,sothatfeedbackbasedonasinglesamplecanbetransferredtoasetofmultiplesamples.Forinstanceϕcanholdforanindividualsample,allsamplesofaspecificclass,j,orallsamplesofthedataset.Consequently,thedisjunction,Wϕ,canbeseparatedas:Asi|yi=j=Asamplei∨Aclassc=j∨Aall.Forthesakeofsimplicity,wearenotformallyintroducingrelationallogicandconsiderthesemanticfeedbackintabularform(cf.Fig.3).Tosummarize,wehavethebinarymasksforthevisualfeedbackAvi∈[0,1]MandthesemanticfeedbackAsi∈[0,1]D.ForthefinalinteractionwerefertoXILwithdifferentiablemodelsandexplanationfunctions,generallyformulatedastheexplanatorylossterm,Lexpl=λXNi=1r(Avi,êhi)+(1−λ)XNFigure3:Neuro-SymbolicXILforimprovedexplanationsandinteraction.(Top)Neuro-SymbolicConceptLearnerwithSlot-AttentionandSetTransformer.(Bottom)Neuro-Symbolicrevisionpipelinewithexplanationsofthemodelbefore(gray)andafterapplyingthefeedback(orange).DataSetSizeClassesInput-dimensionsMulti-objectVisualconfounderNon-visualconfounderNumberofrule-typesToyColor[46]40k25×5×37371ColorMNIST[18]70k1028×28Hans3,e.g.classrulesarealsobasedonobjectpositions.Eachclassinbothdatasetsconsistsof3000training,750validation,and750testimages.Finally,theimageswerecreatedsuchthattheexactcom-ModelValidation(confounded)Test(non-confounded)CLEVR-Hans3CNN(Default)99.55±0.1070.34±0.30CNN(XIL)99.69±0.0870.77±0.37NeSy(Default)98.55±0.27◦81.71±3.09NeSyXIL100.00±0.00•91.31±3.13CLEVR-Hans7CNN(Default)96.09±0.1984.50±1.04CNN(XIL)96.08±0.2589.26±0.29NeSy(Default)96.88±0.16◦90.97±0.91NeSyXIL98.76±0.17•94.96±0.49CLEVR-Hans3–GlobalCorrectionRule(¬Gray)ModelTest(class1)Test(allclasses)NeSy(Default)52.98±9.6081.71±3.09NeSyXIL83.59±8.4483.26±6.46Table2:BalancedaccuraciesonClevr-Hans3andClevr-Hans7.Thebest(“•”)andrunner-up(“◦”)resultsarebold.WecomparethetestaccuracyincomparisontothevalidationaccuracyasanindicationofClever-Hansmoments.marginally,howevercomparingtothenear-perfectvalidationaccuracy,itisclearthemodelstillfocusesonconfoundingfac-tors.6.2Neuro-SymbolicXILtotheRescueNow,wearereadytoinvestigatehowNeuro-SymbolicXILimprovesuponvisualXIL.ReceivingExplanationsofNeuro-Symbolicmodel.TrainingtheNeuro-Symbolicmodelinthedefaultcross-entropysetting,wemaketwoobservations.Firstly,wecanobserveanincreasedtestaccuracycomparedtothepreviousstandardCNNsettings.Thisislikelyduetotheclassrules’relevantfeaturesnowbeingmoreevidentforthemodeltousethanthestandardCNNcouldpossiblycatchonto,e.g.theob-ject’smaterial.Secondly,evenwithahighertestaccuracythanthepreviousmodelcouldachieve,thisaccuracyisstillconsid-erablybelowtheagainnearperfectvalidationaccuracy.ThisindicatesthatalsotheNeuro-Symbolicmodelisnotresilientagainstconfoundingfactors.ExampleexplanationsoftheNeuro-SymbolicmodelcanbefoundinFig.5,withthesymbolicexplanationontherightsideandthecorrespondingattention-basedvisualexplanationleftofthis.Theobjectshighlightedbythevisualexplanationsde-pictthoseobjectsthatareconsideredasmostrelevantaccord-ingtothesymbolicexplanation(seeEq.5fordetails).Thesevisualizationssupporttheobservationthatthemodelalsofo-cusesonconfoundingfactors.RevisingNeuro-SymbolicModelsviaInteractingwithTheirExplanations.WeobservethattheClever-Hansmo-mentoftheNeuro-Symbolicmodelinthepreviousexperimentwasmainlyduetoerrorsofthereasoningmoduleasthevisualexplanationcorrectlydepictstheobjectsthatwereconsideredasrelevantbythereasoningmodule.TorevisethemodelwethereforeappliedXILtothesymbolicexplanationsviathepre-viouslyused,mean-squarederrorregularizationterm.Wepro-videdthetrueclassrulesassemanticuserfeedback.TheresultingaccuraciesoftherevisedNeuro-SymbolicmodelcanbefoundinTab.2andexampleexplanationsinFig.5.Weobservethatfalsebehaviorsbasedonconfoundingfactorscouldlargelybecorrected.TheXILrevisedNeuro-Symbolicmodelproducestestaccuraciesmuchhigherthanwaspreviouslypossibleinallothersettings,includingtheXILrevisedCNN.TotesttheinfluenceofpossibleSlot-Attentionpredictionerrorswealsotestedrevisingthereasoningmodulewhengiventheground-truthsymbolicrepresentations.Indeedthisway,themodelcouldreachanear-perfecttestaccuracy(cf.Appendix).QuantitativeAnalysisofSymbolicExplanations.InordertoquantitativelyevaluatethesymbolicexplanationswecomputetherelativeL1erroronthetestsetbetweenground-truthexplanationsandmodelexplanations.Briefly,forCLEVR-Hans3NeSyXILresultedinareductioninL1errorcomparedtoNeSy(Default)of:73%(total),64%(class1),76%(class2)and82%(class3).Foradetaileddiscussioncf.Appendix.RevisionviaGeneralFeedbackRules.UsingXILforre-visingamodel’sexplanationsrequiresthatahumanuserin-teractswiththemodelonasample-basedlevel,i.e.theuserre-ceivesamodel’sexplanationforanindividualsampleandde-cideswhethertheexplanationforthisisacceptableoracorrec-tiononthemodel’sexplanationisnecessary.Thiscanbeverytediousifacorrectionisnotgeneralizabletomultiplesamplesandmustbecreatedforeachsampleindividually.Considerclass1ofCLEVR-Hans3,wheretheconfound-ingfactoristhecolorgrayofthelargecube.Oncegrayhasbeenidentifiedasanirrelevantfactorforthis,butalsoallotherclasses,usingNeSyXIL,ausercancreateaglobalcorrec-tionruleasinFig.3.Inotherwords,irrespectiveoftheclasslabelofasample,thecolorgrayshouldneverplayaroleforprediction.Tab.2(bottom)showsthetestaccuraciesofourneuro-symbolicarchitectureforclass1and,separately,overallclasses.Weherecomparethedefaulttrainingmodevs.XILwiththesingleglobalcorrectionrule.Forthisexperi-ment,ourexplanatorylosswastheRRRterm[46],whichhastheadvantageofhandlingnegativeuserfeedback.Asonecansee,applyingthecorrectionrulehassubstantialadvantagesforclass1testaccuraciesandminoradvantagesforthefulltestaccuracy.TheseresultshighlightthebenefitofNeSyXILforcorrectingpossibleClever-Hansmomentsviaglobalcorrectionrules,apreviouslynon-trivialfeature.7ConclusionNeuro-Symbolicconceptlearnersarecapableoflearningvi-sualconceptsbyjointlyunderstandingvisionandsymboliclanguage.However,althoughtheycombinesystem1andsys-tem2[15]characteristics,theircomplexitystillmakesthemdifficulttotrustincriticalapplications,especially,aswehaveshown,ifthetrainingconditionsfortheirsystem1componentmaydifferfromthoseinthetestcondition.However,theirsys-tem2componentallowstivelypenalizingitsNeuro-Symbolicexplanations.Ourresultsonanewlycompiledconfoundedbenchmarkdataset,calledCLEVR-Hans,demonstratedthatsemanticexplanations,i.e.,compositionalexplanationsataper-object,symboliclevel,canidentifyconfoundersthatarenotidentifiableusing“visual”ex-planationsonly.Moreimportantly,feedbackonthissemanticlevelmakesitpossibletorevisethemodelfromfocusingontheseconfoundingfactors.OurresultsshowthatNeuro-Symbolicexplanationsandin-teractionsmeritfurtherinvestigation.Usingasemanticloss[59]wouldallowonetostayattheconceptualleveldirectly.Furthermore,oneshouldintegrateaneuralsemanticparsingsystemthathelpstointeractivelylearnajointsymboliclan-guagebetweenthemachineandthehumanuserthroughde-composition[16].Lastly,language-guidedXIL[37]isanin-terestingapproachformorenaturalsupervision.Theseap-proacheswouldhelptomovefromXILtoconversationalXIL.ApplyingNeuro-SymbolicpriorknowledgetoamodelmayprovideadditionalbenefitstoaXILsetting.Finally,itisveryinterestingtoexploremoreexpressivereasoningcomponentsandinvestigatehowtheyhelpcombatevenmorecomplexClever-Hansmoments.Concerningourdataset,aninterest-ingnextstepwouldbetocreateaconfoundedcausaldatasetintheapproachof[10].Ackowledgements.Theauthorsthanktheanonymousre-viewersfortheirvaluablefeedbackaswellasThomasKipfforhissupportwithSlotAttention.TheworkhasreceivedfundingfromtheBMEL/BLEundertheinnovationsupportprogram,project“AuDiSens”(FKZ28151NA187).Itbene-fitedfromtheHessianresearchpriorityprogrammeLOEWEwithintheprojectWhiteBoxaswellasfromtheHMWKclus-terproject“TheThirdWaveofAI.”References[1]SomakAditya,YezhouYang,andChittaBaral.Explicitreason-ingoverend-to-endneuralarchitecturesforvisualquestionan-swering.InProceedingsoftheThirty-SecondAAAIConferenceonArtificialIntelligence,(AAAI),the30thinnovativeApplica-tionsofArtificialIntelligence(IAAI),editors,3rdInternationalConferenceonLearningRepresenta-tions,ICLR2015,SanDiego,CA,USA,May7-9,2015,Confer-enceTrackProceedings,2015.[21]DogaKisa,GuyVandenBroeck,ArthurChoi,andAdnanDar-wiche.Probabilisticsententialdecisiondiagrams.InChittaBaral,GiuseppeDeGiacomo,andThomasEiter,editors,Prin-ciplesofKnowledgeRepresentationandReasoning:Proceed-ingsoftheFourteenthInternationalConference,KR2014,Vi-enna,Austria,July20-24,2014.AAAIPress,2014.[22]PangWeiKoh,ThaoNguyen,YewSiangTang,StephenMuss-mann,EmmaPierson,BeenKim,andPercyLiang.Conceptbottleneckmodels.InProceedingsofthe37thInternationalConferenceonMachineLearning.PMLR,2020.[23]AdamRKosiorek,HyunjikKim,andDaniloJRezende.Conditionalsetgenerationwithtransformers.arXivpreprintarXiv:2006.16841,2020.[24]ChristophH.Lampert,HannesNickisch,andStefanHarmel-ing.Learningtodetectunseenobjectclassesbybetween-classattributetransfer.InIEEEComputerSocietyConferenceonComputerVisionandPatternRecognitionCVPR,pages951–958.IEEEComputerSociety,2009.[25]ChristophHLampert,HannesNickisch,andStefanHarmeling.Attribute-basedclassificationforzero-shotvisualobjectcate-gorization.IEEEtransactionsonpatternanalysisandmachineintelligence,36(3):453–465,2013.[26]SebastianLapuschkin,StephanWäldchen,AlexanderBinder,GrégoireMontavon,WojciechSamek,andKlaus-RobertMüller.Unmaskingcleverhanspredictorsandassessingwhatmachinesreallylearn.Naturecommunications,10(1):1–8,2019.[27]JuhoLee,YoonhoLee,JungtaekKim,AdamKosiorek,Se-ungjinChoi,andYeeWhyeTeh.Settransformer:Aframeworkforattention-basedpermutation-invariantneuralnetworks.InInternationalConferenceonMachineLearning,ICML,pages3744–3753.PMLR,2019.[28]OscarLi,HaoLiu,ChaofanChen,andCynthiaRudin.Deeplearningforcase-basedreasoningthroughprototypes:Aneuralnetworkthatexplainsitspredictions.InSheilaA.McIlraithandKilianQ.Weinberger,editors,ProceedingsoftheThirty-SecondAAAIConferenceonArtificialIntelligence,(AAAI),the30thin-novativeApplicationsofArtificialIntelligence(IAAI),andthe8thAAAISymposiumonEducationalAdvancesinArtificialIn-telligence(EAAI),2018,pages3530–3537.AAAIPress,2018.[29]YitaoLiangandGuyVandenBroeck.Learninglogisticcir-cuits.InTheThirty-ThirdAAAIConferenceonArtificialIntel-ligence,AAAI2019,TheThirty-FirstInnovativeApplicationsofArtificialIntelligenceConference,IAAI2019,TheNinthAAAISymposiumonEducationalAdvancesinArtificialIntelligence,EAAI2019,Honolulu,Hawaii,USA,January27-February1,2019,pages4277–4286.AAAIPress,2019.[30]RuntaoLiu,ChenxiLiu,YutongBai,andAlanL.Yuille.Clevr-ref+:Diagnosingvisualreasoningwithreferringexpressions.InIEEEConferenceonComputerVisionandPatternRecognition,CVPR,pages4185–4194.ComputerVisionFoundation/IEEE,2019.[31]FrancescoLocatello,DirkWeissenborn,ThomasUnterthiner,AravindhMahendran,GeorgHeigold,JakobUszkoreit,AlexeyDosovitskiy,andThomasKipf.Object-centriclearningwithslotattention.InH.Larochelle,M.Ranzato,R.Hadsell,M.F.Balcan,andH.Lin,editors,AdvancesinNeuralInformationProcessingSystems,volume33,pages11525–11538.CurranAssociates,Inc.,2020.[32]Wei-YinLoh.Fiftyyearsofclassificationandregressiontrees.InternationalStatisticalReview,82(3):329–348,2014.[33]RobinManhaeve,SebastijanDumancic,AngelikaKimmig,ThomasDemeester,andLucDeRaedt.Deepproblog:Neuralprobabilisticlogicprogramming.InSamyBengio,HannaM.Wallach,HugoLarochelle,KristenGrauman,NicolòCesa-Bianchi,andRomanGarnett,editors,AdvancesinNeuralIn-formationProcessingSystems31:AnnualConferenceonNeu-ralInformationProcessingSystems2018,NeurIPS2018,3-8December2018,Montréal,Canada,pages3753–3763,2018.[34]JiayuanMao,ChuangGan,PushmeetKohli,JoshuaB.Tenen-baum,andJiajunWu.Theneuro-symbolicconceptlearner:In-terpretingscenes,words,andsentencesfromnaturalsupervi-sion.In7thInternationalConferenceonLearningRepresenta-tions,ICLR.OpenReview.net,2019.[35]DavidMascharka,PhilipTran,RyanSoklaski,andArjunMa-jumdar.Transparencybydesign:Closingthegapbetweenperformanceandinterpretabilityinvisualreasoning.In2018IEEEConferenceonComputerVisionandPatternRecognition,CVPR,pages4942–4950.IEEEComputerSociety,2018.[36]TimMiller.Explanationinartificialintelligence:Insightsfromthesocialsciences.ArtificialIntelligence,267:1–38,2019.[37]JesseMu,PercyLiang,andNoahGoodman.Shapingvisualrepresentationswithlanguageforfew-shotclassification.InProceedingsofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics,pages4823–4830,Online,July2020.AssociationforComputationalLinguistics.[38]W.JamesMurdoch,PeterJ.Liu,andBinYu.Beyondwordim-portance:Contextualdecompositiontoextractinteractionsfromlstms.In6thInternationalConferenceonLearningRepresen-tations,ICLR2018,Vancouver,BC,Canada,April30-May3,[46]AndrewSlavinRoss,MichaelC.Hughes,andFinaleDoshi-Velez.Rightfortherightreasons:Trainingdifferentiablemod-elsbyconstrainingtheirexplanations.InProceedingsofIn-ternationalJointConferenceonArtificialIntelligenceIJCAI,pages2662–2670,2017.[47]PatrickSchramowski,WolfgangStammer,StefanoTeso,AnnaBrugger,FranziskaHerbert,XiaotingShao,Hans-GeorgLuigs,Anne-KatrinMahlein,andKristianKersting.Makingdeepneu-ralnetworksrightfortherightscientificreasonsbyinteractingwiththeirexplanations.NatureMachineIntelligence,2(8):476–486,2020.[48]KarlSchulz,LeonSixt,FedericoTombari,andTimLandgraf.Restrictingtheflow:Informationbottlenecksforattribution.InInternationalConferenceonLearningRepresentations,2020.[49]RamprasaathR.Selvaraju,MichaelCogswell,AbhishekDas,RamakrishnaVedantam,DeviParikh,andDhruvBatra.Grad-cam:Visualexplanationsfromdeepnetworksviagradient-basedlocalization.InIEEEInternationalConferenceonCom-puterVision,ICCV,pages618–626.IEEEComputerSociety,2017.[50]RamprasaathRamasamySelvaraju,StefanLee,YilinShen,HongxiaJin,ShaliniGhosh,LarryP.Heck,DhruvBatra,andDeviParikh.TakingaHINT:leveragingexplanationstomakevisionandlanguagemodelsmoregrounded.In2019IEEE/CVFInternationalConferenceonComputerVision,ICCV,pages2591–2600.IEEE,2019.[51]DanielSmilkov,NikhilThorat,BeenKim,FernandaViégas,andMartinWattenberg.Smoothgrad:removingnoisebyaddingnoise.arXivpreprintarXiv:1706.03825,2017.[52]MukundSundararajan,AnkurTaly,andQiqiYan.Axiomaticattributionfordeepnetworks.InProceedingsofthe34thInter-nationalConferenceonMachineLearning,ICML,volume70,pages3319–3328.PMLR,2017.[53]StefanoTesoandKristianKersting.Explanatoryinteractivema-chinelearning.InProceedingsofthe2019AAAI/ACMConfer-enceonAI,Ethics,andSocietyAIES,pages239–245,2019.[54]PhilippTschandl,CliffRosendahl,andHaraldKittler.Theham10000dataset,alargecollectionofmulti-sourcedermato-scopicimagesofcommonpigmentedskinlesions.Scientificdata,5:180161,2018.[55]RamakrishnaVedantam,KaranDesai,StefanLee,MarcusRohrbach,DhruvBatra,andD.Parikh.Probabilisticneural-symbolicmodelsforinterpretablevisualquestionanswering.InProceedingsofInternationalConferenceonMachineLearning,ICML,2019.[56]DanielS.WeldandGaganBansal.Thechallengeofcraftingintelligibleintelligence.Commun.ACM,62(6):70–79,2019.[57]JialinWuandRaymondJ.Mooney.AppendixCLEVR-HansdatasetForCLEVR-Hansclassesforwhichclassrulescontainmorethanthreeobjects,thenumberofobjectstobeplacedperscenewasrandomlychosenbetweentheminimalrequirednumberofobjectsFigureTypeDimOutNumb.HeadsCommentSAB1284-SAB1284-Dropout--p=0.5PMA1284-Dropout--p=0.5Linear3/7--TableModelGlobalTestAverageClass1Class2Class3NeSy(Default)4.99±0.166.57±0.954.58±0.683.81±0.34NeSyXIL1.37±0.22.37±0.621.09±0.080.68±0.1TruePositiveRateNeSy(Default)2.56±0.052.97±0.272.13±0.232.57±0.2NeSyXIL0.85±0.091.26±0.310.77±0.060.52±0.12Table5:L1errorbetweensymbolicuserfeedback(i.e.ground-truth(GT)symbolic012Predictedlabel012Truelabel0.120.710.160.020.970.010.000.001.00Normalizedconfusionmatrix0.00.20.40.60.8(a)CNNDefault012Predictedlabel012Truelabel0.720.170.110.040.920.040.000.000.99Normalizedconfusionmatrix0.20.40.60.8(b)NeSyDefault012Predictedlabel012Truelabel0.120.720.150.000.990.010.000.001.00Normalizedconfusionmatrix0.00.20.40.60.8(c)CNNXIL012Predictedlabel012Truelabel0.840.090.070.000.990.010.000.001.00Normalizedconfusionmatrix0.00.20.40.60.81.0(d)NeSyXILFigure7:Confusionmatricesofthedifferentmodelsandtrainingsettingsforthetestsetof0123456Predictedlabel0123456Truelabel0.430.150.140.030.090.110.050.010.880.010.070.020.010.010.010.020.870.010.050.030.010.000.040.010.910.020.020.010.000.000.000.010.940.040.010.000.000.010.010.030.950.000.000.000.000.000.010.000.99Normalizedconfusionmatrix0.00.20.40.60.8(a)CNNDefault012(a)(b)(c)(d)(e)Figure9:Additionalexplanationsofthevariousmodeltypesfortestsamples.Greenchecksrepresentcorrectclasspredictions,redcrossesincorrectpredictions.accuracythanwhentrainedwithCLEVR-Hans3.Wesuggestthe