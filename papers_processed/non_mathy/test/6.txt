RelativeAttributesDeviParikhToyotaTechnologicalInstituteChicago(TTIC)dparikh@ttic.eduKristenGraumanUniversityofTexasatAustingrauman@cs.utexas.eduAbstractHuman-nameablevisual“attributes”canbenefitvari-ousrecognitiontasks.However,existingtechniquesrestrictthesepropertiestocategoricallabels(forexample,aper-sonis‘smiling’ornot,asceneis‘dry’ornot),andthusfailtocapturemoregeneralsemanticrelationships.Weproposetomodelrelativeattributes.Giventrainingdatastatinghowobject/scenecategoriesrelateaccordingtodif-ferentattributes,welearnarankingfunctionperattribute.Thelearnedrankingfunctionspredicttherelativestrengthofeachpropertyinnovelimages.Wethenbuildagenera-tivemodeloverthejointspaceofattributerankingoutputs,andproposeanovelformofzero-shotlearninginwhichthesupervisorrelatestheunseenobjectcategorytopreviouslyseenobjectsviaattributes(forexample,‘bearsarefurrierthangiraffes’).Wefurthershowhowtheproposedrelativeattributesenablerichertextualdescriptionsfornewimages,whichinpracticearemorepreciseforhumaninterpreta-tion.Wedemonstrateple,inFigure1,whileitisdifficulttoassignameaningfulvaluetothebinaryattribute‘smiling’,wecouldallagreeontherelativeattribute,i.e.HughLaurieissmilinglessthanScarlettJohansson,butmorethanJaredLeto.Inadditiontobeingmorenatural,relativeattributeswouldofferarichermodeofcommunication,thusallowingaccesstomorede-tailedhumansupervision(andsopotentiallyhigherrecog-nitionaccuracy),aswellastheabilitytogeneratemorein-formativedescriptionsofnovelimages.Howcanwelearnrelativeproperties?Whereastradi-tionalsupervisedclassificationisappropriatetolearnat-tributesthatareintrinsicallybinary,itfallsshortwhenwewanttorepresentvisualpropertiesthatarenameablebutnotcategorical.Ourgoalisinsteadtoestimatethedegreeofthatattribute’spresence—which,importantly,differsfromtheprobabilityofabinaryclassifier’sprediction.Tothisend,wedeviseanapproachthatlearnsarankingfunctionforeachattribute,givenrelativesimilarityconstraintsonpairsofexamples(ormoregenerallyapartialorderingthisrankingisalsospecifictoaqueryimage,andtypicallyintendedfornearest-neighbor-basedclassifiers.Ourworklearnsarankingfunctiononimagesbasedonconstraintsspecifyingtherelativestrengthofattributes,andtheresult-ingfunctionisnotrelativetoanyotherimageinthedataset.Thus,unlikequery-centricretrievaltasks,wecancharac-terizeindividualimagesbythestrengthoftheattributespresent,whichweshowisvaluablefornewrecognitionanddescriptionapplications.3.ApproachWefirstpresentourapproachforlearningrelativeat-tributes(Section3.1),andthenexplainhowwecanuserela-tiveattributesforenhancedzero-shotlearning(Section3.2)andimagedescriptiongeneration(Section3.3).3.1.LearningRelativeAttributesWearegivenasetoftrainingimagesI={i}repre-sentedinRnbyfeature-vectors{xi}andasetofMat-tributesA={am}.Inaddition,foreachattributeam,wearegivenasetoforderedpairsofimagesOm={(i,j)}andasetofun-orderedpairsSm={(i,j)}suchthat(i,j)∈Om=⇒ij,i.e.imageihasastrongerpres-enceofattributeamthanj,and(i,j)∈Sm=⇒i∼j,i.e.iandjhavesimilarrelativestrengthsofam.WenotethatOmandSmcanbededucedfromanypartialorderingoftheimagesIinthetrainingdatawithrespecttostrengthofam.EitherOmorSm,butnotboth,canbeempty.OurgoalistolearnMrankingfunctionsrm(xi)=wTmxi,(1)form=1,...,M,suchthatthemaximumnumberof3.2.Zero-ShotLearningFromRelationshipsConsiderNcategoriesofinterest.Forexample,eachcategorymaybeanobjectclass,oratypeofscene.Dur-ingtraining,Softhesecategoriesare‘seen’categoriesfor3.3.DescribingImagesinRelativeTermsThesecondapplicationofrelativeattributesthatwepro-poseisthatofdescribingnovelimages.Thegoalistobeabletorelateanynewexampletootherelsei≺jforam.Forcomparison,welearnalinearrankingfunctionrmforeachattributeusingtherelativeconstraintsinTable1,andcomparerm(xi)torm(xj)onthesametestpairs.Bothmethods’predictionsarethencomparedtotheground-truthrelativeordering.Thelearntrankingfunction’saccuracyis89%and82%ontheOSRandPubFigdatasets,respectively,ascomparedto80%and67%ifusing6543210204060Accuracy#atttodescribeunseenOSR11109876543210204060Accuracy#atttodescribeunseenPubFigDAPSRAProposedFigure5.Zero-shotlearningperformanceasfewerattributesareusedtodescribetheunseencategories.1230204060AccuracyLoosenessofconstraintsOSR1230204060AccuracyLoosenessofconstraintsPubFigDAPSRAProposedFigure6.Zero-shotlearningperformanceastheunseencategoriesarede-scribedvialooserrelationships.Figure5showstheresultsaswedecreasethenumberofattributesusedtodescribetheunseencategoryduringtraining.NotethatthenumberofattributesusedtodescribeMore	  chubby	  than	  Less	  chubby	  than	  More	  smiling	  than	  Less	  smiling	  than	  More	  VisibleForehead	  than	  Less	  VisibleForehead	  than	  Which	  image	  is?	  Best	  Fit	  Second	  Fit	  Worst	  Fit	  Move	  these	  three	  “labels”	  onto	  the	  three	  images	  above	  according	  to	  your	  choices.	  	  (a)HumanStudyInterface123020406080100