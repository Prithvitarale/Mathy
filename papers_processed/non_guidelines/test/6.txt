Socially-Aware Machine Learning
Towards Leveraging the Relationship Between Narrative
Comprehension and Mentalizing
by Prashanth Vijayaraghavan
Submitted to the Program in Media Arts and Sciences, in partial
fulfillment of the requirements for the degree of
Doctor of Philosophy
at the
MASSACHUSETTS INSTITUTE OF TECHNOLOGY
May 21, 2021
© Massachusetts Institute of Technology 2021. All right reserved.
Author . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Prashanth Vijayaraghavan
Program in Media Arts and Sciences
Certified by . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Deb Roy
Professor of Media Arts and Sciences
Thesis Supervisor
Accepted by . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Tod Machover
Academic Head
Program in Media Arts and Sciences
Submitted to the Program in Media Arts and Sciences,
School of Architecture and Planning, in partial fulfillment
of the requirements for the degree of
June, 2021
Program in Media Arts and Sciences
May 21, 2021
:
June, 2021
3
Socially-Aware Machine Learning:
Towards Leveraging the Relationship Between Narrative
Comprehension and Mentalizing
by Prashanth Vijayaraghavan
Submitted to the Program in Media Arts and Sciences, School of
Architecture and Planning, on May 21, 2021, in partial fulfillment of the
requirements for the degree of Doctor of Philosophy
ABSTRACT
Narratives are the fundamental means by which people organize, un-
derstand, and explain the social world. Research suggests that exposure
to narratives improves mentalizing, referring to the capacity to forecast and
reason about others’ mental states. Simultaneously, enhanced mentalizing
abilities are closely linked to exhibiting improved narrative processing skills.
The purpose of this dissertation is to develop modular computational meth-
ods that leverage the relationship between mentalizing and narrative com-
prehension for understanding specific aspects of social-cognitive processes
and seek to advance the research towards imparting social awareness to ma-
chines. Our work consists of three main functional modules. First, we present
a representation learning approach that computes a social situational embed-
ding of sentence-level social events. Next, we apply the learned social event
representation to embed, infer and explain the characters’ mental states from
the narratives. Finally, we analyze some of the basic elements of narrative
structure present in short personal narratives as a means of exemplifying the
story understanding capability. Particularly, we investigate the role of char-
acters’ cognitive tension captured using our inferred mental representation
for automatically detecting the central conflict of a story i.e. the climax and
their resolution.
4
Unlike most previous work that either uses conventional trait-based mod-
els or exploits low-level annotations of short fixed-length stories, we tackle
a subset of the data and modeling challenges directed at inferring human
motives and emotional reactions. First, we construct a relatively open-ended
corpus of personal narratives and commonsense knowledge from social me-
dia containing more variations in terms of topical content. Using this weakly
annotated corpus, we train deep learning models that compute rich repre-
sentations of social events capturing aspects of syntactic, semantic, and prag-
matic properties and integrate them to generate textual explanations of mo-
tives and emotions of characters in the narrative. Empirically, our proposed
approaches outperform several baselines in mental state tracking tasks and
harness transferability to low-resource regimes and other downstream tasks.
As a final contribution in this dissertation, we demonstrate improved nar-
rative processing skills by computationally predicting key elements of narra-
tive structure in personal narratives. Notably, our studies show that inte-
grating the protagonist’s mental state embeddings with linguistic informa-
tion leads to the enhanced prediction of climax and resolution in narratives.
Our data and modeling contributions emphasize the value of exploiting the
mutual influence of mentalizing and narrative comprehension, thereby pro-
moting future efforts towards building human-centered AI systems.
5
Socially-Aware Machine Learning:
Towards Leveraging the Relationship Between Narrative
Comprehension and Mentalizing
by Prashanth Vijayaraghavan
This doctoral thesis has been reviewed and approved by the following
committee members:
Deb Roy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Thesis Committee Chair
Professor
MIT Media Lab
David Bamman . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Thesis Reader
Assistant Professor
University of California, Berkeley
Douwe Kiela . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Thesis Reader
Research Scientist
Facebook
Chandra Bhagavatula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Thesis Reader
Research Scientist
Allen AI
7
“Cultivation of mind should be the ultimate aim of human existence. ”
B.R.Ambedkar
9
Acknowledgements
My grad school journey has been a great learning experience and I feel
fortunate to have many wonderful people around to help me see through it.
First and foremost, I would like to express my gratitude to my advisor Prof.
Deb Roy, whose expertise, understanding, and patience, added greatly to my
experience at the lab. Deb has always provided the freedom and support to
work on projects that I found interest in. I sincerely thank him for all the
opportunities, guidance and support during the time of research and writing
of this dissertation. I would like to thank my committee members, Chandra
Bhagavatula, David Bamman and Douwe Kiela for their guidance, insightful
comments, and feedback throughout this process. I feel extremely fortunate
to have been able to interact and work with them.
Special thanks to Heather Pierce and Keyla Gomez for being really con-
cerned and supportive through out the Ph.D. program. My journey would
have been incomplete without my amazing friends and colleagues. I want
to thank all of them for the stimulating discussions and all the fun we have
had together in the lab: Soroush Vosoughi, Brandon Roy, Misha Sra, Mina
Soltangheis, Sneha Priscilla Makini, Eric Chu, Nabeel Gillani, Martin Saveski,
Juliana Nazare, Anneli Hershman, Bridgit Mendler, Belen Saldias, Ivan Sysoev,
Lauren Fratamico, Ann Yuan, Shayne O’Brien, William Brannon, Luke, Mag-
gie Hughes, Nazmus Saquib, Mark Exposito, Neo Mohsenvand, Eric Pen-
nington, Perng-hwa Kung, Alex Siegenfeld, Sophie Chou, Hang Jiang, Suyash
Fulay, Sarah Ballinger, Wonjoune Kang, David McClure, Doug Beeferman,
Russell Stevens, William Powers, Andrew Heyward and Preeta Bansal.
Last, but certainly not least, I thank whole of my family, my childhood
friends, friends from school, UG, past jobs and LSM for their continued sup-
port and encouragement through my years at MIT. My love for them is un-
fathomable.
10
11
Contents
Abstract 3
Acknowledgements 9
1 Introduction 23
1.1 The Ubiquity and Importance of Narratives . . . . . . . . . . . 23
1.2 Research Goal . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
1.3 Characteristics of Narrative Data . . . . . . . . . . . . . . . . . 28
1.4 Research Problems . . . . . . . . . . . . . . . . . . . . . . . . . 33
1.5 Overview of Contributions . . . . . . . . . . . . . . . . . . . . . 39
1.6 Organization of Dissertation . . . . . . . . . . . . . . . . . . . . 41
2 Background & Related Work 45
2.1 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
2.2 Modeling Human Social Behaviour . . . . . . . . . . . . . . . . 49
2.3 Modeling Narrative Structure . . . . . . . . . . . . . . . . . . . 53
3 Datasets & Annotations 59
3.1 Extracting Motives and Emotional Reactions . . . . . . . . . . 61
3.1.1 Personal Narratives Corpus . . . . . . . . . . . . . . . . 61
3.1.2 Social Commonsense Knowledge . . . . . . . . . . . . . 65
3.2 Identifying Climax & Resolution in Narratives . . . . . . . . . 68
3.2.1 Story Classifier . . . . . . . . . . . . . . . . . . . . . . . 69
3.2.2 Annotation . . . . . . . . . . . . . . . . . . . . . . . . . 71
Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
12
Agreements . . . . . . . . . . . . . . . . . . . . . . . . . 74
Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
4 Learning Knowledge-Enriched Social Event Representation 77
4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
4.2 Problem Formalization . . . . . . . . . . . . . . . . . . . . . . . 80
4.3 Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
4.3.1 Social Events Dataset . . . . . . . . . . . . . . . . . . . . 81
4.3.2 Paraphrase Datasets . . . . . . . . . . . . . . . . . . . . 83
4.4 Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
4.4.1 Social Event Representation . . . . . . . . . . . . . . . . 83
Encoder . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
Objective Loss . . . . . . . . . . . . . . . . . . . . . . . . 86
4.5 Training . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
4.6 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
4.6.1 Intent-Emotion Prediction . . . . . . . . . . . . . . . . . 88
Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
Empirical Results . . . . . . . . . . . . . . . . . . . . . . 89
Ablation Study . . . . . . . . . . . . . . . . . . . . . . . 90
4.6.2 Hard Similarity Task . . . . . . . . . . . . . . . . . . . . 91
4.6.3 Paraphrase Detection . . . . . . . . . . . . . . . . . . . . 92
4.6.4 Social IQA Reasoning . . . . . . . . . . . . . . . . . . . 93
4.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
5 Modeling Human Motives and Emotions from Personal Narratives 97
5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
5.2 Problem Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
5.3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
5.4 NEMO: Our Proposed Model . . . . . . . . . . . . . . . . . . . 102
5.4.1 Story Entity Encoder . . . . . . . . . . . . . . . . . . . . 104
13
Context-Attention & Gating . . . . . . . . . . . . . . . . 107
5.4.2 Intent-Emotion Explanation Generator . . . . . . . . . 107
First-pass Decoding . . . . . . . . . . . . . . . . . . . . 108
Second-Pass Decoder . . . . . . . . . . . . . . . . . . . . 109
5.4.3 Knowledge-Enrichment Module . . . . . . . . . . . . . 109
5.4.4 Entity-based Memory Module . . . . . . . . . . . . . . 110
5.5 Training & Hyperparameters . . . . . . . . . . . . . . . . . . . 111
5.6 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
5.6.1 Explanation Generation Task (RQ1) . . . . . . . . . . . 113
Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
Baselines . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
Model Variants . . . . . . . . . . . . . . . . . . . . . . . 114
Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
Human Evaluation of Trajectories . . . . . . . . . . . . 116
Qualitative Analysis . . . . . . . . . . . . . . . . . . . . 117
5.6.2 State Classification Task (RQ2) . . . . . . . . . . . . . . 119
Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
Experimental Settings & Baselines . . . . . . . . . . . . 119
Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
Error Analysis . . . . . . . . . . . . . . . . . . . . . . . . 122
5.6.3 Application: Empathetic Dialogue Generation (RQ3) . 123
Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
Model & Baselines . . . . . . . . . . . . . . . . . . . . . 124
Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
5.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
14
6 Modeling Narrative Structure in Short Personal Narratives 127
6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
6.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
6.3 Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
6.4 M-SENSE: Modeling Narrative Structure . . . . . . . . . . . . . 133
6.4.1 Ensemble Sentence Encoders . . . . . . . . . . . . . . . 135
Extracting Linguistic Representations . . . . . . . . . . 135
Incorporating Protagonist’s Mental Representation . . 137
6.4.2 Transformer-based Fusion Layer . . . . . . . . . . . . . 138
6.4.3 Story Encoder . . . . . . . . . . . . . . . . . . . . . . . . 139
6.4.4 Interaction layer . . . . . . . . . . . . . . . . . . . . . . 140
6.4.5 Classification layer . . . . . . . . . . . . . . . . . . . . . 141
6.5 Zero-shot Approaches . . . . . . . . . . . . . . . . . . . . . . . 141
Heuristic-based Approaches . . . . . . . . . . . . . . . 141
Suspense-based Approaches . . . . . . . . . . . . . . . 142
6.6 Training & Hyperparameters . . . . . . . . . . . . . . . . . . . 142
6.7 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
6.7.1 Overall Predictive Performance (RQ1) . . . . . . . . . . 143
Baselines . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
6.7.2 Ablation Study (RQ2) . . . . . . . . . . . . . . . . . . . 147
6.7.3 Analysis and Discussion . . . . . . . . . . . . . . . . . . 149
6.8 Task: Modeling Movie Turning Points . . . . . . . . . . . . . . 151
6.8.1 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
6.9 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
7 Conclusion and Future Work 157
7.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
15
7.1.1 Learning Knowledge-Enriched Social Event Represen-
tation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
7.1.2 Modeling Human Motives and Emotions from Personal
Narratives . . . . . . . . . . . . . . . . . . . . . . . . . . 159
7.1.3 Modeling Narrative Structure in Short Personal Narra-
tives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
7.2 Limitations & Future Work . . . . . . . . . . . . . . . . . . . . . 162
7.3 Closing Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . 165
Bibliography 167
17
List of Figures
1.1 Overview of our goal: From modeling each social event through
a pragmatic lens to inferring trajectories of characters’ mental
states over sequences of events in narratives to fleshing out de-
tails of high-level structural components of the narrative, we
leverage the influence between narrative comprehension and
mentalizing (or ToM) and demonstrate how they contribute
towards building improved AI systems. . . . . . . . . . . . . . 26
1.2 Sample Personal Narrative containing highlights of some of
its major characteristics – events with actions, temporal or-
der (time information), causal links, social roles, protagonist’s
goals, motives & emotional reactions, to list a few. . . . . . . . 31
1.3 Overview of the Research Tasks tackled in this dissertation. (a)
Social Event Embeddings: Sample event text inputs are pro-
vided on the left, and the expected relative positions of event
texts in the learned embedding space are shown on the right.
(b) Narrative Entity Mental Model: Example narrative text in-
put is shown on the left, and the sample generations of intents
of dad and son (narrator) are given on the right. (c) Narrative
Structure Model: On the left, we display the input narrative
text. On the right, we have the output of the sentence labeling
task highlighting the climax and resolution sentences. . . . . . 34
3.1 Illustration of data collection pipeline. . . . . . . . . . . . . . . 61
18
3.2 Dataset details: Personal Narrative Statistics – No. of narra-
tives w.r.t their lengths. . . . . . . . . . . . . . . . . . . . . . . . 62
3.3 Sample OpenIE extraction containing arguments referring to
agent and their motivation (purpose) and emotion. . . . . . . 63
3.4 Dataset details: Samples extractions from Personal Narratives
Corpus. The agent (ARG-0) and the purpose clauses (ARGM-PRP)
are highlighted in red. . . . . . . . . . . . . . . . . . . . . . . . 65
3.5 Dataset details: Samples motives related to specific social roles
from Search-based Social Commonsense Knowledge (SB-SCK)
dataset. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
3.6 Illustration of our data collection pipeline. . . . . . . . . . . . . 69
3.7 Sample Page from our user interface for annotation containing
options to (a) highlight text and tag them as climax/resolution
or (b) choose checkboxes – “No Climax” or “No Resolution”,
if annotators feel there is no climax and resolution. . . . . . . . 72
3.8 Distributions of mean climax & resolution sentence positions. 73
3.9 Sample annotations of climax (Red) and Resolution (Green) by
one of the annotators. . . . . . . . . . . . . . . . . . . . . . . . 74
4.1 Illustration of functioning of our representation learning ap-
proach that produces rich social event embeddings. Event texts
are given in the top green box. With more knowledge, social
event embeddings move beyond high lexical overlap [shown
in (a)] and learn to integrate semantic and pragmatic proper-
ties [shown in (b), (c)] of event texts along with social role in-
formation [shown in (d)]. . . . . . . . . . . . . . . . . . . . . . . 78
4.2 Left: Samples from Search-based Social Commonsense Knowl-
edge (SB-SCK) dataset with highlighted motivations for social
roles, Right: Statistics of SB-SCK dataset. . . . . . . . . . . . . 82
19
4.3 Left: Illustration of our Social Event Representation Model. . . 85
4.4 Results of our ablation study on a held-out validation set. Acc
scores (%) to measure the effect of βE in predicting intents. . . 91
5.1 Sample personal narrative is shown on the top. It contains the
motives and emotional reactions [italics] of different characters
– dad and son (narrator) in the narrative. . . . . . . . . . . . . 98
5.2 Overview of our NEMO model. . . . . . . . . . . . . . . . . . . 103
5.3 Illustration of the full architecture of our NEMO model. . . . . 106
5.4 Attention map (head-6) between context and source. On the
x-axis are the source tokens, on the y-axis the context tokens. 118
5.5 Generation of motivation explanations in multiple decoding
steps. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
5.6 Prediction performance under low-resource (LR) settings (lim-
ited amounts of training data). . . . . . . . . . . . . . . . . . . 120
5.7 Sample generations showcasing the limitations of NEMO. . . . 123
6.1 (Left) Freytag’s Pyramid. (Right) Highlights of climax and res-
olution for a sample personal narrative. . . . . . . . . . . . . . 128
6.2 Illustration of our M-SENSE model. Note that hi1 = hi; hi2 =
ĥi; hi3 = h̃i relate to semantics (xSem), intents (xIntent) and
emotional reactions (xReact) of the ith sentence respectively. . 134
6.3 Performance of sentence encoders for detecting climax in story
with varying length. . . . . . . . . . . . . . . . . . . . . . . . . 150
6.4 Attention analysis of two stories with climax and resolution
sentences related to Maslow’s categories – Esteem (top) and
Love/Belonging (bottom). . . . . . . . . . . . . . . . . . . . . . 152
21
List of Tables
2.1 Correspondence between categories from different narrative
theories as in [Li+17] . . . . . . . . . . . . . . . . . . . . . . . . 55
3.1 Summary of the consolidated in-house datasets used in this
dissertation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
3.2 Statistics of Personal Narratives Corpus (top) and Search-based
Social Commonsense Knowledge (SB-SCK) dataset (bottom). . 66
3.3 Performance of our BERT-based story classifier on the anno-
tated dataset. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
3.4 Statistics of our annotated STORIES dataset. . . . . . . . . . . . 73
3.5 Sentence and Span level inter-annotator agreement . . . . . . 75
4.1 Evaluation results on the held-out test set. We report the accu-
racy (%) scores for different baselines. Boldface indicates the
best accuracy scores for a particular category (intents/emotions). 88
4.2 Results of our ablation study related to the pooling strategy on
the held-out validation set. . . . . . . . . . . . . . . . . . . . . . 90
4.3 Evaluation results on the combined hard similarity dataset. . . 92
4.4 Accuracy scores (%) of different models on Twitter URL Para-
phrasing corpus, TwitterPPDB. Subscript of EVENTBERT model
indicates value of βE. . . . . . . . . . . . . . . . . . . . . . . . . 93
4.5 Accuracy scores (%) of different models on SocialIQA dev and
test dataset. The best accuracy is indicated in boldface. . . . . 94
22 List of Tables
5.1 Test set statistics for explanation generation task: This includes
number of annotated stories and number of character-lines with
motives and emotions. . . . . . . . . . . . . . . . . . . . . . . . 113
5.2 Automatic evaluation results on (a) Personal Narratives cor-
pus & (b) STORYCOMMONSENSE dataset. Bold face indicates
leading results for the corresponding metric. . . . . . . . . . . 115
5.3 State classification performance under supervised settings. ZS:
Zero-Shot Settings, T-Tuned Hyperparameters as reported in
[BC19] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
5.4 Automatic evaluation metrics on ED test set. Ensem-SCS+:
model incorporating our learned embeddings. . . . . . . . . . 124
6.1 Statistics of our annotated STORIES dataset. . . . . . . . . . . . 133
6.2 Evaluation Results of different models for detecting climax (C)
and resolution (R) in short personal narratives. We report F1
score per class & percent mean annotation distance (D) for
these models. We use ↑, ↓ to indicate if higher or lower values
mean better performance respectively. . . . . . . . . . . . . . . 145
6.3 Ablation Results: We report F1 score per class (Climax and
Resolution) with non-default modeling choices for individual
components of our M-SENSE model. . . . . . . . . . . . . . . . 147
6.4 Results of evaluation on TRIPOD dataset. We report Mean An-
notation Distance (%) D results for identifying TP4 and TP5
relevant to this work. . . . . . . . . . . . . . . . . . . . . . . . 154
23
Chapter 1
Introduction
1.1 The Ubiquity and Importance of Narratives
“The narratives of the world are numberless. Narrative is first and
foremost a prodigious variety of genres, themselves distributed amongst
different substances as though any material were fit to receive mans
stories. Able to be carried by articulated language, spoken or written,
fixed or moving images, gestures, and the ordered mixture of all these
substances; narrative is present in myth, legend, fable, tale, novella, epic,
history, tragedy, drama, comedy, mime, painting (think of Carpaccios
Saint Ursula), stained glass windows, cinema, comics, news item,
conversation.”
BARTHES [BAR66; BD75]
Narratives are one of the most common yet powerful means of commu-
nication used to enhance engagement with people’s issues and understand-
ing of the social world. Psychologist Robyn Dawes [Daw99] even claimed
that humans are “the primates whose cognitive capacity shuts down in the
absence of a story”. Regardless of ethnicity, language, and enculturation,
the ubiquity of narratives has been emphasized in several interdisciplinary
academic studies, including literary studies, anthropology, sociolinguistics,
psychology, artificial intelligence, to list a few [Cha80]. This is reflected in
24 Chapter 1. Introduction
Barthes’ analysis of narrative [BD75]. Because of the pervasiveness of narra-
tive in our lives, it is viewed as an essential aspect of making sense of one’s
own experiences, underpinning everyday thinking and expression [SEG01].
The themes and characters in these stories reflect real-world conflicts, solu-
tions, humor, cultural values, people’s psychological states, and their person-
ality. Bruner [Bru09] argued that social cognition is mediated by a special-
ized mode, referred to as the “narrative mode”, which functions by granting
causal efficacy onto psychological states in determining the behavior of the
self and others, an idea that explains folk psychology[Hut07; Hut12]. More-
over, stories tend to form the basis of our memories, thoughts, and knowl-
edge as information stored as a narrative is quickly interpreted and better
remembered than those that are organized into non-narrative frameworks
[GOK; WJ14]. In this work, we use the terms narratives and stories inter-
changeably.
As stories present different facets of the social world, humans constantly
hypothesize and represent mental states of the various interactants (or par-
ticipants) in social situations according to their social actions [SK03; BST09].
This cognitive capability to infer and represent one’s own and other people’s
mental states (e.g., motivations, emotions, thoughts, beliefs, desires, and at-
titudes) is referred to as mentalizing or theory-of-mind (ToM). Beyond inter-
preting the social world, this complex of abilities enables us to understand
prosocial behavior such as to empathize, build peer relationships, form judg-
ments, provide care, to name a few [Eis14; WM08; Imu+16]. This mentalizing
network is considered to be common to social cognition and narrative com-
prehension involving ToM as a common component in which people simu-
late the mental states of other people (or characters). Mentalizing promotes
the construction of a mental model of the story and is deemed essential for
enhanced story comprehension capability. On the flip side, narratives play
a potent role in inferring mental states and personality traits with the help
1.2. Research Goal 25
of social knowledge related to the real-world, evoking the social-cognitive
mechanisms. Repeated evocation through regular engagement with stories
contributes to the improvement of social cognition [MO08; MJ09]. All this
has led several theorists and researchers to suggest how stories exert a pow-
erful influence on social cognition and vice versa [Mar18; Oat99; Hog03].
1.2 Research Goal
Relating Mentalizing and Narrative Comprehension
A growing body of work has been developed in neuroscience concerning
the interdependence between mentalizing and narratives, [GW02; GPHL08;
CSG98; CWC11]. Several neuroimaging studies have emphasized how the
overlapping brain regions implicated for both story comprehension, and men-
talizing reflect their interdependence – (a) narratives act as an instrument
in the evocation of mentalizing processes, i.e., reading more stories in one’s
lifetime and analyzing characters’ behavior in stories contribute to greater
activation of mentalizing network [Fer+08; Mar11; Tam+16b; MG17], and (b)
enhanced mentalizing ability is closely linked to exhibiting improved narra-
tive processing skills owing to the necessity of inferring characters’ mental
states and understanding their complex social relations present in narratives
[Mar+06; AP; Fer13; McK92; LT18; Kim14]. This interdependence is often
linked to the acquisition of an articulated mental language, comprising elab-
orate social and emotional vocabulary. Although the mutual influence of
mentalizing and narrative comprehension has received the most empirical
attention in the field of neuroscience, it is still a topic open to much more in-
vestigation in AI research and, indeed, essential to impart social intelligence
to machines.
26 Chapter 1. Introduction
Fee g
Fee g
M e
M e
Se f
O he
Mentali ing
Narrati e Comprehension
Ho do e model social e ents be ond te t
representations, i.e., incorporate pragmatic
aspects & le erage social situational
information?
Ho do e infer characters' mental states &
track their shifts ith respect to the
sequence of e ents in a narrati e ?
Ho do e detect ke structural elements
of the narrati e -- Clima & Resolution?
Ho does the protagonist's ps chological
states help model narrati e structure?
FIGURE 1.1: Overview of our goal: From modeling each social
event through a pragmatic lens to inferring trajectories of char-
acters’ mental states over sequences of events in narratives to
fleshing out details of high-level structural components of the
narrative, we leverage the influence between narrative compre-
hension and mentalizing (or ToM) and demonstrate how they
contribute towards building improved AI systems.
The primary goal of this dissertation is to develop modular computa-
tional models that will leverage the interdependence between mentalizing
and narrative comprehension to model specific aspects of socio-cognitive
processes and further the research towards building AI systems with social
awareness. The interplay between them is reflected in the process of story-
telling where:
• Narrators present a story with a specific sequence of events necessitat-
ing the social and situational interpretation of events.
• Perceivers construct a unified, coherent representation of the story by
drawing inferences about the mental states of people (or intentionality
1.2. Research Goal 27
of participants) considering their social interactions and the chronolog-
ical relationship between event sequences.
• Perceivers make sense of the narrative by deriving the theme and rec-
ognizing episode boundaries that represent the high-level story struc-
ture.
Figure 1.1 provides an illustration of our overarching goal. We capture this
mutual influence between narrative comprehension and mentalizing by fo-
cusing on the following functional modules:
• Developing a computational model that produces social situational rep-
resentation of events that can dispel the ambiguities in the interpreta-
tion of the text using social commonsense knowledge.
• Constructing mental models of characters in stories by integrating the
learned representation of events computed using social commonsense
knowledge and dynamically tracking the shifts in their mental states
related to the events in the narrative.
• Demonstrating the ability of these mental state models to promote ef-
ficient identification of key elements of the narrative structure like cli-
max and resolution. Integration of psychological states of the protago-
nist beyond linguistic information could potentially enhance the story
understanding capacity.
Combining all these three functional modules that introduce new resources
and modeling approaches, we believe our goal would facilitate technological
advancements and research in a variety of disciplines that are either inter-
ested in developing human-centered social cognition or likely to benefit from
such capabilities.
28 Chapter 1. Introduction
1.3 Characteristics of Narrative Data
Narrative data comprise a diverse range of texts, including novels and short
stories, prose and poetry, movie screenplays and synopsis, personal experi-
ences and life stories, oral memoirs, autobiographies and histories. Such di-
verse texts are considered a narrative if they contain an organized sequence
of causally linked events with a meaningful consequence [Rie93]. This de-
scription of the narrative is well-aligned with Bruner’s definition of narra-
tive:
Perhaps its principal property is its inherent sequentiality: a narrative is
composed of a unique sequence of events, mental states, happenings
involving human beings as characters or actors. These are its
constituents. But these constituents do not, as it were, have a life or
meaning of their own. Their meaning is given by their place in the overall
configuration of the sequence as a whole...
BRUNER [BRU90]
Personal Narratives
Given the diverse forms of narrative text, we focus on social media stories
that are told by common people on a daily basis about their personal experi-
ences. Personal narrative is a form of autobiographical storytelling that gives
shape to life experiences. These stories could potentially be unstructured and
discursive, yet are essential social resources that (a) build the identities of the
tellers and the audiences and (b) learn about the temporal and causal rela-
tionships between event sequences. Moreover, personal stories are known
to be brief, diverse, and major sources of commonsense causal information,
centered around social and mental topics more than natural and physical
causality [RBG11; MSG08; GS09].
1.3. Characteristics of Narrative Data 29
Several previous studies [Bro+19; Abb20; Bro20] have recognized “fo-
calization” or “protagonism” as a crucial part of storytelling (or narration).
It is referred to as the fundamental narrative function of putting forth the
perspective of a single person, i.e., the protagonist, in a narrative. While
news stories, histories, movies have masses of individuals, personal narra-
tives usually contain few characters told from the protagonist’s point of view.
By distinguishing the protagonist’s perspectives from all other participants,
protagonism operates by developing insights into other people as relatable
self-proxies even for stories about others [Sto16; DFG11; Lab01]. This means
the narrators describe the social world and draw inferences about the char-
acters or participants from their perspective, sometimes even egocentrically
related. In the vast majority of stories, they not only express their internal
mental states but also impute others’ inner states through their stories. Fur-
ther, this protagonistic approach to the story reflects Bruner’s narrative mode
of inference based on psychological causation. Hence, while a chronological
presentation would explain “how” things happened, we need the protago-
nist’s narrative mode to explain “why” they happened, in other words, what
motivated the events (i.e., intentions) from a given personal perspective and
how their impact was felt (i.e., emotional reactions) [Bru91b; Bru91a; Bro20].
Together, these properties of personal narratives make them suitable for our
research goals. Therefore, we rely on personal narratives obtained from so-
cial media as a vital part of our knowledge extraction, modeling, and evalu-
ation phases across various aspects of this dissertation.
Personal narratives, like other stories, have specific plots, sequences of
events, and actions ordered to highlight specific themes [Pol88]. They con-
tain a representation of the events comprising entities or characters with spe-
cific social roles, group, and cultural context performing planned actions in-
tended to achieve the desired goal state situated within a particular space
and time. In addition to interpreting the explicit and implied psychological
30 Chapter 1. Introduction
states of narrators and other participants in the narrative, there have been
theories that identify key structural elements in personal verbal narratives as
a result of sociolinguistic studies. A seminal work by Labov and Waletzky
[LW97; Lab06] analyzed oral narratives of true personal experience from the
narrators’ lives, obtained via sociolinguistic interviews. Through this nar-
rative analysis, the significance of basic structural components in narratives
[Tho04; TM03; TKM07] is manifested as:
In our opinion, it will not be possible to make very much progress in the
analysis and understanding of these complex [written] narratives until
the simplest and most fundamental narrative structures are analyzed in
direct connection with their originating functions. We suggest that such
fundamental structures are to be found in oral versions of personal
experiences: not the products of expert storytellers that have been retold
many times, but the original production of a representative sample of the
population.
LABOV AND WALETZKY [LW97]
Thus, Labov’s theory of narrative analysis defined the three elements
of the narrative structure: the orientation, the complicating action, and the
evaluation. More recently, this structure has been refined by Labov [Lab06;
Lab72] to include additional elements: the abstract, the resolution, and the
coda. Prior to Labov’s theory, Freytag [Fre94] had proposed a dramatic struc-
ture containing five categories: Exposition, Rising Action, Climax, Falling
Action, and Denouement. Several such theories with different structural la-
bels were proposed [LW97; Lab72; Lab06; Pri12]. However, certain elements
of the narrative structure are correlated across narrative theories. For exam-
ple, Bruner’s “breach in canonicity” [Bru91b] could correspond to (a) Frey-
tag’s “climax” – referring to the “turning point” of the fortunes of the protag-
onist [AH14] or (b) Labov’s “most reportable event” (MRE)– describing the
1.3. Characteristics of Narrative Data 31
event that has the greatest effect upon the goals, motivations and emotions of
the characters (participants) in the narrative [LW97; Lab06] In fact, Labov ar-
gued that the entire story’s purpose is to serve the MRE. Similarly, both Frey-
tag’s and Labov’s theory of narrative structure contain “resolution” as one of
the elements referring to the event that leads to a swift drop in the tension
created by the MRE as one of the final aspects in the narrative. Therefore, it
is possible to identify a functional schema that reconciles with multiple theo-
ries capturing both dramatic tension and the social aspect of online personal
narratives.
G a
At my place of work, there’s a board with all the managers pictures on it.
When I started here as a lead engineer almost two years ago, I wanted to be
on that board. [I decided to work really hard after my first interview for a
management position fell through due to lack of experience in the position.]
It’s been almost several months since then. [I’ve worked every opportunity
to get that experience and it definitely paid off. I got the job and I’ll be on
that manager board!] I’m really happy and proud today !
E i a Reac i
S cia e
M i e Ca a Li k
Ti e
E e C i a
Re i
FIGURE 1.2: Sample Personal Narrative containing highlights
of some of its major characteristics – events with actions, tem-
poral order (time information), causal links, social roles, pro-
tagonist’s goals, motives & emotional reactions, to list a few.
Figure 1.2 shows a tagged sample narrative from Reddit. This excerpt
sheds light on some of the major characteristics of personal stories, given as
follows:
• Events: Narrative contains a sequence of events with actions forming
the outline of the narrative. We give examples of few related events
in the narrative – “I started here as a lead engineer” and “I worked really
hard...”, “my first interview for management position fell through”.
• Temporal Information: It refers to the timeline of events, most often
presented in a piece of chronological order information (may also men-
tion "time" details). For example, The following sequences provide time
32 Chapter 1. Introduction
information and order in which they occur – “I started here as a lead en-
gineer almost two years ago”, “I decided to work really hard after my first
interview..”, and “It’s been almost several months since then. I’ve worked
very hard...”.
• Causal Links: Story events are generally united using causal connec-
tions. A causal link in our example narrative where one event could
trigger the next event in the story is – “I got the job” #→ “I’ll be on that
manager board”.
• Social roles: The behavior and psychological states of a character in
the narrative are determined by capability, situation, and social role. In
the example narrative, social role information like “lead engineer” or
“manager” plays a role in shaping their goals, motives, and emotions
behind their actions.
• Mental States: This indicates the mental states (goals, motives, emo-
tional reactions, desires, beliefs, etc.) of the characters in the narrative.
The actions of a character could potentially cause mental state shifts de-
pending on the social situation given in the event. Some of this may be
explicitly expressed in the narrative, while others require inference abil-
ities to identify inherent mental states. Narrator/Protagonist’s mental
state in the example narrative is given as follows – the phrase “I’m re-
ally happy and proud” represents the emotional reaction, “Goal state” is
explicitly expressed as – “I want to be on that board” (implicit inference:
to become a manager), “Motive” behind an action is – “worked every
opportunity to get the experience”. Here, the goal state refers to the cog-
nitive representation of a desired end state [FF07]. Underlying all of
these goals, though, is motivation, or the psychological driving force
that enables action in the pursuit of that goal [AGL35].
1.4. Research Problems 33
• Narrative Structure: Correlated across prior narrative theories, we point
out to the key elements of narrative structure – MRE/climax and reso-
lution. In Figure 1.2, we mark the boundaries of climax and resolution
with red and green square braces ([...], [...]) respectively.
In the past, different computation models leveraging the characteristics of
narrative data have been developed towards enhancing aspects of story un-
derstanding capabilities[Bam12; Fic+17]. Some of these works include mod-
eling event schemata and narrative chains, narrative causality, characters’
interpersonal relationships, narrative and open domain question answering,
understanding narrative structures, learning scripts, story plot generation
and creative or artistic storytelling, story ending prediction, to list a few
[VVZO15; SCM16; Joc13; Fin12; CJ08]. Several such approaches have empha-
sized the importance of (a) modeling the effect of events on characters’ men-
tal states on one hand [TFS95; Kal+02] and (b) interpreting causal and tem-
poral relationships between events and identifying the ensuing structures in
terms of the characters’ motivation and affective states, on the other [Ger13;
RTC05; Hap94]. Of particular interest in this dissertation, we explore these
aspects by relying on personal stories collected from social media.
1.4 Research Problems
As described in Section 1.2, the focus of this dissertation is to develop and
evaluate computational functional modules that exploits the link between
mentalizing and narrative comprehension to capture specific aspects of socio-
cognitive processes. Towards our goal, we formulate the research problems
and propose solutions to overcome a subset of their associated challenges by
applying information extraction, data mining, and deep learning techniques
on an open-domain dataset of personal narratives from social media.
34 Chapter 1. Introduction
S1: Ph ician hed o he ho pi al
S2: Ph ician hed o hi edding
S3: Doc o i i hi clinic
S4: Philan h opi i i he clinic
S5: Dono goe o he clinic
Concep Ne
ATOMIC
SB-SCK
x S1
x S2
x S3
x S4
x S5
Lea ning Social E en Rep e en a ion
E entBERT:
E ent Embedding
Model
M dad j ned 60 and I j lo e m dad o bi .
La fe da ha e been a olle coa e ide fo
me. M dad a diagno ed i h CoVID-19 fe da
back and kep on en ila o . I hed o he ho pi al
and fel o pained o ee m ong dad n o ick
and meek. Af e a eek of ea men , he ha finall
eco e ed and no I feel o elie ed.
NEMO:
Narrati e Entit
Mental Model
to get treatment
to reco er from illness
to sta health
Dad
to sa e his dad
to take care of his dad
to c re his father
I (Narrator)
Modeling H man Mo i e and Emo ion
MSENSE:
Narrati e Str ct re
Model
Modeling Na a i e S c e
M dad j ned 60 and I j lo e m dad o bi .
La fe da ha e been a olle coa e ide fo
me. M dad a diagno ed i h CoVID-19 fe da
back and kep on en ila o . I hed o he ho pi al
and fel o pained o ee m ong dad n o ick
and meek. Af e a eek of ea men , he ha finall
eco e ed and no I feel o elie ed.
M dad j ned 60 and I j lo e
m dad o bi . La fe da ha e
been a olle coa e ide fo me. M
dad a diagno ed i h CoVID-19
fe da back and kep on
en ila o . I hed o he ho pi al
and fel o pained o ee m ong
dad n o ick and meek. Af e a
eek of ea men , he ha finall
eco e ed and no I feel o elie ed.
Clima Resol tion
FIGURE 1.3: Overview of the Research Tasks tackled in this dis-
sertation. (a) Social Event Embeddings: Sample event text in-
puts are provided on the left, and the expected relative posi-
tions of event texts in the learned embedding space are shown
on the right. (b) Narrative Entity Mental Model: Example nar-
rative text input is shown on the left, and the sample genera-
tions of intents of dad and son (narrator) are given on the right.
(c) Narrative Structure Model: On the left, we display the input
narrative text. On the right, we have the output of the sentence
labeling task highlighting the climax and resolution sentences.
Figure 1.3 gives an overview of the research problems we aim to tackle in
this dissertation. We present a brief outline of the research tasks (RT) and the
proposed methods as follows:
• RT1: Learning Knowledge-Enriched Social Event Representation
Personal narratives consist of an account of a series of causally-related
events or experiences from the narrator’s point of view. These experi-
ences usually unfold naturally into a temporally extended daily event.
The meaning of an event sentence or phrase can vary depending on
1.4. Research Problems 35
several factors like the speaker’s perspective or the related domain.
Prior approaches have relied on syntactic and semantic features to learn
distributed representation of structured events [LDL18a; LDL18b; GWC16;
Mod16]. However, there are several shortcomings with these embed-
dings as they cannot efficiently capture the relationship between events
that are closer at the pragmatic space beyond understanding within lex-
ical, syntactic, or semantic representation space. Contemporary defini-
tions of pragmatic aspects of language include behavior that includes
social, emotional, and communicative aspects of language [Ada+05;
Par+17]. In the context of event representations, the pragmatic proper-
ties can specifically refer to the human’s inferred implicit understand-
ing of event actors’ intents, beliefs, and feelings or reactions [Woo76;
HN78].
In order to incorporate pragmatic implications of events, we focus pri-
marily on social events, i.e., events depicting social situations and in-
teractions. This is pertinent for our larger goal of modeling personal
narratives. For example, as shown in Figure 1.3a, we ideally expect the
following two events to be similar in the embedding space: “Physician
rushed to the hospital” and “Doctor visits his clinic”. However, most of
the prior embedding approaches put the following two events closer,
though they are unconnected: “Physician rushed to the hospital” and
“Physician rushed to his wedding”. Though they have strong lexical over-
lap and contain similar action verbs, they refer to different events with
different intentionality. Similarly, there is a difference in how humans
process the following two event texts in Figure 1.3a: “Doctor visits his
clinic” and “Philanthropist visits the clinic”. While the former has an in-
tent of attending to his patients, the philanthropist’s action may involve
an act of goodwill. The social role information (e.g., donor vs. doctor)
provides additional information about how we understand the events.
36 Chapter 1. Introduction
Thus, it becomes important to understand each event through a prag-
matic lens for better narrative comprehension, and improved mental-
izing capabilities [PM16; BMJ17]. Therefore, we solve this problem of
computing a social event embedding by extracting semantic proper-
ties from the event texts and integrating salient knowledge that encom-
passes the implicit pragmatic abilities. This is considered a precursor
to developing mental models of characters in narratives.
To this end, we propose to train our models with social commonsense
knowledge about events focusing specifically on the intents and emo-
tional reactions of event participants. We obtain commonsense knowl-
edge assertions from ConceptNet [SCH17], ATOMIC
[Sap+19a; Ras+18a] and also by aggregating more noisy commonsense
knowledge using web-based data mining techniques. This new com-
monsense knowledge dataset is referred to as Search-based Social Com-
monsense Knowledge (SB-SCK). Subsequently, we employ a fine-tuned
BERT-based encoder, called EVENTBERT, to effectively embed social
events with semantic and pragmatic attributes. Empirically, we demon-
strate the capabilities of our social event embeddings by a strong per-
formance on many downstream tasks like event similarity, reasoning,
and paraphrase detection.
• RT2: Modeling Human Motives and Emotions from Short Personal
Narratives
One of the central objectives of this dissertation is to foster research in
imparting mentalizing abilities to machines. With such a grand chal-
lenge, we take a small step in this direction by developing models that
can embed and explain human motives and emotional reactions. Un-
derstanding a story not only requires keeping track of the sequence of
events happening in the story but also inferring and interpreting the
1.4. Research Problems 37
mental states of characters and interactions between them. It is thus
natural to consider the usage of stories towards building a model for
inferring aspects of people’s mental states from their actions in social
situations.
One of the key challenges lies with difficulty to acquire annotated data
containing explanations of stated or implied intents or reactions of char-
acters to events in the narrative. Therefore, we address this challenge
by adopting a combination of web-based data mining and information
extraction (IE) strategies to automatically aggregate noisy expressions
of motivations and emotional reactions related to specific events and
social roles in the text. This results in a weakly-annotated dataset con-
taining characters motivations and emotions from personal narratives.
We also utilize the sentence-level social commonsense knowledge as-
sertions, SB-SCK, already extracted for learning social event embed-
dings.
Next, we focus on devising models to continuously track shifts in men-
tal states of character and effectively embed and generate their text ex-
planations. Note that these explanations are not always stated in the
narrative text, but the implied mental state explanations are derived us-
ing a knowledge enrichment and entity tracking module implemented
using external memory. In Figure 1.3b, we show a sample narrative
with two characters – a father and son (narrator). The son (narrator)
describes his experience of his father getting diagnosed and recovering
from CoVID-19. Take the sentence – “I rushed to the hospital”, the in-
tent of the narrator (“I”) is “to take care of his dad” or “to be worried
for his dad”. To produce such explanations, it is necessary to consider
the story context and social role because modifying the context and so-
cial role information could significantly alter the corresponding intent
38 Chapter 1. Introduction
and emotional reaction behind the same action (as shown in Figure 1.3a
and described under RT1).
For our modeling purpose, we implement a Transformer-based encoder-
decoder architecture, referred to as NEMO 1. We augment this encoder-
decoder architecture with our pretrained knowledge-enrichment mod-
ule, EVENTBERT, to incorporate social commonsense knowledge. Fi-
nally, we employ dynamic state tracking of entities with the help of an
entity-based memory module to produce contextual embeddings and
explanations of characters mental states. Experimentally, we demon-
strate the effectiveness of our model on a benchmark character psychol-
ogy dataset called STORYCOMMONSENSE [Ras+18c] and a downstream
empathetic response generation task.
• RT3: Modeling Narrative Structure in Short Personal Narratives
Since personal stories obtained from social media are idiosyncratic and
noisy, it becomes increasingly difficult to automatically interpret these
stories. Moreover, they hardly adhere to any structural conventions in
narratives. Following narrative theories proposed by Freytag, Prince,
Bruner, Labov & Waletzky [Cut16; Bru91b; LW97], we draw on the
prominent elements of narrative structure (MRE/climax and resolu-
tion) that correlate across multiple theories and are deemed appropriate
for the informal nature of narratives. This work aims to leverage com-
putational methods at the intersection of information retrieval, NLP,
and aspects of psychology and automatically predict the key elements
of narrative structure – MRE and resolution.
We construct a STORIES dataset 2 corpus comprising personal narra-
tives from Reddit with fine-grained manual highlights of climax and
resolution. Drawing on prior studies regarding the relevance of the
1Short for Narrative Entity Mental mOdel
2Short for STructures Of ReddIt PEsonal Stories
1.5. Overview of Contributions 39
protagonist’s mental states, we hypothesize that mental state embed-
dings derived from our NEMO model could potentially provide an ad-
vantage in determining the boundaries of structural components of the
narrative. Therefore, we train an end-to-end neural network called
M-SENSE3 as a sentence labeling task and infuse protagonist’s men-
tal state embeddings in addition to linguistic features though a multi-
fusion feature technique to automatically identify these elements of
narrative structure. In Figure 1.3c, we show sample prediction of cli-
max (red) and resolution (green) by our M-SENSE model that exploits
the narrator’s (protagonist) shift in intent and emotional reactions for
the classification task. Overall, we are able to achieve ∼ 20% higher
success in detecting climax and resolution in short personal narratives
than the previous state-of-the-art methods.
1.5 Overview of Contributions
The goal is to establish that endowing AI agents with social awareness can
result in better performance across various tasks and environments and lead
to the development of models that are better able to meet human preferences
and adapt to new circumstances. In service of this goal, this dissertation
makes the following contributions:
• A representation learning framework that learns to:
– Disentangle semantic and pragmatic attributes from social event
descriptions. Here pragmatic properties refer to the human’s in-
ferred implicit understanding of event actors’ intents, beliefs, and
reactions.
3Short for Mental State Enriched Narrative Structure modEl
40 Chapter 1. Introduction
– Encapsulate both the attributes into an embedding that can move
beyond simple linguistic structures and dispel apparent ambigui-
ties in the true sense of their context and meaning.
• Transferable social event embeddings demonstrating impressive per-
formance gains in downstream tasks – event similarity, reasoning about
social interactions, and paraphrase detection task.
• Automatic data acquisition method based on web-based data mining
and information extraction (IE) strategies for constructing a corpus con-
taining weak-annotations of implicit and explicit motivation and emo-
tion text expressions. This can be applied to different textual domains.
• Two datasets – personal narratives corpus and a search-based social
commonsense knowledge dataset (SB-SCK) for modeling human mo-
tives and emotions from short first-person stories. While the personal
narratives corpus contains explicit characters’ motivations and emo-
tions conditioned on the entire story context, our SB-SCK comprises
phrase or sentence-level implicit mental state mappings associated with
social events.
• Transformer-based story understanding model augmented with exter-
nal memory modules that infuse social commonsense knowledge and
dynamically track entities’ mental states.
• STORIES dataset consisting of short personal narratives with manual
annotations of key categories of high-level narrative structure, specifi-
cally climax and resolution.
• An end-to-end computational model based on a multi-feature fusion
approach for automatically identifying climax and prediction using the
protagonist’s mental representations.
1.6. Organization of Dissertation 41
The models The above research has also led to the production of research ar-
tifacts, including peer-reviewed publications [VR21a; VR21b], datasets and
tools to support these projects 4 and make them reproducible for other re-
searchers.
1.6 Organization of Dissertation
The rest of this dissertation is organized as follows:
• Chapter 2 provides details of pertinent background information and
a survey of the related work. First, we explore the literature that ex-
plains the mutual relationship between narrative processing and ToM
and how they play a critical role in understanding human social behav-
ior and promoting social cognition. Next, we discuss the recent works
on representation learning for social events and examine other relevant
studies that have benefited from commonsense knowledge. Follow-
ing that, we summarize other story understanding and text genera-
tion efforts that are directed towards inferring characters’ psycholog-
ical states. Finally, we refer to prior approaches in the field of narra-
tology and NLP that investigate the story structure based on narrative
theories and describe the techniques used to eventually predict the core
components of narrative structure.
• Chapter 3 presents the datasets constructed as a part of this disserta-
tion. We describe the data collection pipeline and the annotation setup
employed to obtain data for training and evaluating our models. For
4https://github.com/pralav
42 Chapter 1. Introduction
modeling social events and characters’ mental states, we delineate web-
based knowledge mining and information extraction techniques to au-
tomatically aggregate weakly-annotated data. Next, we outline our an-
notation setup that allows for fine-grained span-level highlighting of
key elements of narrative structure, i.e., climax and resolution in short
personal narratives. We explain different span and sentence-level mea-
sures to compute inter-annotator agreement for our manual data col-
lection task and show that we can achieve a substantial inter-annotator
agreement for both the categories of narrative structure.
• Chapter 4 proposes a representation learning framework that effec-
tively embeds both semantic and pragmatic aspects of social events
with the help of a growing set of social commonsense knowledge as-
sertions acquired from different domains. We utilize knowledge as-
sertions from ATOMIC [SAP+19A], CONCEPTNET [LS04] and our ag-
gregated dataset, SB-SCK [VR21a], for training our BERT-based social
event embedding models. Experimentally, we demonstrate the bene-
fits of applying our social event representation in various downstream
tasks like event similarity, reasoning, and paraphrase detection tasks.
• Chapter 5 describes a Transformer-based architecture to model char-
acters’ motives and emotions from personal narratives. We develop a
model that learns to produce contextual embeddings and explanations
of characters’ mental states by integrating external knowledge along
with prior narrative context and mental state encodings. We lever-
age the social event embeddings explained in Chapter 4 and utilize the
weakly-annotated personal narratives to train our model and demon-
strate its effectiveness on the benchmark character psychology dataset.
Additionally, we show that the learned mental state embeddings can
be applied in downstream tasks like empathetic response generation.
1.6. Organization of Dissertation 43
• Chapter 6 analyzes the importance of studying the links between cog-
nitive and linguistic aspects in narrative comprehension. In this chap-
ter, we probe this interdependence by jointly modeling textual seman-
tics and mental language in narratives for improved detection of narra-
tive structure categories. We implement an end-to-end computational
model that leverages the protagonist’s mental state information and in-
tegrates their representations with contextual semantic embeddings us-
ing a multi-feature fusion approach to model high-level narrative struc-
ture. We show that our model surpasses several prior zero-shot and
supervised baselines for identifying climax and resolution.
• In Chapter 7, we first summarize the contributions of this dissertation.
Next, we highlight the limitations of our work and discuss the direc-
tions for future research.
45
Chapter 2
Background & Related Work
Our current research explores how stories are central to human cognition
and how they influence our understanding of the world and events that un-
fold around us. The notion that narratives could facilitate inference of others’
mental states, referred to as mentalizing has very early origins[Hak00]. As
early as 330 BCE, Aristotle mentions in Poetics that “man tends most towards
representation and learns his first lessons through representation”. Poetics is
one of the earliest surviving works of dramatic theory, elucidating it as a lan-
guage that represents and imitates life. Further, he argued that stories convey
reality about the world even though fictional stories may not be a completely
accurate representation of truth [Oat99]. In the field of psychology and cer-
tain theories in narratology, narratives are described as representations of
temporally coherent events pivoted around the goals of a protagonist, typ-
ically following a schema or structure consisting of elements, including a
setting, an inciting incident, a rising action, a resolution, and a denouement
[TVDB85; Rum75].
Since stories are commonly about people, their mental states, and their
relationships [CS96], mentalizing or Theory of Mind might be one of the so-
cial cognitive processes engaged by narratives [Hog03; Zun06] involving the
ability to infer beliefs, thoughts, motives, emotional reactions of other peo-
ple. In this chapter, we focus on reviewing the previous studies that aspects
of narrative comprehension, mentalizing, and the well-established positive
46 Chapter 2. Background & Related Work
impact of their relationship.
In the following sections, we discuss several interdisciplinary studies that
present the importance of mentalizing in navigating the social world and its
influence on narrative comprehension. Following this, we survey computa-
tional approaches investigated earlier on each of these fronts and provide a
lead to how our work tackles some of the existing challenges towards accom-
plishing our overall goal.
2.1 Background
Overview of Mentalizing and Its Relevance to Narratives
The ability to anticipate, represent and reason about what others will think,
feel or do in different situations is central to social cognition. Consider a
scenario where one experiences difficulty predicting social signals or impli-
cations like agreeable people tend to be courteous and warm or exhausted
people tend to show anger; it can lead to a complicated social life filled with
misconceptions, faux pas, and miscommunication. Fortunately, humans can
predict others’ probable social actions through either their personality traits
(e.g., agreeableness) or mental states (e.g., tiredness). Neuroimaging stud-
ies have also suggested the mentalizing, or “theory of mind” network plays
a role in social cognitive processing more broadly, including reflecting on
personality characteristics of one’s self and others, inferring mental states in-
cluding emotion processing and intentions from actions.
A model proposed by Shamay-Tsoory et al. [STAP07] divide ToM into
two separate systems, namely cognitive ToM and affective ToM. Cognitive
ToM is described as involved in processing inferences about others’ beliefs
and intentions, whereas affective ToM is involved in processing inferences
about other peoples emotions and feelings. This model describes affective
2.1. Background 47
and cognitive ToM involving common and different brain areas studied by
Poletti, Enrici, and Adenzato. Several studies in the field of personality psy-
chology [Ryc04] have some congruence with the above idea of cognitive-
behavioral models. However, in these studies, personality is defined as “A
dynamic and organized set of characteristics possessed by a person that uniquely
influences their cognition, motivations, and behaviors in various situations”
[Ryc04]. The dimensional theories like the “Big Five” model or theories that
propose additional six personality dimensions are known to be tailored to
understand stereotypes, mind perception, and common behaviors. A work
by Tamir et al. [TT18] studied if these low dimensional personality dimen-
sional theories can efficiently aid social predictions. It was found that much
of the richness of others’ minds can indeed be compressed to coordinates in
low-dimensional trait space. Similarly, there is a reasonable amount of lit-
erature [Tam+16a; GGW07] that support how the representation of people’s
momentary mental states into lower dimension can facilitate social predic-
tion in humans.
It is often highlighted how engagement with narratives encompass a deeply
embodied mental simulation [Zwa04] and how narratives offer encapsulated
abstract representations of concrete work scenarios and people. Several stud-
ies point to a common implication that stories help to foster a better under-
standing of other people. The relationship between narratives and social cog-
nition has been investigated with school children [Mar+06]. Given the expec-
tation that children who are exposed to more stories tend to develop mental-
izing capabilities more rapidly than other children, different approaches have
been used to study this hypothesis, and the results have turned in support
of this notion. Maternal expertise in choosing children’s literature predicted
better empathy, socio-emotional adjustment, and improved false-belief rea-
soning in children [MTM10; AA09].
Kimhi [Kim14] discussed the development of mentalizing ability across
48 Chapter 2. Background & Related Work
the life span in persons focusing on its social and academic manifestations
that are critical for everyday life skills. Considering the social manifesta-
tions of ToM in symbolic play, conversation, and autobiographical memory
and academic manifestations of ToM in reading comprehensions, narrative
skills, and writing abilities, many related works, including the literature with
mixed evidence on the significance [BCEGB00] and direction of association
[JA00; Suw+12] were discussed. However, there is consensus that children’s
ability to understand others mental states, though it may not be sufficient
by itself, appears necessary for engaging in adaptive and positive behavior
[Ast04] and these abilities are reflected in their social interactions [Hug98].
This is further supported by results from an assessment of individuals with
autism. Even their high verbal and intellectual levels do not aid in navigat-
ing effectively in social and academic settings exacerbated by the diminished
attention to social cues and difficulty in social adaptive behavior [Kli+02;
BZ13].
Consequently, interventions have been proposed and developed to en-
hance ToM in children and young people with autism spectrum conditions.
Specific ToM socio-cognitive training [Gou+11; PP13] (e.g., Thought Bubble
Training) has been found to enhance the targeted skills; yet, generalization to
other skills generalization to the natural environment has been minimal for
the most part. More sophisticated interventions (e.g., dyadic & group social
interventions) involve training strategies [MKD07; Bau07; BZ+13] that inte-
grate social interaction training in children’s natural settings with the main
social interactive agents (teachers, peers, and parents) involved along with
specific sociocognitive abilities. With such training and improvement in so-
cial cognition, language, and self-regulation [Len03], it was observed there
was a general decrease in children’s aggressive behaviors and an increase in
pro-social acts throughout their preschool years [FS73; Per+07].
Construed broadly, mentalizing covers a range of capabilities such as
2.2. Modeling Human Social Behaviour 49
perspective-taking, simulating mental states, identifying character traits, so-
cial and emotional reasoning. Linked closely to the acquisition of social vo-
cabulary and processing of social information, mentalizing is critical for facil-
itating active engagement in social and academic activities. Taking a leaf out
of the various experiments explained above, we are interested in develop-
ing learning techniques directed at analyzing stories to augment mentalizing
skills. Therefore, in this work, we incrementally aggregate social common-
sense knowledge in the form of intents and emotional reactions and further
improve the narrative processing skills. For our dissertation, we use the ag-
gregated knowledge and also adapt quickly to the different social contexts
by harnessing the transferability to personal narratives. We, therefore, focus
on addressing a subset of challenges to represent people’s mental states or
personalities and draw insights into people’s social behavior.
2.2 Modeling Human Social Behaviour
In the light of our work, it is crucial to review the literature that adopts dif-
ferent mechanisms to model human social behavior. We investigate the back-
ground work on a set of methods in the context of building mentalizing abil-
ities towards a long-term goal of socially intelligent systems. With increas-
ing human-machine hybrid technologies, the real-world interactions with AI
systems are often stilted. It is essential to acknowledge the challenges associ-
ated with the understanding of explicitly unstated desires, emotional states,
and intentions of users from language. Misinterpretation of users’ implied
intents and implicit beliefs from natural language could have dramatic real-
world consequences. Building AI systems that can interact with humans flu-
ently will require machines to share common knowledge about how people
will act, communicate and react under specific contexts and circumstances.
50 Chapter 2. Background & Related Work
Many AI researchers have attempted to adopt these ideas and build sys-
tems that can encode personality traits or mental states into representations
and utilize them in different social contexts. Bridewell and Isaac (2011) [BI11]
introduced a computational framework for common, complex, and under-
investigated aspects of human social behavior like deception based on the
capacity to reason about the goals of other agents, resting on mental state as-
cription. Fahlman [Fah11] proposed a knowledge-base system, Scone, used
to emulate some aspects of human mental behavior and support human-
like commonsense reasoning and language understanding. Beyond domain-
specific knowledge, social understanding requires generic knowledge about
social interactions and their ensuing effects on mental states. Early research
conducted by Wilensky along these lines inferred the intentions of interacting
agents while Dyer dealt with extracting morals from social scenarios. Win-
ston’s [Win14] Genesis system was developed to understand and generate
stories using computational models that use commonsense inference rules
and concept patterns. This includes their work to support question answer-
ing, personality or mood-based interpretation, and summarization of stories.
One possible direction explored to overcome shortcomings of AI systems
in navigating the social world is to endow them with commonsense knowl-
edge. While there have been significant efforts to create knowledge bases like
Cyc [Len+90] and ConceptNet [LS04], there is a paucity of inferential knowl-
edge related to people’s behavior in the form of their motivations and their
reactions. Using stories to define a space of acceptable behaviors, Harrison
et al. [HR16] developed a technique to prevent autonomous agents from ex-
hibiting anti-social or psychotic behaviors. Recently, knowledge bases such
as Event2Mind [Ras+18a], and ATOMIC [Sap+19a] are tailored to capture the
mental states of people linked to day-to-day events. Another line of work to-
wards improving automatic recognition and interpretation of human social
signals in AI systems relies on inferring personality traits. Considering that
2.2. Modeling Human Social Behaviour 51
personality compels a tendency on many aspects of human behavior, mental
states, and affective reactions, there is an enormous opportunity for sensing
spontaneous natural user behavior to facilitate efficient interaction in social
settings. [SHR18] presents a hypothesis that users with similar personali-
ties are expected to display mutual behavioral patterns when cooperating
through social networks. Imitating personal style in dialogue systems has
demonstrated promising results. Some of the early efforts include modeling
personas of movie characters and incorporating speaker persona in dialogue
models based on speaking style characterized by natural language sentences
[BOS13; Li+16]. Despite recent successes, it is still incredibly challenging to
build socially intelligent agents that can understand humans and engage in
socially competent conversations that involve empathy, cooperation, persua-
sion, care-giving, to list a few.
Recent approaches have focused on reflecting upon the concepts of hu-
man ToM to attribute mental states such as intentions and beliefs to inan-
imate objects. Some notable approaches include those that use hierarchi-
cal Bayesian inference [Bak+17; YDF08; BST11] or artificial neural networks
[LP18; Lan+17b]. The former is generally cognitively-inspired and suggests
the existence of a “psychology engine” in cognitive agents to process ToM
computations, while the latter achieves imparting ToM to a certain degree
by characterizing different species of deep reinforcement learning agents. In
addition to these methods, there also have been multi-agent models rooted
in statistical machine learning theory and robotics. These approaches have
generally evaluated simulations of the theory of mind in relatively simple
situations. However, there is very limited work in this area of combining
the theory of mind and language. It is also well known that two of the most
fundamental elements of human cognitive capabilities are the ability to com-
municate through complex language systems and the attainment of a theory
of mind. Interestingly, both language and theory of mind develop relatively
52 Chapter 2. Background & Related Work
at the same time in a persons life. Language is a fundamental element in
understanding emotions, thoughts, and actions that are constitutive of both
experiences and perceptions. Early ToM abilities facilitate the development
of early language abilities, while more complex language abilities are a pre-
cursor to complex mentalizing (or ToM) abilities. Language, ToM, and social
skills are all connected and interdependent. Hence, we focus on bridging
this gap in research towards understanding language and the development
of mentalizing abilities.
Towards this goal, it is important to produce an efficient social event
representation that can contribute to modeling the motives and emotions of
characters. The primary reason behind this is because narratives consist of a
sequence of events about the social situations presented to the characters in
the narrative [AGS83; Ger13]. Understanding the meaning of social events
requires representing them at syntactic, semantic, and pragmatic levels to
embed them in the context of commonsense knowledge. An ample amount
of studies has been centered around constructing situation models to under-
stand a text and the events described in them [MM09; Zwa+98]. Situation
models involve dynamic processes that allow them to fuse information from
the event text description with world knowledge and produce an integrated
event representation [Zwa+98; ST93]. Thus, such representations have to be
extended to narratives by considering the story context, entities, and actions
and how they are connected through events and situational relationships.
Such approaches enhance AI systems’ capabilities to better recognize char-
acters’ planned actions and their intentionality towards achieving desired
states [TBS89].
Many computational approaches have been attempted to model the mo-
tives, emotions, desires, and goals of characters in the narrative. A recent
body of work [Gui+17; Gho+17] is related to detecting emotional stimula-
tion in narratives and utilizes specific attributes like sentiment or affect states
2.3. Modeling Narrative Structure 53
based on LIWC categories. A close work used to infer character mental states
in short five-sentence commonsense stories based on rich low-level annota-
tions of intent and emotions [Ras+18c]. In our work, we develop automatic
techniques to extract weakly-annotated mental state expressions from nat-
ural variable-length personal narratives and propose a method to leverage
aggregated social commonsense knowledge to efficiently generate explana-
tions of motivation and emotion states of characters in the narrative. Further,
we address the modeling challenges by incorporating social commonsense
knowledge from social events and employing entity modeling for tracking
the mental states of characters in the narrative.
In this dissertation, the first aspect of our research will focus on learning
to model the mental states of people by integrating commonsense knowledge
of social behavior with knowledge acquired from a textual narrative corpus.
The representations learned by such models are more likely to yield AI sys-
tems that are generally better at perceiving, understanding, and responding
effectively to different social situations. With commonsense knowledge act-
ing as the basis of mentalizing, the behavior of such socially-aware systems,
specifically during human-machine social interactions, will be consequently
more recognizable and aligned to people’s expectations.
2.3 Modeling Narrative Structure
Narrative theory has drawn distinctions between the story’s content or theme,
that is, the narrated event and its form, or telling [SW17]. This notion of
conveying the same story in numerous forms is drawn from work in many
academic traditions, including literary studies, folklore/anthropology, psy-
chology, and sociolinguistics [McQ00; DF08]. For example, literary analysis
has examined the structure, cultural forms, and textual qualities of narra-
tive (often literary texts), while anthropological studies have explored the
54 Chapter 2. Background & Related Work
content and form of stories, their cultural resonance, and the storytelling
practices of different cultures [Pro10; Pol81]. Coherent situation models of
a narrative require the ability to accurately recognize boundaries in narra-
tive episodes which can be attributed to structural components of narratives
[Ger13; Mag+12; MTK05]. Recognizing temporal shifts in mental states and
monitoring them is critical towards understanding the boundaries between
narrative episodes represented in the situation models [Zwa+98; Zwa16].
Drawing from narrative psychology, narratives have been used to under-
stand cognitive processes. However, the protagonist’s mental models can
be an intriguing way of imposing structure in narratives [Bru90; Bru91b;
Bru91a; Bru09].
Several previous works have laid emphasis on understanding different
aspects of narratives [Els12a; GBS11; Fin12]. Earlier many annotation schemas
such as Rhetorical Structure theory [MT88] and Penn Discourse Treebank
[Pra+08] were proposed to analyze different types of discourse. Such schemata
provide a principled way of performing structural analysis of text [BHN18;
KG78]. Given the limited efforts towards capturing the functional schemata
or structure in narratives, it is advantageous to undertake computational
interpretation of such structures in order to comprehend the meaning con-
veyed in a narrative. These structures typically indicate a list of functions
that follow a specific order sequence between them. Moreover, they could
potentially signify critical points of the narrative text and contribute to the
dramatic arc [OR11; Li+17].
Propp [Pro10] defined the repeated plot elements as functions for Rus-
sian folklore. These are understood as a part of characters’ acts, defined from
their significance for the course of the action. There are other theories like
Campbell’s “Hero’s journey”. The common property of such theories is they
are closely associated with particular kinds of stories and domains. Lehn-
ert [Leh81] presented plot units as conceptual structures for modeling events
2.3. Modeling Narrative Structure 55
Freytag Labov & Waltezky Prince
Exposition Orientation
Starting State
Rising Action Complicating Actions
Climax Most Reportable Event State-Changing Event
Falling Action Resolution
Ending State
Denouement Coda
TABLE 2.1: Correspondence between categories from different
narrative theories as in [Li+17]
and states in the stories and their corresponding relationships between them.
The primary motivation behind the idea of plot units is the notion that emo-
tional reactions are central to the narrative, and the story’s plot can be tracked
using the transition of affect states at the event-level. However, this assump-
tion has its limitations where affect states emerge from the events, and mental
states are not modeled or distinguished from the actual events occurring in
the story. To overcome the limitations of the plot units, Elson [Els12a] pre-
sented a richer annotation schema, referred to as Story Intention Graph (SIG),
to capture timelines as well as beliefs, intentions, and plans of story charac-
ters. It consists of three layers and is highly expressive, involving motivation
and affect states of characters. However, the level of expressiveness expected
from this approach is highly resource-intensive and is sometimes difficult to
interpret and annotate.
Other narrative theories generalize stories across genres to contain a cer-
tain uniform structure. Prince [Pri12] proposed three basic states which de-
scribe the narratives to contain a beginning, a middle, and an end. Here
the middle acts as the transformational event. Similarly, Freytag’s dramatic
pyramid contained five parts that include – Exposition, Rising Action, Cli-
max, Falling Action, and Denouement [Fre94]. Similarly, Labov and Walet-
zky [LW97] proposed a theory on oral narratives which initially divided nar-
rative clauses into three dimensions – temporal, structural and evaluation
56 Chapter 2. Background & Related Work
points in narratives [LW97; Lab06; Lab01]. Here, the complicating action
culminates in the “Most Reportable Event” (MRE), which indicates the event
with the highest cognitive tension that the characters grapple with. The struc-
tural label Evaluation is claimed to end with Resolution and Coda. Based on
[Li+17], correspondence across narrative theories was identified, and these
categories and their related counterparts in other theories are shown in Ta-
ble 2.1. Rahimtoroghi et al. [Rah+14], and Swanson et al. [Swa+14] used
a subset of Labov’s categories, including orientation, action, and evalua-
tion in personal weblog narratives. Black and Wilensky (1979) evaluate the
functionality of story grammars in story understanding, [PKL19] introduced
a dataset consisting of screenplays and Wikipedia plot synopses annotated
with turning point as a means of analyzing their narrative structure. More
recent work by [Lev+20] addressed the task of automatically detecting nar-
rative structures primarily directed at news stories. By adopting elements
from the narrative theory of Labov and Waletzky (Complication and Reso-
lution) and designing their new element, they construct a news corpus and
proposed supervised methods to identify them.
Our goal is not directed towards building a new functional schema for
social media personal narratives in this work. However, our primary ob-
jective is to test the hypothesis that the mental state representation models
can significantly impact improving narrative comprehension tasks, which in
our case, is identifying key elements of narrative structure in short personal
narratives obtained from social media. Given the different theories, their la-
bels, and commonalities, we prioritize climax/MRE and resolution to be the
categories of interest for our work. The intuition behind selecting these two
elements lies in the aspect of ‘tellability’. Researchers in narratology have an-
alyzed various components of a narrative that contribute to a notion of plot
quality referred to as ‘tellability’. It is commonly derived from certain struc-
tural properties used in narrative theory. Bruner insisted on the fact that “to
2.3. Modeling Narrative Structure 57
be worth telling, a tale must be about how an implicit canonical script has
been breached, violated, or deviated from”. Bruner’s ‘breach in canonicity’
[Bru91b] could correspond to (a) Freytags ‘climax’ – referring to the ‘turn-
ing point’ of the fortunes of the protagonist [AH14] or (b) Labov’s ‘most re-
portable event’ – describing the event that has the greatest effect upon the
goals, motivations and emotions of the characters (participants) in the narra-
tive [LW97; Lab06]. Moreover, most of the narratives containing an event of
highest tension also reach a ‘resolution’ stage involving a swift drop in ten-
sion as the final step. Our work aims to develop computational approaches
that model the key elements of narrative structure – MRE and resolution.
Drawing ideas from prior theories that express the influence of protagonist
cognitive state [Els12a; Els12b; Bru91b; Bru09], we rely on the fine-grained
mental states of the protagonist in the narrative and compute the shifts in
their inner states over time for identifying key narrative events and bound-
aries that effectively contribute towards the automatic prediction of different
structural components of the narrative.
59
Chapter 3
Datasets & Annotations
Several previous studies [Els12b; Oat95; CJ08; PM14; CGDI16] on narratives
have used different forms of textual data ranging from news stories to literary
texts to Wikipedia articles as described in Chapter 2. Given our overarching
goal of investigating the interplay between narratives and mentalizing, we
pivot our work to take advantage of the characteristics of personal narratives
as discussed in Chapter 1. In this chapter, we discuss the various datasets
collected for the purpose of our research and describe in detail the strategies
used to extract weak-annotations of relevant information from the data. By
aggregating personal narratives from Reddit, we process these narratives to
derive specific properties from them, essential for our modeling purposes.
We prepare three main in-house datasets as a part of this work namely
Personal Narratives Corpus, Search-based Social Commonsense Knowledge
(SB-SCK) dataset, and STORIES1 corpus. These datasets are central to our
modeling and evaluation phases. In addition to these datasets, each research
problem we proposed in Chapter 1 utilizes other publicly available bench-
mark datasets for evaluation. We describe our data collection process in two
parts.
• We aggregate explicit and implicit expressions of motives and emo-
tions at the sentence-level with and without the story context. Implicit
intents and emotions are obtained using web-based mining without
1Short for STructures Of ReddIt PEsonal Stories
60 Chapter 3. Datasets & Annotations
Datasets Annotation Type Size Dataset Details
SB-SCK
Dataset
Automatic ∼ 100, 000
Sentence-level implicit
mental state knowledge
mappings.
Personal Narratives
Corpus
Automatic ∼ 85, 000
First-person Reddit
stories with weak-
annotations of explicit
motivation and
emotion expressions.
STORIES
Corpus
Manual ∼ 2, 500
First-person Reddit
stories annotated with
Climax and Resolution.
TABLE 3.1: Summary of the consolidated in-house datasets
used in this dissertation.
any story context, and these are applied for embedding social events
(SB-SCK). Explicitly stated expressions of intent and emotions are usu-
ally extracted along with the story context to model the characters’
mental states (Personal Narratives Corpus).
• We construct the STORIES corpus to identify critical elements of narra-
tive structure in short personal narratives. Since climax and resolution
are predominantly present in most stories, we let the crowdworkers to
manually select portions of the story that qualify as climax and resolu-
tion resulting in a dataset containing fine-grained manual annotations.
Table 3.1 provides a summary of the in-house datasets aggregated, pro-
cessed, and partially annotated for our use in this dissertation. In the fol-
lowing sections, we delve deeper into the data collection processes drawing
ideas from information extraction and data mining techniques.
3.1. Extracting Motives and Emotional Reactions 61
3.1 Extracting Motives and Emotional Reactions
Our data collection pipeline is depicted in Figure 3.1. We aggregate two
datasets: (a) weakly-annotated personal narratives corpus and (b) Search-
based Social Commonsense Knowledge (SB-SCK). The former is intended
to capture the motives and emotions extraction considering the entire story
context. These are generally explicitly mentioned by the narrator in their sto-
ries. One of the limitations of the personal narratives corpus is that it may
not contain implicit mental state mappings (motives & emotions) for several
events in the narratives. To alleviate this limitation, we collect sentence-level
implicit mental states by adopting a combination of web data mining and
information extraction strategies. We elaborate on the steps involved in our
data collection process in the following sections.
C R P
P API: / /
/ /
F P
N F , 18,
, .
O IE E
P -A
M E
E
P C
E E
E 
F N E -
M D
, P -
E i De ec i
- P M
&
F 
N , D -
-
K D
C , M -
E
P
N
C
B- CK
C
fe
I a i
A G MEN A G MEN
B
A 0 A 1
(b)
(a)
( )
M
'
I
.
he he he
i de ake e
k bad
A G MEN A G MEN M DIFIE
A 0 A 1
a i a i g
B
FIGURE 3.1: Illustration of data collection pipeline.
3.1.1 Personal Narratives Corpus
We construct a corpus of personal narratives by gathering posts from Reddit
related to daily interactions, life experiences, relationships, comical or em-
barrassing situations, to name a few. Using Pushshift API2, we aggregate
887,441 posts from specific subreddits: /r/offmychest and /r/confessions.
Of these posts, we discard all those posts with tags like “[Deleted]”, “NSFW”
2https://pushshift.io/
62 Chapter 3. Datasets & Annotations
3 or “over_18” field set to true. The number of sentences in the posts ranges
from 1 to 1015. Further, we remove texts containing less than three sentences,
based on Prince’s definition [Pri12] of a minimal story as consisting of a start-
ing state, an event, and an ending state. We compute the 90th-percentile of the
story lengths and remove those that exceed this length. This augurs well for
our specific interest in short personal narratives. Therefore, we are left with
439,408 posts, with an average length of 12.08 sentences.Figure 3.2 shows the
data distribution related to their lengths.
Search-based Social Commonsense Knowledge
Social Roles Event Phrases Motives
Politicians
use social media
to woo voters
Activists to create a movement
Police to connect with residents
and solve crime
Workers
gather around table
to solve business problems
Priests to pray to god, share wine
and bread
Friends to share a meal, conversation
ee, and
ere to
n stand
break
nd gets
to the
at the
o as to
ard to
rthday,
ld rip
he said
en she
me. I
looked
lowing
owards
elt too
#Narratives
7K
14K
21K
28K
35K
#Sentences
3 7 11 15 19 23 26
(b)
FIGURE 3.2: Dataset details: Personal Narrative Statistics – No.
of narratives w.r.t their lengths.
To create our dataset related to motivations, we look for specific expres-
sions associated with intents or purpose. Human motivations and emotions
can be expressed linguistically in many ways, sometimes with explicit use
of purpose clauses. Generally, purpose clauses take the form: To-Infinitive;
(In order/So as) + To-Infinitive, (so that) + Subject + Verb; For + Noun/‘ing’-
form. In order to systematically identify text expressions that specify mo-
tivation, we leverage OpenIE4 methods [Sta+18; APM15] to extract a list of
propositions usually composed of a single predicate and an arbitrary number
of arguments. Using PropBank [PGK05] and its annotation scheme, we can
3NSFW – not safe for work
4https://demo.allennlp.org/open-information-extraction/
3.1. Extracting Motives and Emotional Reactions 63
break down syntactically complex sentences as: (a) ARG-0 related to the ar-
gument exhibiting features of prototypical agent and (b) ARGM-PRP related
to the purpose or motivation expressions in the text. Figure 3.3 shows a sam-
ple OpenIE extraction of agent and its purpose/emotion.
P
N
C
B- CK
C
fe
I a i
A G MEN A G MEN
B
A 0 A 1
(b)
( )
M
'
I
.
he he he
i de ake e
k bad
A G MEN A G MEN M DIFIE
A 0 A 1
a i a i g
B
FIGURE 3.3: Sample OpenIE extraction containing arguments
referring to agent and their motivation (purpose) and emotion.
One of the authors assessed the extraction quality by analyzing a random
subset of the agent-purpose pairs for each type of purpose clause and their
context. We manually identify a set of 300 extracted purpose clause texts if
they genuinely reflect the motivation behind an action. To filter trivial mo-
tivation expressions (e.g.,“to do it”), a logistic regression classifier is trained
by constructing hand-crafted features from text like mean word embeddings,
POS tags, number of words, presence of stopwords, and entities. Eventually,
we shortlist those expressions above a threshold score, ρpn >= 0.4. By elim-
inating trivial extractions with a basic classifier (see Appendix ??), we use
64 Chapter 3. Datasets & Annotations
the filtered data as our weakly-annotated training data. Further, we aug-
ment these extracted motivation texts with their paraphrases using a back-
translation approach [Edu+18] to simulate multiple-annotation settings. A
pretrained English↔German translation model is used for this purpose (e.g.,
to divert attention in tough times → to distract attention in difficult times).
We adopt a similar strategy to extract the emotions of characters in the
narratives. First we identify 400 keywords extracted from a combination of:
(a) emotion-directed5 lexical units from FrameNet [BFL98] corresponding to
different emotions, and (b) emotion vocabulary list6. Though we don’t have
any semantic role labeling for emotions, we still feed the sentences through
the OpenIE extraction method. By examining extracted propositions, we dis-
card those story sentences when: (a) sentence is negative (contains not), (b)
emotion keyword is not a part of the predicate, and (c) the first argument is
neither a noun nor pronoun. Using the first argument as the agent experienc-
ing the emotion and lexical units specified in FrameNet to express feelings
footnoteWe choose semantic frames related to “Feeling” (e.g., verbs like feel,
experience, get, be; phrases like sense of, feelings of, full of), we map specific
sentences in the narrative to the particular character and its emotion expres-
sions. We accomplish this by utilizing spaCy’s rule-based matching tool7 to
capture particular patterns in text. The data statistics are given in Table 3.2.
Sample extractions are highlighted in Figure 3.4.
Three non-author annotators labeled a random sample of 300 instances
(balanced between intent & emotions) for validation. Given the narrative
context up to the sentence of interest, each annotator is asked to choose the
right intent or emotion explanation expressed or implicitly felt by the char-
acter in the narrative. We let the annotators choose from the candidate texts
that are: (a) extracted using our method, (b) chosen randomly, or (c) None (if
5https://framenet.icsi.berkeley.edu/fndrupal/luIndex
6https://www.enchantedlearning.com/wordlist/emotions. shtml#wls-id-0
7https://spacy.io/usage/rule-based-matching
3.1. Extracting Motives and Emotional Reactions 65
Search-based Social Commonsense Knowledge
Social Roles Event Phrases Motives
Politicians
use social media
to woo voters
Activists to create a movement
Police to connect with residents
and solve crime
Workers
gather around table
to solve business problems
Priests to pray to god, share wine
and bread
Friends to share a meal, conversation
Personal Narratives
Intents
I haven't been able to get my degree, and
it’s killing me. I don't know where to
start or how to do it. I put my job in stand
by in order to finish my degree.….
Intents
My best friend had a really bitter break
up. She constantly breaks down and gets
lost in thought. I advised her to go to the
gym. Now, she has been sweating at the
gym daily. She is trying so hard so as to
divert attention in tough times….
Emotions
… My mother sends a birthday card to
my girlfriend, but not me. This birthday,
I asked my girlfriend if I could rip
the card as she had a bad day. She said
yes, because she felt irritated when she
received it……
Emotions
…. there are these guys staring at me. I
heard the cars stop behind me, I looked
back so as to check if they were following
me and I saw those guys coming towards
me. I got inside the car and felt too
anxious.
#Narratives
7K
14K
21K
28K
35K
#Sentences
3 7 11 15 19 23 26
(a) (b)
FIGURE 3.4: Dataset details: Samples extractions from Personal
Narratives Corpus. The agent (ARG-0) and the purpose clauses
(ARGM-PRP) are highlighted in red.
the annotators feel there is no clear intent or emotion for any instance). We
find that the annotators agree with our extracted intents (Fleiss’ κ = 0.87)
and emotion (Fleiss’ κ = 0.90) texts in 89% and 93% of the cases respectively.
3.1.2 Social Commonsense Knowledge
Though explicit motivation and emotion expressions are extracted by meth-
ods explained in the previous section, the implicit motives and emotions of
characters expressed in sentences are not captured. To obtain those implicit
66 Chapter 3. Datasets & Annotations
Personal Narratives Corpus
#total narratives 439,408
#avg characters per story 2.02
#narratives w/ mappings 85,587
#sents w/ motives 167,256
#sents w/ emotions 318,872
% first-person motives 48.01%
% first-person emotions 58.26%
SB-SCK Dataset
#events w/ motives 103,357
#events w/ emotions 69,584
#unique social roles 586
TABLE 3.2: Statistics of Personal Narratives Corpus (top)
and Search-based Social Commonsense Knowledge (SB-SCK)
dataset (bottom).
states, we: (a) exploit social commonsense knowledge (SCK) obtained from
ATOMIC [Sap+19a] and ConceptNet [LS04] and (b) mine the web to aug-
ment more knowledge about the events from the personal narrative corpus.
While ATOMIC contains inferential knowledge based on 24k short events, the
knowledge from ConceptNet may not align with our requirements. For our
purpose, we choose ConceptNet’s relevant relations: /r/MotivatedByGoal,
/r/CausesDesire, /r/Entails, /r/ Causes, /r/HasSubevent.
In our work, we posit that social roles (e.g., student, mother, boyfriend,
etc.) provide extra information about the motives and emotions behind an
action. The base events in knowledge sources – specifically ATOMIC contain
typed markers (e.g., PersonX) where such information is lost. Therefore, we
adopt web-based knowledge mining techniques to account for this extra in-
formation. The quality of such assertions may not be as high as well-curated
knowledge collections like ATOMIC. However, they can act as an excellent
source for pretraining our models. We refer to this as Search-based Social
Commonsense Knowledge (SB-SCK) data. Figure 3.5 shows samples from
3.1. Extracting Motives and Emotional Reactions 67
this dataset that exemplifies how the same action could have different so-
cial role-related motivations. The following steps are involved in aggregat-
ing this dataset containing more social commonsense knowledge along with
social role information: (a) process texts from our personal narratives cor-
pus, (b) extract propositions from text using OpenIE tools, (c) perform a web
search for plausible intents and emotions by attaching purpose clauses and
feelings lexical units (explained earlier) and (d) finally, remove the poorly
extracted facts using a simple classifier trained on some seed commonsense
knowledge.
Search-based Social Commonsense Knowledge
Social Roles Event Phrases Motives
Politicians
use social media
to woo voters
Activists to create a movement
Police to connect with residents
and solve crime
Workers
gather around table
to solve business problems
Priests to pray to god, share wine
and bread
Friends to share a meal, conversation
Narratives
able to get my degree, and
I don't know where to
do it. I put my job in stand
nish my degree.….
had a really bitter break
ntly breaks down and gets
I advised her to go to the
has been sweating at the
is trying so hard so as to
in tough times….
sends a birthday card to
ut not me. This birthday,
girlfriend if I could rip
had a bad day. She said
he felt irritated when she
ese guys staring at me. I
stop behind me, I looked
eck if they were following
hose guys coming towards
de the car and felt too
#Narratives
7K
14K
21K
28K
35K
#Sentences
3 7 11 15 19 23 26
) (b)
FIGURE 3.5: Dataset details: Samples motives related to specific
social roles from Search-based Social Commonsense Knowl-
edge (SB-SCK) dataset.
These steps involved in the data collection pipeline are described in de-
tail below. We feed sentences from personal narratives to OpenIE tools which
yield subject-relation-object triples. Next, we form a web search query q after
normalizing 8 the triples and concatenating them with purpose clauses (for
motivations) or feeling lexical units (for emotions). The query q is issued to
the search engine, using its public API and enabling the spelling correction
feature. We train a simple logistic regression using manually annotated seed
8For example, “clean a bedroom floor” is changed as “clean bedroom floor” using weak
normalization and “clean floor” under strong normalization settings.
68 Chapter 3. Datasets & Annotations
sets of search results to verify if they are valid candidates for knowledge ex-
traction. We use the following features: average word embedding, number
of words matched, exact match or approximate match, presence/number of
stop words in mental state text, type of clause (purpose/feelings), and pres-
ence of entities. We use an N-V-OW representation scheme for words simi-
lar to [FDR19], where each word is categorized into: HeadNoun, FirstVerb,
and OtherWords. Finally, we discard all results below a threshold score
ρsck < 0.35. The data statistics are presented in Table 3.2. In Chapter 4, we
primarily use the SB-SCK dataset to compute rich social event representation
where the knowledge accumulated acts as a source of extracting pragmatics
properties from the event text. However, there are severe shortcomings in
applying them directly on stories due to the absence of context information.
Using the computed sentence-level pragmatics-aware social event embed-
dings, we utilize the Personal Narratives Corpus for modeling motives and
emotions of characters in the narrative given the story context. We describe
this model in great detail in Chapter 5.
3.2 Identifying Climax & Resolution in Narratives
Figure 3.6 presents our data collection pipeline. The first stage in this pipeline
is dedicated to ingesting posts from Reddit. To collect natural first-person
stories, we rely on Reddit communities comprising user-generated textual
accounts of happy events, long-standing baggage, recent trauma, life ex-
periences, adventurous encounters or guilt, and redemption episodes. To
this end, we aggregate posts from two communities: /r/offmychest and
/r/confession using the PushShift API 9. The Pushshift API provides access
to a database of all Reddit posts made since Reddit’s launch as a social plat-
form. We obtain ∼ 440, 000 posts from this step.
9https://pushshift.io/
3.2. Identifying Climax & Resolution in Narratives 69
R P C c
P API: / /
/ /
F P
N F , D , P L ,
18, .
S C a ca
BE -
R P a
Na a
FIGURE 3.6: Illustration of our data collection pipeline.
Next, we filter the collected data to retain only those posts that do not con-
tain tags like “[Deleted]”, “NSFW” 10 or “over_18”. Relying on Prince’s defi-
nition [Pri12] of a minimal story to comprise a starting state, a state-changing
event, and an ending state, we eliminate posts containing less than three sen-
tences. The subsequent stages in the pipeline are detailed in the sections
below.
3.2.1 Story Classifier
The aggregated data consists of a wide variety of contents, some of which do
not qualify as personal narratives. In order to separate such non-narrative
content from the collected data, we develop a story classifier that takes tex-
tual content as input and predicts the likelihood of the input text being a
story.
Story vs. Non-Story Dataset We gather a diverse collection of first-person
blog text drawn randomly from the Spinn3r Blog Dataset containing every-
day situations [GS09]. Consistent with our filtering approach for Reddit
posts, we follow a similar length criterion and sample ∼ 1, 500 blog posts.
Further, we randomly selected ∼ 1, 500 texts from our Reddit posts corpus.
Together, we obtain a total of ∼ 3, 000 posts to be annotated by MTurk work-
ers.
For each post, annotators were instructed to read the textual content and
choose one among the three labels: Story, Non-Story, or Unsure [Gor+13]. We
define these categories as follows – (a) Story: Non-fictional narratives that
10NSFW – not safe for work
70 Chapter 3. Datasets & Annotations
Models P R F1
Sem. Triplet [Cer+12] 0.64 0.47 0.46
VerbNet [EF17] 0.71 0.66 0.68
HAN [Yan+16] 0.75 0.73 0.74
BERT [Dev+18] 0.81 0.78 0.79
TABLE 3.3: Performance of our BERT-based story classifier on
the annotated dataset.
people share with each other about their own life experiences. They contain
a sequence of causally or temporally related events with the narrator being
a participant; (b) Non-Story: Texts that are not primarily personal stories or
don’t give an account of past events. They may or may not contain texts from
the first-person point of view but include opinion pieces, excerpts from news
articles, recipes, technical explanations, facts, questions or some random dis-
cussion, personal advice, to list a few. When the annotators are uncertain
about the right label, they are allowed to select the “Unsure” option. The
three workers reached unanimous agreement on 76% of the cases. We use
the majority vote when such an agreement is not reached. Of the 3,000 posts,
1,197 posts were tagged as “Story”, 1,173 as “Non-Story” and remaining as
“Unsure”.
Model We introduce a story classifier that separates non-fictional narra-
tives from the non-narrative textual content. Prior work has used feature
engineering to extract features like Tf-Idf, Semantic Triplets, VerbNet & coref-
erence resolution chain based character features [Cer+12; EF17] for this task.
A work by Piper [Pip18] specifically used the linguistic aspect of the text to
measure fictionality, i.e., distinguish works of fiction from non-fiction. In our
work, we use a pretrained BERT model for our classification task. Given an
input text, the goal is to predict if the text qualifies as a story or not. We
formulate the input text as T = {S1, S2, ..., Sn}, where Si is the ith sentence
of the text. Following [Dev+18], we tokenize the input text and concatenate
3.2. Identifying Climax & Resolution in Narratives 71
all tokens as a new sequence, {[CLS], S1, [SEP], S2, [SEP], ..., Sn−1, [SEP], Sn,
[SEP]}, where [CLS] is a special token used for classification and [SEP] is a
delimiter. Each token is initialized with a vector by summing the correspond-
ing token and position embedding from pretrained BERT, and then encoded
into a hidden state. Finally, we get [H[CLS], HS1
, HS2
, .., HSn
, H[SEP]] as an en-
coding output. We concatenate the [CLS]-token representation from the last
four layers of the model for our classification task. We apply two linear layers
on top of the concatenated output representation with a sigmoid activation
function at the final linear layer. We optimize the binary-cross entropy loss
and choose the model with the least loss on the validation set as our final
story classifier. We evaluate this model on the held-out test set.
In Table 3.3, we report the F1 score, and compare our approach to other
baselines. The best performing model achieves an F1-score of 0.79. Finally,
we feed the Reddit posts to the trained story classifier and obtain a probabil-
ity score, p, that indicates the likelihood of the post is a story. Furthermore,
to increase the reliability of our data, we discard all those posts with a prob-
ability score lesser than a chosen threshold δ, i.e., p < δ. In our work, we set
δ to 0.75. This procedure yields a total of 63,258 stories, referred to as Reddit
Personal Narratives dataset.
3.2.2 Annotation
Here, we explain the annotation process involved in constructing our manu-
ally annotated STORIES dataset. This dataset contains a total of 2,382 Reddit
personal narratives, comprising 42,614 sentences. Table 3.4 shows the de-
scriptive statistics of our dataset.
72 Chapter 3. Datasets & Annotations
FIGURE 3.7: Sample Page from our user interface for anno-
tation containing options to (a) highlight text and tag them as
climax/resolution or (b) choose checkboxes – “No Climax” or
“No Resolution”, if annotators feel there is no climax and reso-
lution.
Setup
We created a user interface for MTurk workers to make the annotation pro-
cedure convenient for capturing key elements of the narrative structure –
climax and resolution. Towards formalizing and describing our annotation
3.2. Identifying Climax & Resolution in Narratives 73
scheme, proper guidelines were provided for the annotators. These guide-
lines include: (a) Definitions for both climax and resolution, (b) General an-
notation directions involving color schemes for highlighting the narrative el-
ements, and (c) Select examples of personal narratives with colored high-
lights of identified narrative elements. The user interface allows the workers
to highlight parts of the text that qualify as climax and resolution using red
and green colors, respectively. Each worker has presented a sampled text
from Reddit personal narrative corpus. Additionally, the workers are pro-
vided with an option of selecting checkboxes: “No Climax” or “No Reso-
lution”. This caters to those personal stories that don’t contain a climax or
resolution. Figure 3.7 provides an example of a page from our user interface
for annotation purposes. A personal story is shown to the annotator, and
options to highlight and tag them as climax and resolution are provided.
Dataset Statistics
#Total Narratives 63,258
#Annotated Narratives 2,382
#Total Sentences 42,614
#Climax Sentences 5,173
#Resolution Sentences 4,502
TABLE 3.4: Statistics of our annotated STORIES dataset.
FIGURE 3.8: Distributions of mean climax & resolution sen-
tence positions.
74 Chapter 3. Datasets & Annotations
Agreements
Once the data is collected using our annotation setup, we measure the inter-
annotator agreement (IAA) at both the sentence and span-level. For sentence-
level agreement, we use the following metrics: (i) Cohen’s kappa (κ) [Coh60],
average pair-wise kappas are computed, (ii) mean annotation distance (D),
i.e., the distance between two annotations for each category, normalized by
story length [PKL19]. Following [SRW08], we compute two measures for the
text span agreement: (i) exact agreement in which the text spans are expected
to match fully; and (ii) relaxed (lenient) matching in which the overlap be-
tween spans is considered as a match; and agreement naturally increases as
we relax the matching constraints.
S Enc de
Sen ence Enc de
In e ac i n La e
(b)
Cla ifica i n La e
F i n La e
NEMO
Sam le A a i
I e al a s anted to ha e m o n pa check since I started high school I e felt
pathetic just asking m parents for mone for the mo ies or for a school e ent or
something like that For the last fe months of through March of this ear I e
been appl ing to part time jobs and getting nothing It is so tiring Getting rejected e er
time has brought me do n to a signi icant lo But I inall got a job at the restaurant
m dad orks at as a bus bo and I get m irst pa check tomorro I m so proud of
m self Something I can call m o n
It as sno ing hea il and I had an instinct that something as amiss I got a te t
message that m friend met ith an accident I as shocked Thankfull She s ine and
so is e er one else ho as in the car But hol shit just seeing her message sa ing that
she d been in a car accident scared tf out of me The instinct I had turned true In a a
I m orried about it and concerned ho this ill turn out I m still not quite o er it like
idk h I still feel so eird and upset but I reali e shes oka and ine I m e pecting to
talk to her toda e ening I hope talking to her might make me feel a lot better
M co orker has orked ith us for a ear no We all just orked ith her o er the
eekend She had a dark sense of humor She al a s joked about ho life asn t orth
li ing during her shifts And right on Monda she killed herself and as just gone I m
totall broken None of us are a are of ho to respond to it I reall don t kno hat to
make of it or ho to process it She as a too oung to lea e us She ne er thought
about us in her inal moments I m still not out of the shock and struggling to get o er
this
(a)
STORYENTENC
IEE-DEC
Enc de :
Dec de :
Kn ledge
En ichmen
M d le
En i -ba ed
Mem
In en /Em i n E lana i n
FIGURE 3.9: Sample annotations of climax (Red) and Resolu-
tion (Green) by one of the annotators.
3.2. Identifying Climax & Resolution in Narratives 75
Metric Climax Resolution
Span-level Analysis
Exact Agreement (F1) 0.524 0.665
Relaxed Agreement (F1) 0.687 0.772
Sentence-level Analysis
Percentage Agreement 0.736 0.807
Cohen’s Kappa (κ) 0.651 0.769
Mean Annotation Distance (%D) 1.764 1.590
TABLE 3.5: Sentence and Span level inter-annotator agreement
Analysis
We study the appearance of climax and resolution sentences by estimating
their mean position normalized by the story length. We present the distribu-
tion of the position of both the structural elements in Figure 3.8. While the
expected average position for the climax (0.61) coincides with the peak, we
observe that the resolution contents occur later in the story. Table 3.5 shows
the sentence and span-level IAA measures for each narrative element. We
observe that substantial agreement is achieved for both the climax and reso-
lution. Clearly, the sentence-level analysis produces higher reliability scores
than span-level measures. We attribute this to granularity, where the annota-
tors marked expressions within the sentences in a close neighborhood with
slightly different boundaries. Moreover, we obtain higher agreement values
for resolution than the climax.
We analyze the discrepancies in the annotated data to gain insights into
the potential challenges in the annotation process. For the climax, we note
that the annotators get confused with sentences that involve events con-
tributing to rising action (or Labov’s complicating action), eventually culmi-
nating in a climax (or Labov’s MRE). Further, we observe that the differences
are more nuanced in many instances and hence harder to detect reliably.
Though we achieve higher agreement on the resolution category, the annota-
tion gets less accurate with ambiguities in resolution and aftermath/endings,
76 Chapter 3. Datasets & Annotations
especially when narratives don’t have a clear resolution. Interestingly, the
annotators are able to discern between the two interest categories despite
the high cognitive load and complexity involved in detecting them from un-
structured user-generated content. Figure 3.9 displays sample annotations
(e.g. multi-sentence or non-contiguous highlights; no resolution) from our
STORIES dataset.
77
Chapter 4
Learning Knowledge-Enriched
Social Event Representation
4.1 Introduction
Everyday life comprises the ways in which people typically act, think, and
feel on a daily basis. Our life experiences unfold naturally into temporally ex-
tended daily events. The event descriptions can be packaged in various ways
depending on several factors like speaker’s perspective or the related do-
main. Interpretation of event descriptions will be incomplete without under-
standing multiple entities involved in the events and even more so when the
focus is primarily on “social events”, i.e., events explaining social situations
and interactions. Therefore, a social event representation model must capture
the semantic properties from the event text description and embed salient
knowledge that encompasses the implicit pragmatic abilities. Early defini-
tions of pragmatic aspects refer to the use of language in context; comprising
the verbal, paralinguistic, and non-verbal elements of language [Ada+05].
Contemporary definitions have expanded beyond just communicative func-
tions to include behavior that includes social, emotional, and communicative
aspects of language [Ada+05; Par+17].
78 Chapter 4. Learning Knowledge-Enriched Social Event Representation
S1: S d c a S2: S d dd
S3: S d a c S4: T ac a c
S5: P ac b c
x S1
x S2
x S3
x S4
x S5
x S1
x S2
x S3
x S4
x S5
C N
C N
A OMIC
C N
A OMIC
SB-SCK
x S1
x S2
x S3
x S4
x S5
x S1
x S2
x S3
x S4
x S5
(a) (b)
(c) (d)
FIGURE 4.1: Illustration of functioning of our representation
learning approach that produces rich social event embeddings.
Event texts are given in the top green box. With more knowl-
edge, social event embeddings move beyond high lexical over-
lap [shown in (a)] and learn to integrate semantic and prag-
matic properties [shown in (b), (c)] of event texts along with
social role information [shown in (d)].
Moving away from the extensively studied speech acts, we analyze char-
acteristics that reflect how a person behaves in social situations and how so-
cial contextual aspects influence linguistic meaning. In the context of event
representations, the pragmatic properties can specifically refer to the hu-
man’s inferred implicit understanding of event actors’ intents, beliefs, and
feelings or reactions [Woo76; HN78].
4.1. Introduction 79
Understanding the pragmatic implications of social events is non-trivial
for machines as they are not explicitly found in the event texts. Prior studies
[Din+14; Din+15; GWC16; WBC18] often extract the syntactic and semantic
information from the event descriptions but ignore the pragmatic aspects of
language. In this work, we address this shortcoming and aim to (a) disentan-
gle semantic and pragmatic attributes from social event descriptions and (b)
encapsulate these attributes into an embedding that can move beyond sim-
ple linguistic structures and dispel apparent ambiguities in the real sense of
their context and meaning.
Towards this goal, we propose to train our models with social common-
sense knowledge about events focusing specifically on intents and emotional
reactions of people. Such commonsense understanding can be obtained from
existing knowledge bases like ConceptNet [SCH17], Event2Mind/ATOMIC
[Sap+19a; Ras+18a] or by collecting more noisy commonsense knowledge
using data mining techniques. We, therefore, leverage these knowledge as-
sertions aggregated from multiple sources to enable semantic and pragmatic
enrichment of social event representations. One of the shortcomings of the
dataset like ATOMIC is that the tokens referring to people are often replaced
with a ‘Person’ marker. The social role information (e.g., student, mother,
teacher, etc.) can significantly change the meaning of the event description
and its interpretation as a whole. The motivation and emotional reaction
associated with the same event can vary depending on the social role infor-
mation. Figure 4.1 presents a sample functioning scenario producing incre-
mentally richer social event embeddings. As the model gains more knowl-
edge from different sources, it learns to discern events based on semantic and
pragmatic properties, including social roles. For example, “Student takes
course”, and “Teacher takes course“have significant lexical and semantic re-
latedness. However, the social role information introduced by our own in-
house aggregated SB-SCK dataset (as explained in Chapter 3) enhances the
80 Chapter 4. Learning Knowledge-Enriched Social Event Representation
representation learned from social event texts as depicted in Figure 4.1(d).
In this work, we develop a representation learning approach that learns
to embed social event text at syntactic, semantic, and pragmatic levels. Our
model utilizes a set of knowledge assertions from various domain sources to
effectively integrate pragmatic attributes to interpret the real sense of events
beyond lexical overlap or shallow semantic representation. Our contribu-
tions are as follows:
• We adopt a representation learning approach to disentangle the rep-
resentation learned from event text into pragmatic and non-pragmatic
properties and effectively consolidate the social commonsense knowl-
edge from multiple domain sources and generate a semantically & prag-
matically enriched social event embedding.
• We evaluate our models primarily on four different tasks: (a) intent-
emotion prediction for event texts based on the social commonsense
knowledge aggregated from different domains, (b) event similarity task
using hard similarity dataset [Din+19; WBC18], (c) paraphrase detec-
tion using Twitter URL corpus [Lan+17a], and (d) social commonsense
reasoning task using SocialIQA [Sap+19b] dataset.
4.2 Problem Formalization
Formally, we assume that our learning framework has access to streams of
social commonsense knowledge data obtained from n different domains, de-
noted by D = {D1, D2, ..., Dn}. We denote jth-input free-form event text in
ith-domain as x
(i)
j = [w1, w2, ..., wL]. Here, w(·) refers to the tokens in the
event text. Data from each domain source contains source-specific textual
descriptions of social situations and their intuitive commonsense informa-
tion such as intents and emotions. Training samples, drawn from a domain
4.3. Datasets 81
dataset Di, could contain either a significant overlap or a completely new set
of knowledge when compared with the previously processed domains D1:i.
Given such a setup, we aim to generate richer social event representations
using our representation learning framework.
4.3 Datasets
For our representation learning task, we aggregate social commonsense knowl-
edge data1 from various domain sources. This knowledge contains details
about pragmatic aspects like intents and emotional reactions.
4.3.1 Social Events Dataset
Different domain sources of social commonsense knowledge used for train-
ing our social event representation model are explained as follows.
ATOMIC dataset consists of inferential knowledge based on 24k short events
covering a diverse range of everyday events and motivations. Though each
event contains nine dimensions per event, the scope of this work will be lim-
ited to intent and emotions as our inferential pragmatic dimensions.
CONCEPTNET knowledge base contains several commonsense assertions.
For our purpose, we choose ConceptNet’s relevant relations: /r/MotivatedByGoal,
/r/CausesDesire, /r/Entails, /r/Causes, /r/HasSubevent. We convert triples
in the dataset into template form.
SB-SCK As explained in Chapter 3, search-based social commonsense knowl-
edge dataset contains additional social role information(e.g., student, mother,
1The project details about future data/code releases or any updates will be available at
https://pralav.github.io/lifelong_eventrep?c=10
82 Chapter 4. Learning Knowledge-Enriched Social Event Representation
SB-SCK Dataset
#events w/ motives 103,357
#events w/ emotions 69,584
#unique social roles 586
Search-based Social Commonsense Knowledge
Social Roles Event Phrases Motives
Politicians
use social media
to woo voters
Activists to create a movement
Police
to connect with residents
and solve crime
Workers
gather around
table
to solve business
problems
Priests
to pray to god, share wine
and bread
Friends
to share a meal,
conversation
FIGURE 4.2: Left: Samples from Search-based Social Common-
sense Knowledge (SB-SCK) dataset with highlighted motiva-
tions for social roles, Right: Statistics of SB-SCK dataset.
teacher, worker, etc.) that provide details about the social context and its in-
ferred motives and emotions behind actions specified in the events (as shown
in Figure 4.1, 4.2, we adopt web-based knowledge mining techniques for
capturing these knowledge assertions. Figure 4.2(Left) shows samples from
this dataset indicating how the same action could have different social role-
related motivations. We refer to this as Search-based Social Commonsense
Knowledge (SB-SCK) data. Figure 4.2(Right) presents the data statistics.
For data from each of the above domain sources, we sample free-form
event text, paraphrase, intent, emotional reactions, and negative samples of
paraphrases, intents, and emotional reactions. Based on the annotated la-
bels for motivation (Maslow’s) and emotional reactions (Plutchik) in STO-
RYCOMMONSENSE data, we run a simple K-Means clustering on the open
text intent data. We identify five disjoint clusters on each of the three do-
mains and map them to those categories. We use these categories so that
different types of data are sufficiently represented in our train, valid, and test
sets in this work.
4.4. Framework 83
4.3.2 Paraphrase Datasets
We use random samples of parallel texts from paraphrase datasets like PARANMT-
50M corpus[WG17] and Quora Question Pair dataset 2. These paraphrase
datasets are primarily used for pretraining our model. We also produce para-
phrases of free-form event texts in our dataset using a back-translation ap-
proach [Iyy+18]. We used pretrained English↔German translation models
for this purpose.
4.4 Framework
Our goal is to learn distributed representations of social events by incorporat-
ing pragmatic aspects beyond shallow event semantics. Moving away from
conventional supervised multi-task classification-based learning approaches,
we focus on a representation learning approach that enables us to adapt and
learn a social event embedding model. The motivation for learning such rep-
resentations is to uncover latent information at syntactic, semantic, and prag-
matic levels by exposing the model to the knowledge about implicit men-
tal states of event actors’. This knowledge is obtained from various domain
sources and can effectively guide the modeling of complex social events and
extract the meaning of the events beyond shallow features. In this section,
we will explain various components of our modeling framework.
4.4.1 Social Event Representation
Given an input event text description, the core idea is to encode the free-
form event text and decompose the ensuing representation into pragmatic
(implied emotions and intents) and non-pragmatic (syntactic and semantic
2https://www.kaggle.com/c/quora-question-pairs/data
84 Chapter 4. Learning Knowledge-Enriched Social Event Representation
information) components. Eventually, we combine these decomposed repre-
sentations to obtain an overall event representation and apply it in different
downstream tasks.
Encoder
The input to our model is a free-form event text description from ith do-
main, x
(i)
j ∈ Di. This free-form event text contains a sequence of tokens,
x
(i)
j = [w1, w2, ..., wL], where each token w(·) is obtained from an input vo-
cabulary V. The model encodes the input event text x
(i)
j ∈ RL×dX in mul-
tiple steps. First, we construct a context-dependent token embedding us-
ing a context embedding function G : RL×dX #→ RL×dH , where dX and dH
refer to the embedding and hidden layer dimensions respectively. Follow-
ing this encoding step, we incorporate pooling or projection function, Gpp̄:
RL×dH #→ R3×dH , that transform event text from context-dependent embed-
ding space into pragmatic and semantic space. More specifically, we produce
latent vectors for intents (hI), reactions (hR) and non-pragmatic (hN) infor-
mation. Finally, we combine the latent vectors hN, hI, hR using a simple feed-
forward layer, GC: R3×dH #→ RdH , to produce a rich social event embedding,
hC. Given positive and negative examples of intents, emotional reactions
and paraphrases associated with the input event text, we learn to effectively
sharpen each of these embeddings hI, hR and using metric learning methods.
For the sake of brevity, we drop the domain index i and the sample index
j in this section. These encoding steps are summarized as:
He = [h1, h2, ..., hL] = G([w1, w2, ..., wL]) (4.1)
hI, hR, hN = Gpp̄(He) (4.2)
hC = GC(hI, hR, hN) (4.3)
4.4. Framework 85
Mem
[[CLS]m[SEP] 1, 2, .., n [SEP]]
Enc de
hP
hN
Lo I + Lo R
hI
hR
hC Lo C
FIGURE 4.3: Left: Illustration of our Social Event Representa-
tion Model.
We denote this multi-step encoding process resulting in hI, hR, hC as a
function Gevent. Now, we experiment with the following text embedding tech-
niques as our context embedding function (G):
BiGRU : We use a recurrent neural network to encode the input sequence.
More precisely, we choose a gated recurrent network (GRU) over LSTM as
they achieve comparable performance levels with lesser computational re-
source requirements. Using bidirectional GRUs, we obtain forward (
−
→
ht ) and
backward hidden states (
←
−
ht ) of the input sequence. We concatenate these
forward and backward hidden states at each timestep t ∈ {1, 2, ..., L} to get
an overall latent vector representation (He) of the input event text. This is
computed as:
He = [
←
→
h1 ,
←
→
h2 , ...,
←
→
hL ] =
←
−
→
GRU(x) (4.4)
−
→
ht ,
←
−
ht =
−
−
→
GRU(wt,
−
−
→
ht−1),
←
−
−
GRU(wt,
←
−
−
ht−1) (4.5)
←
→
ht = [
−
→
ht ;
←
−
ht ] (4.6)
BERT We employ BERT [Dev+18], a multi-layer bidirectional Transformer-
based encoder, as our context embedding method G. We fine-tune a BERT
model that takes attribute-augmented event text x = [CLS] m [SEP] w1, ..., wL [SEP]
as input and outputs a powerful context-dependent event representation He.
86 Chapter 4. Learning Knowledge-Enriched Social Event Representation
The attribute m ∈ {xIntent, xReact, xNprag} refers to special tokens for in-
tents, reactions and non-pragmatic aspects. Special tokens [CLS] and [SEP]
are commonly added as first and last tokens. Formally, we define it as:
He = [h1, h2, ..., hL] = BERT(x) (4.7)
In our default case, our Gpp̄ function is the output embedding of [CLS]
token associated with their respective attribute-augmented input. In cases
where input event text is not augmented with attribute special tokens, we
apply pooling strategies such as attentive pooling (AP) and mean (MEAN)
of all context vectors obtained from the previous encoding step G. We ob-
tain hI, hR, hN based on these techniques. Depending on the type of context
embedding function, we refer our multi-step event text encoder, Gevent, as
EVENTGRU or EVENTBERT.
Objective Loss
Using positive {u
p
I , u
p
R, u
p
C} and N − 1 negative {un
I , un
R, un
C} examples of in-
tents, emotions and paraphrases associated with the event texts, we calculate
N-pair loss, Lv(h, zp, {zn
k }N−1
k=1 ), to maximize the similarity between the rep-
resentation of positive examples (z
p
v) and the computed embeddings (hv).
Here, ze
v is computed using a transformation function fv as: ze
v = fv(ue
v),
where v ∈ {I, R, C} and e ∈ {p, n}. Thus, our loss function is devised as:
LT =
βD
2
· (LI + LR) + βE · LC (4.8)
where LI, LR are used to learn disentangled pragmatic embeddings (intent
and emotion), LC is intended to jointly embed semantic and pragmatic as-
pects to produce an overall social event representation. βD, βE are loss coeffi-
cients that weigh the importance of disentanglement loss and an overall joint
4.5. Training 87
embedding loss. These coefficients are non-negative and they sum to 1.
4.5 Training
Since our model involves metric learning, hard negative data mining is an es-
sential step for faster convergence and improved discriminative capabilities.
However, selecting too hard examples too often makes the training unstable.
Therefore, we choose a hybrid negative mining technique where we choose a
few semi-hard negatives examples [HBL17] and combine them with random
negative samples to train our model effectively. Usually, it is also unclear
what defines “good” hard negatives [HBL17].
In our work, we define a heuristic objective by weighing samples based
on two factors: (i) word overlap or similarity in embedding space of the event
text and (ii) intent and emotion free-form text or categories based on STO-
RYCOMMONSENSE data. More specifically, given an event text as an anchor
and a positive intent text based on a ground truth motivation category, we
mine negative instances for intent as follows: (a) choose random text samples
associated with a motivation category that is different from that of the posi-
tive example but closer in the embedding space or word overlap, (b) choose
random text samples within the same motivation category but with differ-
ent emotion category. We repeat this process for drawing negative instances
related to emotions. For paraphrases, we consider few examples with sig-
nificant word overlap while the rest are randomly chosen samples. Since N-
pair loss function allows for faster convergence and alleviates challenges in
hard mining strategy, we utilize N-pair loss as our objective function. N-pair
loss helps lessen the sensitivity of triplet loss function to the choice of hard
triplets. This is done by pushing away multiple negative examples jointly at
each update. Before using these negative intent/emotion samples, we pre-
train our model with paraphrase data to capture different forms of conveying
88 Chapter 4. Learning Knowledge-Enriched Social Event Representation
Methods Intents Emotions
ConvKB 58.87 71.05
NTN 59.19 71.58
ERNIE 64.37 74.46
EventGRU 60.06 70.61
EventBERT 70.03 79.96
TABLE 4.1: Evaluation results on the held-out test set. We re-
port the accuracy (%) scores for different baselines. Boldface
indicates the best accuracy scores for a particular category (in-
tents/emotions).
the same semantic content. For this pretraining, we sample examples from
our paraphrase dataset explained in 4.3.2. Finally, we pre-train our model
with paraphrase data and fine-tune it using the examples obtained from hard
negative mining for intents, emotions, and paraphrases. For our training, the
learning rate is set to 0.0001, the number of training epoch is 20. We conduct
a study by assigning different values for loss coefficients, βD, βE, and explain
their results in Section 4.6.1.
4.6 Experiments
In this section, we experiment with our learned social event representations
on different NLP tasks: intent-emotion prediction, paraphrase detection, So-
cial IQA reasoning, and event similarity. While we utilize the intent-emotion
prediction task for evaluating our continual learning setup, we establish the
richness of our social event embeddings using the remaining downstream
tasks.
4.6.1 Intent-Emotion Prediction
We evaluate our trained models on a held-out test set across the different
domains in our aggregated dataset (see Section 4.3). By default, we use
EVENTBERT as our multi-step encoder.
4.6. Experiments 89
Setup
In this work, we compare against different baseline neural network approaches
applied in the past for knowledge embedding on our training set. We report
the test set performance on predicting intents and emotions. The baselines
are listed below.
• ConvKB [Ngu+18] We train a variant of this CNN-based method by
feeding event text as triples to this model. We evaluate this method by
applying linear layers on top of the output feature vector.
• NTN [Soc+13; Din+15; Din+19]: This method utilizes neural tensor net-
work to perform semantic composition of event arguments. The bi-
linear tensors are explicitly applied to model the relationship between
event actor and their actions. We apply linear layers on top of the final
representation.
• ERNIE3 [Zha+19]: We utilize a variant of this model consisting of a
Transformer-based textual encoder and a knowledge encoder that fuses
knowledge and textual information into a united feature space. We use
this model and apply a linear layer on top of the representation for
intent and emotion prediction.
• EventGRU: This is our model variant with a GRU-based encoding strat-
egy.
• EventBERT: This is our complete model in default settings. We com-
pare this proposed approach over the above baselines.
Empirical Results
Table 4.1 reports the accuracy scores for the intent and emotion prediction
task. We note that our EventBERT model outperforms all the other baselines
3https://github.com/thunlp/ERNIE
90 Chapter 4. Learning Knowledge-Enriched Social Event Representation
Pooling Strategy Intents Emotions
AP 65.50 76.13
MP 67.28 76.69
CLS 68.56 78.48
TABLE 4.2: Results of our ablation study related to the pooling
strategy on the held-out validation set.
in this task. The closest performing model is ERNIE which is a transformer-
based model that integrates knowledge representation with textual informa-
tion. Despite ERNIE’s improved performance on many knowledge graph-
related tasks, our EventBERT records the best performance on this task. We
intuit that the main reason for this performance lies in the advantage of
jointly training on the aggregated datasets with the ability to disentangle
for pragmatic properties effectively. Moreover, we note that models attain
the best performance by permuting the training set across various domain
sources instead of sequentially training separately on individual datasets.
Ablation Study
We conduct an ablation study by analyzing various model configurations
related to: (a) pooling: attribute-augmented input (CLS), Mean Pooling (MP),
and Attentive Pooling (AP), and (b) loss co-efficient: βE. For each pooling
strategy, we did compare the model performance for different values of βE.
However, we report only the best performing configuration for each pooling
strategy towards predicting intents and emotions. Table 4.2 shows the results
of different pooling strategies for intent and emotion prediction task.
Additionally, we measure the effect of βE in the prediction of intents. As
shown in Figure 4.4, the model performs significantly better for lower values
βE as more weight is assigned for the disentanglement of pragmatic aspects.
Since we are evaluating here precisely to predict intents, the disentangling
4.6. Experiments 91
coefficient plays a critical role. We do have models trained using these differ-
ent coefficients and use the representations for downstream tasks. Though
the best performing model may vary depending on the task under consid-
eration, we observe that a balanced loss function with βE = 0.5 allows for
consistently good performance in both intent-emotion prediction (Figure 4.4)
and hard similarity tasks (see Section 4.6.2). Despite other hyperparameters,
changes to βE determine the importance of incorporating semantic or prag-
matic information in the ensuing event embedding.
otions
0.61
8.48
6.13
6.69
8.48
5.88
8.48 βE
Accuracy
(%)
60
62.5
65
67.5
70
0.3 0.5 0.7 0.9
2020
2020
January
May
FIGURE 4.4: Results of our ablation study on a held-out valida-
tion set. Acc scores (%) to measure the effect of βE in predicting
intents.
4.6.2 Hard Similarity Task
By following the work of Ding et al. [Din+19], we evaluate our social event
representation on an extended dataset of event pairs containing: (a) similar
event pair having minimum lexical overlap (e.g., people admired president/
citizens loved leader) (b) dissimilar event pair with high lexical overlap (e.g.,
92 Chapter 4. Learning Knowledge-Enriched Social Event Representation
Models % Acc.
KGEB 50.09
NTN + Int 58.83
NTN + Int + Senti 64.31
EVENTBERTβE=0.3 66.19
EVENTBERTβE=0.5 71.23
EVENTBERTβE=0.7 69.79
TABLE 4.3: Evaluation results on the combined hard similarity
dataset.
people admired president/ people admired nature). A good performance
in this task will ensure that similar events are pulled closer to each other
than different events. Combining hard similarity datasets from [Din+19] and
[WBC18], the total size of this balanced dataset is 2,230 event pairs. Using
our joint embedding hC for an event text and triplet loss setup, we compute a
similarity score between similar and dissimilar pairs. The baselines include:
Knowledge-graph based embedding model (KGEB) [Din+16], Neural Ten-
sor Network (NTN) and its variants augmented with ATOMIC dataset based
embeddings (Int, Senti) [Din+19]. We report the model’s accuracy in assign-
ing a higher similarity score for similar pairs than dissimilar pairs. Table 4.3b
shows that our model outperforms the state-of-the-art method for this task.
4.6.3 Paraphrase Detection
To assess the quality of our learned embedding, we present an evaluation on
the paraphrase detection task. Given a sentence pair, the objective is to de-
tect whether they are paraphrases or not. For each sentence pair (s1, s2), we
pass them through our model and obtain their respective hC, given by vectors
(u, v). We concatenate these vectors (u, v) with the element-wise difference
|u − v| and fed to a feed-forward layer. We optimize binary cross-entropy
loss. For evaluation purposes, we compare our model against baselines like
BERT and ESIM [Che+16]. Trained on a subset of the dataset explained in
4.6. Experiments 93
Models % Acc
ESIM 84.01
BERT 87.63
EVENTBERT0.5 88.23
EVENTBERT0.7 90.16
TABLE 4.4: Accuracy scores (%) of different models on
Twitter URL Paraphrasing corpus, TwitterPPDB. Subscript of
EVENTBERT model indicates value of βE.
Section 4.3.2, we choose an out-of-domain test dataset where samples stem
from a dissimilar input distribution. To this end, Twitter URL paraphrasing
corpus [Lan+17a], referred to as TwitterPPDB, is selected. This dataset con-
tains sentence pairs from Twitter where tweets are considered paraphrases if
they have shared URLs. We used a 3-month collection of paraphrases. Table
4.4 contains results of our evaluation. The results testify to the efficacy of our
embeddings.
4.6.4 Social IQA Reasoning
We determine the quality of our latent social event representations by eval-
uating on a social commonsense reasoning benchmark – SocialIQA dataset
[Sap+19b]. Given a context, a question, and three candidate answers, the
goal is to select the right answer among the candidates. Since our social
event embedding approach models particular pragmatic components like in-
tents and emotions, we assume that our model will help score better on spe-
cific question types like ‘motivations’ and ‘reactions’. Trained on a dataset of
around 33k samples explained in [Sap+19b], BERT achieves state-of-the-art
performance in this multiple-choice implementation setup. Following Sap et
al.[Sap+19b], the context, question, and candidate answer are concatenated
using separator tokens and passed to the BERT model. Additionally, we feed
the context to our EVENTBERT model to obtain three embeddings hI, hR, hC.
94 Chapter 4. Learning Knowledge-Enriched Social Event Representation
Models Dev Test
w/o Social Event Embeddings
GPT2 63.3 63.0
BERT-base 63.3 63.1
BERT-large 66.0 64.5
w/ Social Event Embeddings
BERT-base 65.1 64.0
BERT-large 68.7 67.9
TABLE 4.5: Accuracy scores (%) of different models on So-
cialIQA dev and test dataset. The best accuracy is indicated
in boldface.
While the original work computed a score l using the hidden state of [CLS]
token, we introduce a minor modification to this step as:
l = W5 tanh(W1 hCLS + W2 rxIntent + W3rxReact + W4 rC) (4.9)
where W1:4 ∈ RdH×dH and W5 ∈ R1×dH are learnable parameters. Similar
to [Sap+19b], triple with the highest normalized score is used as the model’s
prediction. We fine-tune BERT models using our new scoring function with
social event embedding (denoted as “w/”) and compare against baselines
(like GPT/GPT2 [Rad+18]) without our event embeddings (denoted as “w/o”).
We report the scores directly from the original work [Sap+19b]. Results in
Table ??a indicate that a simple enhancement procedure at the penultimate
step can offer significant performance gains. Our findings suggest that our
enhanced model performed well for question types like ‘wants’ and ‘effects’
that weren’t explicitly modeled in our embedding model. This confirms that
our pragmatics-enriched embeddings lead to improved reasoning capabili-
ties.
4.7. Conclusion 95
4.7 Conclusion
Humans rely upon commonsense knowledge about social contexts to ascribe
meaning to everyday events. This social commonsense knowledge may in-
clude a growing set of norms of behavior and pragmatic implications of the
participants’ actions in a given social situation. In this work, we introduce
a representation learning approach for the effective representation of social
events with the help of social commonsense knowledge assertions acquired
from different domains. By incorporating social commonsense knowledge
with our text encoding techniques, we learn rich embeddings of social events
from their free-form textual descriptions. First, we sharpen the semantic and
pragmatic aspects of social events using social commonsense knowledge and
jointly capture the overall non-ambiguous meaning of the event text. Using
an intent-emotion prediction task, we evaluate the learning setup based on
a held-out corpus of social events obtained from multi-domain knowledge
sources. By evaluating this held-out corpus of social events obtained from
multiple domain sources, we establish that our model is able to outperform
several baselines.
Experimental results on downstream tasks like event similarity, reason-
ing, and paraphrase detection tasks demonstrate our social event embed-
dings’ capabilities. However, we note that the trained model might not en-
compass all the knowledge necessary to handle novel social situations in-
volving cultural context as we don’t model for that explicitly. More relevant
knowledge assertions embodying cultural information can be helpful in such
scenarios. Instead of training the model from scratch for growing knowledge,
lifelong learning approaches for social event representation can guide the ac-
commodation of new knowledge and promoting positive knowledge trans-
fer to new domains [VR21a]. We hope that our work will motivate further
exploration into lifelong representation learning of social events and advance
96 Chapter 4. Learning Knowledge-Enriched Social Event Representation
the research in inferring pragmatic dimensions from texts.
97
Chapter 5
Modeling Human Motives and
Emotions from Personal Narratives
5.1 Introduction
Narratives are one of the most common yet powerful means of communi-
cation used to enhance engagement with people’s issues and understanding
of the social world. People share and consume them in a variety of ways to
convey and make sense of their experiences. Theorists and researchers in a
wide variety of fields like neuroscience, psychology, and narratology have
long posited that narratives exert a powerful influence on social cognition
by evoking mentalizing process [GW02; GPHL08; CSG98; CWC11]. Mental-
izing is used to describe all kinds of reasoning about others’ mental states,
such as inferring other peoples thoughts, beliefs, attitudes, emotions, and
motivations. Studies have argued that reading more stories in one’s lifetime
and analyzing characters’ behavior in stories contributes to greater activation
of mentalizing network [Mar18]. Therefore, comprehending narratives is key
to understanding human agency.
In this work, we are specifically interested in uncovering certain aspects
of the relationship between narratives and mentalizing [Fer+08; Mar11; Tam+16b;
MG17]. We focus on developing computation approaches to model human
98
Chapter 5. Modeling Human Motives and Emotions from Personal
Narratives
M dad j ed 60 a d I j l e m
dad bi .
La fe da ha e bee a lle c a e
ide f me.
M dad a diag ed i h C VID-19
fe da back a d ke e ila .
I hed he h i al a d fel ai ed
ee m g dad ick a d
meek.
be l ed
celeb a e i h hi
[e ci ed, lo ed]
e,
be c ce ed
[ e, lo ed]
ge ea me
a heal h
[sick, sad]
e,
ge medical a e i
[ill, sick]
e e l e
e d ime i h hi dad
[happ , e ci ed]
feel e helmed
eflec he a
[e ci ed, sad]
ake ca e f hi dad
c e hi fa he
[ orried, pse ]
ake ca e f hi dad
be ied f hi dad
[depressed, sad]
I (Na a )
M dad j ed 60 a d I j l e m dad bi .
La fe da ha e bee a lle c a e ide f me. M dad a
diag ed i h C VID-19 fe da back a d ke e ila . I
hed he h i al a d fel ai ed ee m g dad
ick a d meek. Af e a eek f ea me , he ha fi all ec e ed a d
I feel elie ed.
be l ed
celeb a e i h hi
[e ci ed, lo ed]
e
[none, lo ed]
ge be e
a heal h
[sick, sad]
ake ca e f hi hea
be ick
[ill, sick]
ec e f m hi ill
be heal h agai
[happ , rela ed]
M dad
M dad
bee a
back a
M Dad
Af e a eek f ea me , he ha fi all
ec e ed a d I feel elie ed.
ec e f m ill e
a i g d heal h
[happ , rela ed]
ee hi dad heal h
be ha kf l
[con en , jo o s]
FIGURE 5.1: Sample personal narrative is shown on the top. It
contains the motives and emotional reactions [italics] of differ-
ent characters – dad and son (narrator) in the narrative.
motives and emotions from narratives containing explicit and implicit refer-
ences to the characters’ psychological states and their corresponding social
contexts. To this end, different models of narrative analysis such as Labov’s
“evaluative devices” [GRDI10], or Lehnert’s “plot units” [Leh81] have been
proposed to track the mental states or affect states of the characters towards
narrative understanding and summarization. A work by [Ras+18c; Ras+18a]
focused on constructing a dataset comprising rich low-level annotations of
5.1. Introduction 99
categories and textual explanations of motivations and emotional reactions
of characters in five-sentence stories. By modeling character-specific con-
texts and pretraining on free-text responses, they provide benchmark results
on this new resource. However, very limited work focuses on rich repre-
sentation and generation of textual explanations of mental states, precisely
motives, and emotional reactions. Also, there is tremendous scope for im-
provement in furthering the research towards imparting mentalizing capa-
bilities for machines. Some of the key challenges in modeling human motives
and emotions include: (a) lack of annotated data that captures explicit and
implicit mental states of characters in narratives from different domains, (b)
ability to track characters’ mental state shifts continuously, and (c) effectively
embed and generate their corresponding text explanations.
To tackle a subset of the aforementioned challenges, we resort to personal
narratives from social media. Similar to a literary story, a personal narrative
is likely to contain a beginning, middle, and end, where the middle typi-
cally presents a complication for the person, one that is resolved in some
way by the ending. Similarly, it may convey information about goals, mo-
tives, thoughts, conflicts, emotions, and resolutions of people, including self
or other people inside or outside their social circle [GW11; Abb20]. This
makes them a practical resource for knowledge extraction and modeling.
Since manual annotation is usually labor-intensive and expensive, we adopt
a combination of web data mining and information extraction (IE) strategies
to automatically extract and aggregate noisy expressions of motivations and
emotions related to specific events in the text (applicable to different textual
domains). This facilitates the acquisition of weakly-annotated data contain-
ing characters’ motivations and emotions from personal narratives and social
commonsense knowledge from the web. Figure 5.1 (top) shows a sample per-
sonal narrative from Reddit with character-specific explanations of intents
and emotions behind every event in the narrative. Consider the sentence “I
100
Chapter 5. Modeling Human Motives and Emotions from Personal
Narratives
rushed to the hospital...”, the intent of the narrator (“I”) is “to take care of
his dad” or “to be worried for his dad”. To produce such explanations, it is
necessary to condition on the story context and social role because modify-
ing them could significantly alter the meaning and their corresponding intent
and emotional reactions behind the same action (e.g. “doctor rushed to the
hospital” could have a different intent: “to attend to an emergency patient”).
Thus, our goal is to (a) develop rich representations of mental states of
humans grounded in intuitive theories of human psychology and common-
sense knowledge, (b) generate textual explanations of mental states consid-
ering the prior context and social role information, and (c) harness transfer-
ability to downstream tasks. We, therefore, implement a Transformer-based
encoder-decoder architecture, referred to as NEMO1 to embed and explain
characters’ (or entities’) mental states. To this end, we equip our model with
components that: (a) enable pragmatic enrichment of narrative sentences us-
ing the aggregated knowledge and (b) track entities’ mental states over time
using an external memory module. Inspired by the ideas from cognitive
science [GV10], these components can be perceived as analogous to certain
characteristics of semantic and episodic memories. Thus, our contributions
are as follows:
• Data collection of Personal Narratives 2 and Social Commonsense Knowl-
edge containing weak-annotations of motivation and emotion text ex-
pressions.
• An end-to-end Transformer-based NEMO model augmented with mod-
ules that infuse social commonsense knowledge and dynamically track
entities’ mental states.
1Short for Narrative Entity Mental mOdel
2We will be making the data available soon.
5.2. Problem Setup 101
• Trained on the aggregated weakly annotated data, we conduct experi-
ments on the STORY- COMMONSENSE dataset [Ras+18c] under various
evaluation settings. To exemplify our learned embeddings’ transfer-
ability, we perform a simple evaluation on EMPATHETICDIALOGUES
dataset.
5.2 Problem Setup
Formally, a story S consists of a sequence of T sentences S = [s(1), s(2), .., s(T)]
and a set of N entities/characters E = {e1, e2, .., eN}. We denote tth-sentence
containing L words as s(t) = [w
(t)
1 , w
(t)
2 , ..., w
(t)
L ]. Given an entity ej, current
story sentence s(t) and prior story context s(<t), we aim to generate men-
tal state explanations of ej, Ym = [y
(1)
m , y
(2)
m , ..., y
(T)
m ], related to mental state
attribute m ∈ {xIntent, xReact}. Therefore, our approach models the condi-
tional probability: P(y
(t)
m |s(t), s(<t), y
(<t)
m , ej, m).
5.3 Related Work
There has been a growing interest in developing computational models to
model aspects of human behavior from day-to-day events or stories. Prior
work by [GRI13] presented a system Aesop that builds on the idea of Lehn-
ert’s plot units [Leh81] and utilizes existing resources to predict affect states
of characters in Aesop Fables. A line of work by [CGDI16; Rah+17] focused
on modeling desire and fulfillment. This work considers five or fewer sen-
tences to model the context of the desire expression and developed a logistic
regression-based classifier for the desire fulfillment prediction task. There
has been a recent body of research [Gui+17; Gho+17] that detects emotional
stimuli in stories and generates text based on specific attributes like senti-
ment or affect states based on LIWC categories. One of the closest works in
102
Chapter 5. Modeling Human Motives and Emotions from Personal
Narratives
this space is [Ras+18c]’s resource for character mental state tracking in short
five-sentence commonsense stories. In our work, we develop automatic tech-
niques to extract weakly-annotated mental state expressions with social role
information being retained from personal narratives (a more natural setting)
and propose a method to leverage social commonsense knowledge to gener-
ate and classify character motivation and emotion states efficiently. Further,
we address the modeling challenges by incorporating social commonsense
knowledge from social events and employing entity modeling for tracking
the mental states of characters in the narrative.
Prior work in entity modeling is limited by their ability to track simple
attributes, entity reference or specific physical properties of entities as in
[Hen+16; Bos+17; Ji+17]. In this work, we focus on capturing the dynam-
ics of the entities’ previous motivation and emotional states. We achieve this
by equipping our model using a memory module with operations involving
decoder contextual hidden states. It is worth noting that models that incor-
porate entity-aware memory-based target-side context are a rarity. We intuit
that employing attention mechanism over prior decoder states (target-side
context) facilitates improved explanation generation by efficiently recording
the motivation and emotion states.
5.4 NEMO: Our Proposed Model
Our overall objective is to learn character-specific embeddings of mental states
– especially motives and emotional reactions, and produce their textual ex-
planations by integrating external knowledge along with social role informa-
tion, preceding narrative context, and mental state encodings. In this direc-
tion, we introduce a Transformer-based encoder-decoder architecture aug-
mented with external memory modules that enable knowledge-enrichment
5.4. NEMO: Our Proposed Model 103
and dynamic state tracking of entities. Figure 5.2 provides an overview of
our NEMO model. The prime components of our model include:
Encoder: Decoder:
Kno ledge
Enrichment Mod le
Entit -based
Memor Mod le
Intent/Emotion
E planation
STORYENTENC IEE-DEC
Encoder Decoder
Encoder: Decoder:
Kno ledge
Enrichment Mod le
Intent/E
E pla
STORYENTENC IEE-DEC
Kno ledge
Enrichment Mod le
FIGURE 5.2: Overview of our NEMO model.
• Knowledge-Enrichment Module (KEM): Following a recent work by [VR21a],
we utilize a pretrained EVENTBERT for this component. EVENTBERT
leverages social commonsense knowledge to sharpen the social event
embeddings with semantic and pragmatic attributes. Here, the prag-
matic properties refer to the human’s inferred implicit understanding
of event actors’ intents and feelings or reactions. We feed the mental
state attribute m and the current story sentence s(t) as our input and get
a sentence-level attribute-specific pragmatics-aware embedding R
(t)
m as
the output of this module.
• Story Entity Encoder(STORYENTENC): Our modified Transformer-based
encoder is employed to produce prior story context embedding (C(<t))
and entity-aware representation (Ht
m) of the current story sentence (s(t))
104
Chapter 5. Modeling Human Motives and Emotions from Personal
Narratives
consolidating the prior story sentences (s(<t)), entity (ej) and mental
state attribute-specific pragmatics-aware knowledge embedding (R
(t)
m )
obtained from (KEM).
• Entity-based Memory Module (EMM) : This module is used to dynam-
ically track the prior mental states of characters in the narrative so
that the generated explanations are coherent to the previous events in
the narrative. Therefore, we keep track of previously generated men-
tal state representations in a separate memory indexed using each en-
tity (ej) and mental state attribute information (m) and denoted as
M[ej, m]. This module is accessed during the decoding phase by at-
tending over memory cells to obtain attribute-specific prior mental state
embeddings (M
(<t)
m ).
• Intent-Emotion Explanation Generator(IEE-DEC): Our two pass-iterative
decoder generates intent and emotion explanations by processing the
encoder outputs (C(<t), H
(<t)
m ), KEM output (R
(t)
m ), and attribute-specific
entity ej’s prior mental state embeddings M
(<t)
m retrieved from EMM.
5.4.1 Story Entity Encoder
Figure 5.3 presents a closer look into the model architecture. A variant of
the conventional Transformer encoder is used to produce an entity-aware
representation of the story. We introduce additional sub-layers to incorporate
prior context, entity, and mental state attribute information. Our encoding
strategy, STORYENTENC(·), is defined as:
(C(<t)
, H
(t)
m ) = STORYENTENC(s(t)
, s(<t)
, ej, m) (5.1)
5.4. NEMO: Our Proposed Model 105
where ej ∈ E is the entity under consideration, H
(t)
m is the resulting entity-
aware representation of the story at tth-step. Inspired by [Her+15], we iden-
tify character names in a story using Coref systems and replace them with
abstract markers to prevent degenerate solutions. We do not replace words
related to social roles. We randomly permute these entity markers from a
set of generic markers reused across multiple stories to primarily distinguish
them from other entities in the story during our training and testing process.
This allows us to embed unseen entities in new stories. We denote the story-
specific entity embeddings as Eej
∈ Rde .
Our STORYENTENC is composed of a stack of Ns identical layers. To cre-
ate an entity-specific understanding of the story, we perform the following
steps: (a) concatenate the character information along with the current sen-
tence to produce entity or character-aware representation of the story sen-
tence, (b) introduce an additional context-attention sub-layer that integrates
story context into the encoder, and (c) fuse knowledge representation related
to specific mental state attributes. The entity concatenated input sentence
is given as: [CLS] ej [SEP] w
(t)
1 , ..., w
(t)
L [SEP] and E
(t)
s is its correspond-
ing matrix containing dw-dimensional word-embedding vectors (in our case,
de = dw). Using steps (a) and (b), we integrate the interactions between
entity-specific information from the current story sentence and its prior con-
text. This process is given as follows:
U(l) = MHA(H
(l−1)
s , H
(l−1)
s , H
(l−1)
s ) (5.2)
V(l) = MHA(U(l), C(<t), C(<t)) (5.3)
H
(l)
s = FFL(V(l)) (5.4)
where l is the encoding layer, l ∈ {1, 2, ..., Ns} and H
(0)
s = E
(t)
s , C(<t) is the
prior story context embedding as computed in Section 5.4.1 and H
(l)
s is the
106
Chapter 5. Modeling Human Motives and Emotions from Personal
Narratives
Nc
Self-A en ion
Feed-For ard
S or Con e
Embedding
Self-A en ion
Con e -
A en ion
Feed-For ard
S or Sen ence
Embedding
Self-A en ion
Con e -
A en ion
Kno ledge-
A en ion
S a e E plana ion
Embedding
Encoder-Decoder
A en ion
Feed-For ard
Feed-For ard
Self-A en ion
Memor -
A en ion
Fir -Pa
Decoder A en ion
S a e E plana ion
Embedding
Feed-For ard
Kno ledge-
A en ion
Feed-For ard
Kno ledge
Enrichmen
Mod le
En i -ba ed
Memor Mod le
N
Nf
N
N
STORYENTENC IEE-DEC
FIGURE 5.3: Illustration of the full architecture of our NEMO
model.
embedding of the source sentence at the lth layer. Finally, we fuse the knowl-
edge representation (R
(t)
m ) related to specific mental state attribute (m) ob-
tained from (KEM) with the output at Nth
s layer (H
(Ns)
s ). The fusion step in-
volves Nf additional Transformer layers with the context-attention replaced
by knowledge-attention i.e. MHA(HNs
s , Rm(t), Rm(t)). We found in prelimi-
nary experiments that even a single fusion layer is effective in outperforming
our baselines. The output from the fusion layer is the final encoded story rep-
resentation, H
(t)
m , encapsulating context, entity and attribute-specific knowl-
edge information.
5.4. NEMO: Our Proposed Model 107
Context-Attention & Gating
We implement standard Transformer encoder layers for computing the story
context information from previous sentences s(<t). For the prior story context
s(<t), we insert a [CLS] and [SEP] token at the start and end of each sentence,
respectively. Since we add new sub-layers in this work, we introduce a gat-
ing mechanism instead of residual connections to prevent the uncontrolled
influence of information from sub-layers over the current sentence represen-
tation:
β = σ(W1H + W2 f (H)) (5.5)
G(H) = β + f (H) + (1 − β) + H (5.6)
where f refers to the sub-layers, σ(·) is a sigmoid function, W1, W2 are
learnable parameters.
5.4.2 Intent-Emotion Explanation Generator
Motivated by human cognitive behaviors, we explore the process of deliber-
ation into the sequence generation framework [Xia+17]. This is implemented
as a two pass-iterative decoding strategy. During the first pass, the decoder
generates a rough draft of the explanations (ŷ
(t)
o1
) by considering sentence-
level knowledge along with encoder outputs and prior context. The first
step decoding outputs are fed to the second pass decoder along with entity’s
mental state context obtained from an entity-based memory module EMM.
Formally, the two-step decoding procedure is denoted as:
ŷ
(t)
m,o2
= IEE-DEC(H
(t)
m , C(<t)
, R
(t)
m , M
(<t)
m ) (5.7)
where R(t) is the sentence-level knowledge embedding from KEM, M
(<t)
m is
the attribute-specific entity’s prior mental state embeddings retrieved from
108
Chapter 5. Modeling Human Motives and Emotions from Personal
Narratives
EMM. In order to generate entities’ intent and emotion explanations, we in-
troduce artificial tokens associated with mental state attributes as the start
token. These special tokens could be one of the following mental state at-
tributes, m ∈ {xIntent, xReact}. For brevity, we drop the subscript m from
the equations.
First-pass Decoding
Just like the encoder, our decoder has Ny stacked identical layers. We aug-
ment each layer with context and knowledge-attention sub-layers. While the
former provides prior story context representation (extracted from s(<t)), the
latter captures the attribute-specific sentence-level knowledge information
(R(t)). The first-pass decoding procedure is explained as follows:
U,(l) = MHA(H
(l−1)
o1
, H
(l−1)
o1
, H
(l−1)
o1
) (5.8)
V,(l) = MHA(U,(l), C(<t), C(<t)) (5.9)
W(l) = MHA(V,(l), R(t), R(t)) (5.10)
Z(l) = MHA(W(l), H(t), H(t)) (5.11)
H
(t)
o1
= FFL(Z(l)) (5.12)
where l ∈ {1, 2, .., Ny}, H
(l−1)
o1
is the output from previous layer, and
H
(0)
o1
= [y
(t)
0 , y
(t)
1 , ..., y
(t)
i−1] denotes the representation of words generated up
until the ith step (y
(t)
<i ). Before feeding our computed representations to a
feed-forward layer, we integrate the representation of the current sentence
from the encoder using encoder-decoder attention. At the end of Ny layers,
we compute word probabilities for the first-pass decoded sequence: P(ŷ
(t)
o1
) =
so f tmax(H
(Ny)
o1
). Here ŷ
(t)
o1
is the first-pass decoding output.
5.4. NEMO: Our Proposed Model 109
Second-Pass Decoder
During the second-pass decoder, we contextualize the current entity states’
using entity’s prior mental state embeddings (M(<t)) stored in an entity-
specific external memory (EMM) in combination with the first-pass decoder
outputs:
W,(l) = MHA(U,,(l), M(<t), M(<t)) (5.13)
Z,(l) = MHA(W,(l), Ĥ
(t)
o1
, Ĥ
(t)
o1
) (5.14)
where U,,(l) is the second-pass counterpart of self-attention sub-layer (U,(l))
and Ĥ
(t)
o1
is the representation of words generated during the first pass. The
polished mental state explanations are computed as: P(ŷ
(t)
o2
) = so f tmax(H
(Ny)
o2
),
where H
(l)
o2
= FFL(Z,(l)) is the feed-forward sub-layer output. Thus, ŷ
(t)
o2
is
the polished decoded output.
5.4.3 Knowledge-Enrichment Module
Knowledge-Enrichment Module (KEM) can be viewed akin to a semantic
memory [BC08]. Generally, semantic memory refers to a long-term store-
house of general knowledge related to events, facts, and concepts. The core
idea is to encode a story sentence into a pragmatics-aware embedding. The
pragmatic components refer to the implied emotions and intents associated
with the events in the story text. By leveraging social commonsense knowl-
edge explained in Section 3.1.2, we follow a recent work of [VR21a] and uti-
lize the EVENTBERT as our KEM to pretrain and effectively embed both se-
mantic and pragmatic aspects of social events.
The input is a concatenation of mental state attribute m ∈ {xIntent, xReact}
with the story sentence s(t). This is fed through the EVENTBERT to pro-
duce attribute-specific contextualized social event embeddings, R
(t)
m . This
110
Chapter 5. Modeling Human Motives and Emotions from Personal
Narratives
encoding step is followed by an attentive pooling function that attends over
contextual embeddings to output a summarized pragmatics-aware embed-
ding rm ∈ Rdh reflecting intents (m = xIntent) and emotional reactions
(m = xReact). We learn these representations by pretraining using an N-
pair loss (as in [VR21a]) for each intent or emotion explanations. By train-
ing on data from social commonsense knowledge sources, we enable the
model to learn pragmatics-aware representation of the social events. While
the contextual vectors R(t) are used during encoding and decoding phases,
the summarized vectors r
(t)
m are used to initialize our entity-based memory
module (EMM). MOre details on this component has already been described
in Chapter 4.
5.4.4 Entity-based Memory Module
Entity-based Memory Module can be seen as an episodic memory that ide-
ally stores the mental states of characters in a specific narrative. To track
entity-specific mental state representations, we utilize a memory, M, con-
taining separate memory cells for each entity ej and mental state attribute
m. Therefore, memory is indexed using entity embeddings (Eej
) and mental
state attribute embeddings (Em)). For simplicity, we denote it as: M[ej, m].
The memory operations are explained as follows: M = (K, A, V), where key
K is tied with entity embeddings, A refers to the mental state attribute m and
V contains the attribute-specific target-size context vectors.
Memory Attention: Our decoder applies a multi-head attention mecha-
nism over prior mental state representations of an entity M
(<t)
m for each men-
tal state attribute m. For a specific entity ej and mental state attribute m, we
retrieve (t − 1) memory cells from M[ej, m] by masking the future time steps.
Finally, we inject the sequence-order information using positional encoding
[Vas+17] to get M(<t) (drop the subscript m to be consistent with previous
5.5. Training & Hyperparameters 111
notations).
Memory Write: We keep track of prior mental states by storing their rep-
resentations in our memory M[ej, m]. It is possible to limit the memory al-
located to each entity for prior context (say n-previous sentences). However,
we don’t set such limits in this work. We initialize the memory with sentence-
level pragmatics-aware summarized vector, r
(t)
m . For the write operation, we
apply a gating mechanism to store the final decoder hidden state of ŷ
(t)
o2
given
as h
(t,L)
ŷo2
at the tth memory cell:
γ = σ(Wrr
(t)
m + Whh
(t,L)
ŷo2
) (5.15)
M[ej, m, t] = γ + r
(t)
m + (1 − γ) + h
(t,L)
ŷo2
(5.16)
where Wr and Wh are learnable parameters. In our experiments, we find that
this method is simple yet effective.
5.5 Training & Hyperparameters
Our aggregated data is split into train, validation, and test sets at 70-10-20
split. Following [Xio+19]’s work, our model is trained to minimize the neg-
ative log-likelihood of predicting each word during both the decoding steps:
L = Lmle1 + Lmle2. To handle our weakly-annotated data, we perform phase-
wise training of our model. We pretrain our model using all the social com-
monsense knowledge data where the entity or character information is con-
catenated with the input text during the first phase. The memory cells are
initialized to zero, and the model learns to produce sentence-level explana-
tions. The second phase involves modeling the current story sentence along
with the prior narrative context. We initialize the memory with pretrained
sentence-level knowledge embedding r
(t)
m once for a mini-batch and further
112
Chapter 5. Modeling Human Motives and Emotions from Personal
Narratives
update them with noisy explanations. This exposes the model to its potential
test-time errors and guides the model to learn robust parameters.
Using grid-search, we tune the hyperparameters and the best configura-
tion (Nc = 2, Nf = 1, Ns = 12, dh = 768 and 12 attention heads) is obtained
based on validation set perplexity. To prevent overfitting, we use dropout
with a rate of 0.2. By default, we experiment with GloVe vectors and ELMo-
based contextualized embeddings (usually mentioned during evaluation).
We use Adam as our optimizer with a learning rate of α = 0.0002 [KB14]
and a training batch size of 8. We use greedy decoding at training time, but
utilize beam-search with a beam size of k = {3, 5, 10, 12} [BCB14; SHB15] at
inference time.
5.6 Experiments
In this section, we describe the various evaluation settings: datasets, base-
lines, model variants, modes, and metrics. We designed our experiments to
study the following research questions:
RQ1: How well does our model perform compared to other baselines in
the explanation generation task? How much does each component impact
the overall performance?
RQ2: Can our model representations be used to perform state classifica-
tion based on labeled motivation and emotional reaction categories?
RQ3: Do the learned mental state representations exhibit transfer capa-
bility to a downstream task?
5.6. Experiments 113
Dataset #Stories #Motives #Emotions
Personal Narratives 300 882 1418
STORYCOMMONSENSE 2500 6831 13785
TABLE 5.1: Test set statistics for explanation generation task:
This includes number of annotated stories and number of
character-lines with motives and emotions.
5.6.1 Explanation Generation Task (RQ1)
Dataset
We run experiments on (a) the manually annotated gold explanations for
sampled data from personal narratives corpus and (b) the benchmark char-
acter psychology dataset – STORYCOMMONSENSE [Ras+18c]. Table 5.1 sum-
marizes the dataset used for evaluation of our explanation generation task.
Baselines
We compare our model’s performance to different baseline methods. We fol-
low a model architecture for the baseline methods as in [Ras+18c], where
they compute an encoded vector by concatenating the current sentence rep-
resentation along with the entity-specific context (involving sentences where
a particular entity appears). These methods are enlisted as follows:
• LSTM [Ser+17], which is a hierarchical RNN-based encoder-decoder
model. The sentence tokens are encoded using a bi-LSTM. The entity-
specific vector, computed using a similar method, is then concatenated
with the sentence vector.
• REN [Hen+16], which is a recurrent entity network updating entity
states in a dynamic long-term memory. A memory cell is initialized
for every entity in the story and updated after reading every sentence.
The memory vector in the cell corresponding to the entity under con-
sideration is the final encoded vector.
114
Chapter 5. Modeling Human Motives and Emotions from Personal
Narratives
• NPN [Bos+17], which performs dynamic entity tracking by explicitly
modeling actions as state transformers. Memory is initialized and ac-
cessed as in REN.
• GPT [Rad+18], which is a fine-tuned transformer-based language model
architecture. The input setup consists of the concatenation of entity
marker, story context tokens, current sentence tokens, and mental state
attribute token m separated by special [SEP] tokens. This is closely re-
lated to how GPT is used in [Bos+19].
Model Variants
By evaluating on the personal narrative corpus, we assess the impact of three
of our model components: KEM (semantic memory), EMM (episodic mem-
ory), IEE-DEC (deliberation decoder). To comprehensively study their im-
pact, we remove them one at a time as model variants and evaluate their
impact on the performance in the explanation generation task.
Metrics
Due to the short sequence length of generated explanations and the high
possibility of producing similar explanations in multiple ways, we avoid
word-overlap based metrics and instead compute embedding-based met-
rics such as embedding average and vector extrema for evaluating expla-
nation generation quality [Liu+16; HKN18]. Embedding average calculates
sentence-level embeddings by averaging the word embeddings of each to-
ken in a sentence. Vector extrema metric takes the most extreme value for
each dimension amongst all word vectors in the sentence and uses that value
in the sentence-level embedding. To compare the ground truth and gener-
ated explanation, we compute the cosine similarity between their respective
sentence-level vectors. These metrics Additionally, these metrics are useful
5.6. Experiments 115
Models Motivation Emotion
Avg VE Avg VE
HRED 58.43 48.78 52.05 51.18
REN 58.96 49.87 53.59 52.14
NPN 59.03 50.02 52.63 51.76
GPT 63.56 54.77 56.74 56.09
NEMO 69.27 59.78 62.88 61.34
COMET repl. 66.55 58.23 60.78 60.21
w/o EMM 67.16 57.64 59.74 58.38
w/o KEM 65.38 56.86 60.58 60.06
w/o IEE-DEC 66.92 58.17 60.42 59.83
(A) Personal Narrative Corpus
Models Motivation Emotion
Avg VE Avg VE
Random 56.02 45.75 40.23 39.98
LSTM 58.48 51.07 52.47 52.30
REN 58.83 51.79 53.95 53.79
NPN 57.77 51.77 54.02 53.85
GPT 60.19 52.95 55.68 55.47
NEMO 66.25 59.16 62.78 61.92
(B) STORYCOMMON-
SENSE dataset
TABLE 5.2: Automatic evaluation results on (a) Personal Nar-
ratives corpus & (b) STORYCOMMONSENSE dataset. Bold face
indicates leading results for the corresponding metric.
for comparison with the previous benchmark used for the generation task
[Ras+18c].
Results
The main results of our evaluation on Personal narratives and STORYCOMM-
ONSENSE datasets are summarized in Table 5.2a and Figure 5.2b respectively.
We observe that our complete model achieves an absolute mean improve-
ment of ∼ 9% and ∼ 12% over a fine-tuned GPT model using the embedding
average metric of the generated intent and emotion explanations respectively
across both the datasets.
116
Chapter 5. Modeling Human Motives and Emotions from Personal
Narratives
Effect of architectural choices By training variants of our NEMO model
with and without specific components of the model, we are able to ascer-
tain their importance for the task at hand. Table 5.2a shows that our KEM
and EMM yield significant boost to the overall performance. The dip in per-
formance on intent generation is more pronounced when KEM is removed
while EMM is critical for the improved performance of emotion generation.
We intuit the reason to be the additional sentence-level commonsense knowl-
edge infused by KEM leading to better generations of intents while entities’
prior states from EMM guiding the overall prediction of the current emotional
state.
Effect of Knowledge Embeddings From Table 5.2a, it is clear that KEM pro-
vides really good performance gains. Further, we replace the knowledge em-
beddings obtained from KEM with the embeddings extracted from COMET
[Bos+19]. COMET is a framework that adapts the language model weights
to produce diverse commonsense knowledge tuples. The scores reported in
Table 5.2a indicate that there is a significant advantage of using KEM em-
beddings over COMET. Also, we note that COMET only provides a small
marginal improvement in comparison to a NEMO model without KEM com-
ponent. But the addition of our KEM component provides a huge jump in
performance, specifically while generating motives. This can be attributed
to the social role information, a characteristic of our social commonsense
knowledge resource, utilized by our KEM module. We verify this in the error
analysis (see Section 5.6.2).
Human Evaluation of Trajectories
We conduct a human evaluation to test the effectiveness of our NEMO model
in generating motivation and emotion explanation trajectories. Our exper-
iment compares our model explanations to those obtained from GPT-based
5.6. Experiments 117
model. We randomly select 100 stories and present the story, character, and
the visualization of trajectories to three workers. The workers then select the
trajectory that best matches the characters’ mental states. The inter-annotator
agreement had a Fleiss’ κ = 0.74 and κ = 0.78 for intent and emotion tra-
jectories respectively, indicating substantial agreement among the workers.
Moreover, 47 intent and 56 emotion trajectories had a unanimous agreement
among three workers, of which 45 intent and 52 emotion trajectories were in
favor of trajectories generated by NEMO. Based on the majority agreement,
the workers selected our intent and emotion trajectories for 81% and 83% of
the presented stories, respectively. Thus, it is clear that our model is able to
generate better explanation trajectories.
Qualitative Analysis
Effect of Context We investigate the effect of context in producing convinc-
ing explanations for our text by filtering null attention and plotting an atten-
tion map between context and source text (see Figure 5.4). Notably, this par-
ticular attention head (head-6) maps specific source words to their relevant
context words. The attention head’s focuses on the following words: “re-
locate” #→ {“lived”,“beach“, “hurricane”} and “they” #→ {“jennifer”,“her“,
“family”}. Further, we also show sample generation with and without the
context information. It is evident from these examples that NEMO can iden-
tify particular aspects of the context that are relevant (e.g., antecedents, spa-
tial concepts) and leverage them to produce appropriate explanations.
Effect of Two-pass decoding Step Figure 5.5 provides sample motivations
generated by our proposed model in multiple passes along with GPT (as it
performs competitively for our task). We demonstrate our model’s ability to
generate explanations from the narrator’s perspective (1st person) and that
118
Chapter 5. Modeling Human Motives and Emotions from Personal
Narratives
 HYDOBLPJGUDZLR
6(3!
WKH\
KDYH
GHFLGHG
WR
UHORFDWH
WR
D
QHZ
SODFH
MHQQLIHU
DQG
KHU
IDPLO\
OLYHG
QHDU
WKH
EHDFK
6(3!
WKH\
KHDUG
D
KXUULFDQH
ZDV
FRPLQJ
6(3!








&RQWH[W-HQQLIHUDQGKHUIDPLO\
OLYHGQHDUWKHEHDFK7KH\KHDUGD
KXUULFDQHZDVFRPLQJ7KH\KDYH
GHFLGHGWRUHORFDWHWRDQHZSODFH
6RXUFH7KH\KDYHGHFLGHGWR
UHORFDWHWRDQHZSODFH
&KDUDFWHU-HQQLIHU
Z&RQWH[W ,QWHQW¬WRJHWDZD\
IURPWKHVWRUPWREHVDIH
ZR&RQWH[W ,QWHQW¬WRKDYHD
QHZSODFHWROLYHLQWRVWDUWD
QHZOLIH
&RPSDUDWLYH*HQHUDWLRQV
,QSXW7H[W
&RQWH[W , ZDV MRLQLQJ D JUDG VFKRRO DW
WLPHZKHQHWKQLFSUREOHPVZHUHULIH
6RXUFH$V,ZDVFURVVLQJWKHURDGWRJHW
WR P\ FODVV WKHUH ZDV D JLUO ZKR ZDV
UHVLVWLQJWKHSROLFHEUXWDOLW\OHDGLQJIURP
IURQWDQGODWHU,MRLQHGLWWRR
0RGHOV (QWLW\&KDUDFWHU, P\VHOI
*37
 WRJHWWRWKHFODVV
 WRJDLQNQRZOHGJH
 WREHVDIH
2XU0RGHO
)LUVWSDVV
 WRJHWWRWKHFODVVTXLFNO\
 WRJHWWRWKHFODVVLQSUREOHPV
 WRGHIHQGVRPHRQH
2XU0RGHO
6HFRQG3DVV
 WRJHWWRWKHFODVVRQWLPH
 WRVWDQGXSIRUDFDXVH
 WRGHIHQGVRPHRQHLQDVLWXDWLRQ
6DPSOH*HQHUDWLRQ
&RQWH[W6LQFH,ZDVDNLG,ZDQWHGWREHDZULWHU,
ZDQWHGWRPDNHSHRSOHKDSS\DQGKDYHWKHPEHVXSHU
H[FLWHGWRUHDGZKDW,GLG:HOOODVWQLJKWWKLVEHFDPHD
UHDOLW\DQG,JRWDQRWKHUERRNSXEOLVKHG,ZDVSURXG
DQGKDSS\,ZDVH[FLWHGWRVKDUHZLWKIULHQGV%XWRQO\
IRXUIULHQGVFDUHGWRHYHQUHDGLW
6RXUFH,·POHJLWLPDWHO\KHDUWEURNHQDQGGLVLQWHUUHG
(QWLW\&KDUDFWHU, P\VHOI
 WRH[SUHVVP\IHHOLQJV
 WRH[SUHVVP\IHHOLQJVDERXWWKHERRN
 WREHDJUHDWDXWKRU
5HSODFH´RQO\IRXUµZLWK´RQO\DKDQGIXORI IULHQGVµ
 WRH[SUHVVP\IHHOLQJV
 WRKDYHDORWRI IULHQGVWRUHDGLW
 WRKDYHDORWRI IULHQGVWRUHDGWKHERRN
G
E
H
D
FIGURE 5.4: Attention map (head-6) between context and
source. On the x-axis are the source tokens, on the y-axis the
context tokens.
of another entity/character in the narrative. The result also shows improve-
ment after the second-pass decoding.
Input Text
Context: I loved Mary intensely. But
she wanted to be only friends with me.
Source: She found a guy called John
Context: I was joining a grad school at
time when ethnic problems were rife.
Source: As I was crossing the road to
get to my class, there was a girl who
was resisting the police brutality,
leading from front and later I joined it
too.
Models Entity/Character: Mary Entity/Character: I (myself)
GPT
• none
• to be loved
• to be happy
• to get to the class
• to gain knowledge
• to be safe
Our Model
(First pass)
• to have a relationship
• to be with him
• to be loved by someone
• to get to the class quickly
• to get to the class in problems
• to defend someone
Our Model
(Second Pass)
• to have a relationship with john
• to be friends with john
• to have a relationship with the guy
• to get to the class on time
• to stand up for a cause
• to defend someone in a situation
FIGURE 5.5: Generation of motivation explanations in multiple
decoding steps.
5.6. Experiments 119
5.6.2 State Classification Task (RQ2)
Dataset
The STORYCOMMONSENSE dataset comprises over 300k low-level annota-
tions for motivations and emotions across 15,000 short stories selected from
ROCStories training set [Ras+18c]. This dataset includes the categorization
of motivations and emotional reactions based on different classical theories
of psychology.
Experimental Settings & Baselines
We conduct experiments under the following settings:
• Zero-shot (ZS) In this setting, we map the generated emotion expla-
nation to one of the 8 Plutchik’s categories via nearest neighbor search
in the word-embedding space: ȳc = argmaxc∈C(cos(EŷxReact
, Ec)), where
c ∈ C is the label related to Plutchik’s categories. Without any further
fine-tuning, we compare our results against COMET-CGA [BC19] and
use their word formulation setup for labels.
• Supervised (SS) We fine-tune our trained model using a feed-forward
layer on the top of the encoder output. Additionally, we experiment
with (NEMOE) and without (NEMONE) annotated explanation train-
ing. In addition to the baselines in the original work, we compare
against – BiLSTM + Self-Attention (BM) and BiLSTM + Self-Attention
+ Knowledge (BM+K) which incorporate multihop knowledge paths
using graph-based algorithms [PF19] for predicting human needs (mo-
tivation categories). Additionally, we report scores from a recent work
[Gao+20] that uses label semantics (referred to as LS) and track label-
label correlation for emotion inference task.
120
Chapter 5. Modeling Human Motives and Emotions from Personal
Narratives
F1
score
0
14
28
42
56
70
Percentage of Training data
20% 40% 60% 80% 100%
E NE
G
U
7
6
6
7
3
4
FIGURE 5.6: Prediction performance under low-resource (LR)
settings (limited amounts of training data).
• Low-resource regimes (LR) This scenario has a significant practical
interest, specifically in adapting our model to domains with a small
amount of in-domain labeled data. Having trained on personal narra-
tives corpus, we simulate low resource regimes by varying the percent-
age of training examples from STORYCOMMONSENSE state classifica-
tion dataset.
Metrics
Consistent with prior study [Ras+18c], we compute the micro-averaged F1
scores for the state classification task: Maslow, Reiss and Plutchik states.
Results
Visibly, our models (in Table 5.3) outperform the state-of-the-art methods sig-
nificantly in both settings. With ELMo-based embeddings, the improvements
are even more pronounced. For the zero-shot settings, we report the scores
5.6. Experiments 121
Models Maslow Plutchik Reiss
COMET-CGA (ZS) _ 19.30 _
COMET-CGA (T) _ 27.50 _
NEMO (ZS) _ 42.61 _
LSTM 34.55 28.81 24.51
CNN 35.23 30.04 24.21
REN 33.57 30.15 20.53
NPN 31.69 30.29 17.75
BM 53.54 _ 26.57
BM+K 56.69 _ 32.96
BM (ELMo) 59.81 _ 35.49
BM+K (ELMo) 61.72 _ 36.70
LS _ 65.88 _
NEMOE 69.77 68.16 45.76
NEMONE 67.37 66.57 46.21
NEMOE (ELMo) 72.09 71.26 48.52
w/o EMM 69.13 67.19 45.50
w/o KEM 66.28 68.61 43.92
COMET repl. 66.95 69.14 43.92
TABLE 5.3: State classification performance under supervised
settings. ZS: Zero-Shot Settings, T-Tuned Hyperparameters as
reported in [BC19]
directly from the original work [BC19]. We find a similar pattern in the state
classification task for the supervised setting as in Section 5.6.1. The impact
of COMET is only marginally felt while the KEM component provides a rela-
tively huge performance boost. Interestingly, our results in Figure 5.6 suggest
that the model variant fine-tuned with explanations learns faster with lesser
in-domain labeled data than its counterpart without explanation fine-tuning.
We note that both these models outperform several baselines with less than
40% of training examples. We believe that the explanation fine-tuning fur-
ther sharpens the learned mental state representations as the annotations are
much cleaner than our aggregated personal narratives corpus.
122
Chapter 5. Modeling Human Motives and Emotions from Personal
Narratives
Error Analysis
Decoding Phase During the beam-decoding step for sentences irrelevant
for a particular entity, “none” can only be predicted once, which causes other
candidates in the beam to be incorrect if “none” is the appropriate answer.
However, we posit that the embeddings hold richer information than the ex-
planations generated due to the limitations in the way we implement the
decoding. For the explanations, we observe that the models miss out on
quantities that are expressed as numbers or ambiguous phrases used in so-
cial media personal narratives. Figure 5.7 shows an example where a small
replacement to the input produces better explanations.
Emotion State Classification A noticeable trend in the categorization task
is the high level of cross-predictions among related emotions. Several mis-
classifications occur between joy-surprise and anger-disgust categories. The
subtle difference between those emotion pairs makes it harder for the models
to distinguish them in some cases clearly.
Intent State Classification Since we observed only a marginal improve-
ment with the addition of the COMET module, we compare the difference
in errors made by COMET replaced NEMO model in comparison to our com-
plete NEMO model for predicting Maslow’s motivation categories. We gauge
that COMET replaced model made more errors (in ∼ 24.5% of the cases) when
the stories contain more than one social role information. This validates our
claim that the social role information captured by our NEMO with KEM mod-
ule is beneficial for both the classification and generation task.
5.6. Experiments 123
QH
SODF
HQHUDWLRQV
J D JUDG VFKRRO DW
HPVZHUHULIH
LQJWKHURDGWRJHW
V D JLUO ZKR ZDV
WDOLW\OHDGLQJIURP
WWRR
U, P\VHOI
FNO\
SUREOHPV
WLPH
XVH
LQDVLWXDWLRQ
6DPSOH*HQHUDWLRQ
&RQWH[W6LQFH,ZDVDNLG,ZDQWHGWREHDZULWHU,
ZDQWHGWRPDNHSHRSOHKDSS\DQGKDYHWKHPEHVXSHU
H[FLWHGWRUHDGZKDW,GLG:HOOODVWQLJKWWKLVEHFDPHD
UHDOLW\DQG,JRWDQRWKHUERRNSXEOLVKHG,ZDVSURXG
DQGKDSS\,ZDVH[FLWHGWRVKDUHZLWKIULHQGV%XWRQO\
IRXUIULHQGVFDUHGWRHYHQUHDGLW
6RXUFH,·POHJLWLPDWHO\KHDUWEURNHQDQGGLVLQWHUUHG
(QWLW\&KDUDFWHU, P\VHOI
 WRH[SUHVVP\IHHOLQJV
 WRH[SUHVVP\IHHOLQJVDERXWWKHERRN
 WREHDJUHDWDXWKRU
5HSODFH´RQO\IRXUµZLWK´RQO\DKDQGIXORI IULHQGVµ
 WRH[SUHVVP\IHHOLQJV
 WRKDYHDORWRI IULHQGVWRUHDGLW
 WRKDYHDORWRI IULHQGVWRUHDGWKHERRN
E
E
H
D
FIGURE 5.7: Sample generations showcasing the limitations of
NEMO.
5.6.3 Application: Empathetic Dialogue Generation (RQ3)
Natural social interactions require humans to recognize and infer others’ im-
plied emotions and respond appropriately by acknowledging their underly-
ing feelings. Since NEMO infers motivations and emotion states from stories,
we posit that the embeddings learned from such a model can lead to im-
proved performance on this dialogue generation task.
124
Chapter 5. Modeling Human Motives and Emotions from Personal
Narratives
Models PPL
AVG
BLEU
Fine-Tuned 21.24 6.27
Fine-Tuned Large 16.55 8.06
EmoPrepend-1 24.30 4.36
TopicPrepend-1 25.40 4.17
Ensem-DM 19.05 6.83
Ensem-SCS+ 17.06 7.64
TABLE 5.4: Automatic evaluation metrics on ED test set.
Ensem-SCS+: model incorporating our learned embeddings.
Dataset
We use EMPATHETICDIALOGUES (ED) dataset, introduced by [Ras+18d], for
evaluating the ability of NEMO representations to improve generation of em-
pathetic responses. The dataset consists of 25k personal dialogues grounded
in specific emotional situations where a speaker was feeling a given emotion,
with a listener responding. The train/ val/ test split was 19533/ 2770/ 2547
conversations, respectively.
Model & Baselines
Following Rashkin et al.’s prior work [Ras+18b], we experiment with the
ensemble of encoders that augments the encoders to incorporate the embed-
dings extracted from pretrained architectures. The ensemble model that in-
corporates our mental state representations is referred to as “Ensem-SCS+”.
We compare our ensemble model with other well-performing benchmarks
reported in [Ras+18b] involving pretrained external predictors:
• Ensem-DM: An ensemble model with supervision from trained Deep-
moji system [Fel+17].
• EmoPrepend-1: Add an emotion label to the beginning of the token
sequence as encoder input. This is obtained from a separate classifier
that predicts emotion labels from the description of the situation.
5.7. Conclusion 125
• TopicPrepend-1: Similarly, the top predicted label from the supervised
topic classifier is merely prepended to the beginning of the token se-
quence as encoder input.
Results
For the above baselines, we report the values directly from the original work.
Table 5.4 shows that our Ensem-SCS+ model produces significant improve-
ment in automated metrics, quantifying the impact of using our learned rep-
resentations. Our model with a relatively lower number of parameters is able
to perform closer to the best performing large model.
5.7 Conclusion
In this paper, we present a Transformer-based method to model the mental
states of characters related to the events in the personal narratives. Using
data mining and information extraction techniques, we aggregate weakly-
annotated data to train our model known as NEMO. We show that the pro-
posed method is able to outperform several baselines in mental state tracking
task. We also observe that the pretraining on weakly-annotated data helps in
improving the overall performance under low-resource settings. We believe
that further improvements can be achieved in explanation generation and
state categorization in cases where the text contains character-irrelevant con-
tent or non-events by introducing specialized knowledge in our model. Our
analysis also demonstrated the transferability of our learned representation
in a downstream empathetic response generation task. Future work could in-
vestigate the applicability of these mental state representations in modeling
vital elements of narrative structures.
127
Chapter 6
Modeling Narrative Structure in
Short Personal Narratives
6.1 Introduction
Narratives are the fundamental means by which people organize, under-
stand, and explain their experiences in the world around them. Researchers
in the field of psychology maintain that the default mode of human cogni-
tion is a narrative mode [Bec15]. Humans share their personal experiences
by picking specific events or facts and weave them together to make mean-
ing. These are referred to as personal narratives, a form of autobiographical
storytelling that gives shape to experiences. [Pol88] suggested that personal
narratives, like other stories, follow broad characteristics involving: (a) typi-
cally a beginning, middle, and end, (b) specific plots with different characters
and settings, or events. Often, characters learn something or change as a re-
sult of the situation or a conflict and resolution, but not always. Some of these
characteristics provide a basis for the organizational framework of a story,
commonly referred to as the narrative structure or the storyline. The grow-
ing amount of personal narrative text information in the form of social media
128 Chapter 6. Modeling Narrative Structure in Short Personal Narratives
posts, comments, life stories, or blog posts presents new challenges in keep-
ing track of the storyline or events that form the defining moments of the nar-
rative. Several recent works [Dor+18; Yua+17; CLG17; Ko+18; Mos+17] have
made efforts to advance the research in narrative comprehension. However,
the development of computational models that automatically detect and in-
terpret different structural elements of a narrative remains an open problem.
Discovery of structural elements of a narrative has many applications in: (a)
retrieval of narratives based on similar dramatic events or concepts instead
of keywords [MAP91; FW06; MLL91], (b) linking related stories that form
a narrative thread towards theme generation [BS13; Sun07], (c) summariza-
tion of stories [Leh81; Pap+20] and (d) story ending prediction or generation
[CCY19; Li+13; Mos+17], (e) commonsense reasoning [Goo+12; GBS11], to
list a few.
My dad just turned 60 and I just love my dad
to bits. Last few days have been a
rollercoaster ride. My dad looked tired and
less active than usual. My dad was
diagnosed with CoVID-19 few days back and
kept on ventilator. So I felt so pained to see
my strong dad turn so sick and meek. After a
week of treatment, he has Hinally recovered
and now I feel so relieved.
Climax
Resolution
Exposition
Inciting Incident
R
i
s
i
n
g
A
c
t
i
o
n
Resolution
Dénouement
F
a
l
l
i
n
g
A
c
t
i
o
n
Climax
Narrative Progression
Action/
Tension
FIGURE 6.1: (Left) Freytag’s Pyramid. (Right) Highlights of
climax and resolution for a sample personal narrative.
Researchers in narratology have analyzed various components of a nar-
rative that contribute to a notion of plot quality referred to as ‘tellability’. It is
commonly derived from certain structural properties used in narrative the-
ory. Several narrative theories have been proposed such as Freytag [Fre94],
Prince [Pri12], Bruner [Bru91b; Bru09], Labov & Waletzky [LW97], to name
a few. These theories explain different elements of a narrative structure con-
taining typical orderings between them. Certain elements of the narrative
structure are correlated across different narrative theories. For example, Bruner’s
6.1. Introduction 129
‘breach in canonicity’ [Bru91b] could correspond to (a) Freytags ‘climax’ – re-
ferring to the ‘turning point’ of the fortunes of the protagonist [AH14] or (b)
Labov’s ‘most reportable event’ – describing the event that has the greatest
effect upon the goals, motivations and emotions of the characters (partic-
ipants) in the narrative [LW97; Lab06]. Shorter narratives tend to consist
mostly of complicating actions that culminate in the MRE or climax and in-
stances of events that reach a ‘resolution’ stage indicated by a swift drop
in dramatic tension. In comparison, the other structural elements are more
likely to occur in longer narratives. Figure 6.1 (Left) shows the Freytag’s
pyramid containing the key elements of the narrative structure, and Figure
6.1 (right) includes highlights of climax (used interchangeably as MRE) and
resolution for a sample personal narrative. Thus, our work aims to leverage
computational approaches at the intersection of information retrieval, NLP,
and psychological aspects and model the key elements of narrative structure
– MRE and resolution. As a working definition, we consider an MRE/climax
to be contained in the sentence(s) based on the following criteria: (a) it is an
explicit event at the highest tension point of the story, and (b) it is the only
event that can be reported as the summary of the story. Similarly, an event
qualifies as ‘resolution’ if it usually occurs after the MRE and resolves the
dramatic tension in the narrative.
Papalampidi et al. [PKL19] introduced a dataset consisting of movie screen-
plays and plot synopsis annotated with turning points. Few attempts have
been made at annotating elements of high-level narrative structures [Li+17]
and automatically extracting them from the text. Ouyang et al. [OM15]’s
study on predicting MRE in narratives is the closest work to the problem con-
sidered in this study. While most of these methods rely on syntactic, seman-
tic, surface-level affect or narrative features obtained using hand-engineering
or pretrained semantic embedding methods to model narrative structure, we
investigate the role of the protagonist’s psychological states in capturing the
130 Chapter 6. Modeling Narrative Structure in Short Personal Narratives
pivotal events in the narrative and their relative importance in identifying
the elements of narrative structure – Climax and Resolution. We find the
basis for this study in prior theoretical frameworks [Mur03; Rya86; OM14;
Leh81; Sch16] that emphasize (a) how narrative structure organizes the use
of psychological concepts (e.g., intentions, desires, and emotions) and medi-
ates all the human interactions and their social behavior, and (b) how pro-
tagonist’s mental states (both implicit and explicit inferences, also imputed
by readers) and psychological trajectory correlate with the classic dramatic
arc of stories. Thus, to obtain the protagonist’s mental states, we refer to a
recent work [VR21b; Sap+19a; Ras+18c] that tracks characters’ mental states
using an external memory module and enables pragmatic enrichment of nar-
rative sentences based on social commonsense knowledge aggregated using
information retrieval and data mining strategies. Towards our overarching
goal of detecting climax and resolution in short personal narratives, we im-
plement an end-to-end computational model that uses a multi-feature fusion
technique to effectively integrate the protagonist’s mental state representa-
tion with linguistic information at syntactic and semantic levels. Our contri-
butions are summarized below:
• A STORIES1 corpus containing a collection of Reddit Personal Narra-
tives with fine-grained annotations of prominent structural elements of
a narrative – climax and resolution.
• An end-to-end neural network for modeling narrative structure, re-
ferred to as M-SENSE2, that allows for integration of protagonist’s men-
tal state representations with linguistic information through a multi-
feature fusion technique.
1Short for STructures Of ReddIt PEsonal Stories
2Short for Mental State Enriched Narrative Structure modEl
6.2. Related Work 131
• Experiments that analyze the impact of our modeling choices for short
personal narratives. Specifically, we gauge the influence of incorporat-
ing mental state embeddings and report an improvement in F1 scores
of ∼ 11% and ∼ 13% over the base model for predicting climax and
resolution, respectively.
6.2 Related Work
There is a large body of prior work that focuses on different aspects of nar-
rative comprehension. Computational analysis of narratives operates at the
level of characters and plot events. Examples include plot-related studies
– story plot generation, plot summarization, detecting complex plot units,
modeling event schemas and narrative chains and movie question-answering;
character-based studies – inferring character personas or archetypes, analyz-
ing inter-personal relationships and emotional trajectories, identifying ene-
mies, allies, heroes [CVR18; BOS13; VCR20; Ras+18c; VR21b]; story-level
analysis – story representation, predicting story endings, modeling story sus-
pense, and creative or artistic storytelling, to list a few [VVZO15; LDL19;
SCM16; Joc13; Fin16; Tam+18].
Several studies have analyzed the literature in narratology and formu-
lated different goals and annotation labels associated with narratives towards
modeling their structure. Elson’s [Els12a] Story Intention Graph (SIG) pro-
vided an annotation schema to capture timelines as well as beliefs, intentions,
and plans of story characters. The annotations in this approach are simi-
lar to story generation methods described in Belief-Desire-Intention agents
[RG+95], and intention-based story planning [RY10]. Previous studies like
[GBS11] have analyzed the personal web blog stories containing the every-
day situation. Rahimtoroghi et al. [Rah+14], and Swanson et al. [Swa+14]
132 Chapter 6. Modeling Narrative Structure in Short Personal Narratives
used a subset of Labov’s categories, including orientation, action, and evalu-
ation in such personal weblog narratives. Black and Wilensky (1979) evalu-
ate the functionality of story grammars in story understanding, As explained
earlier, [PKL19]’s dataset for analyzing turning points is a valuable addition
in this area of work. Moreover, there has been consistent efforts [Jor+18;
Jor+19] that study the link between Information Retrieval (IR) and narra-
tive representations from text. These include works that exploit narrative
structure in movies for IR [Jha08], detect and retrieve narratives in health
domain (patient communities & medical reports) [Joh+08; RMA04; DVK19;
KCZ17], identify narrative structures in news stories [BBP20; Lev+20] or gen-
erate summaries from screenplays or novels [Pap+20], to name a few. Given
this broad spectrum of work, we leverage mental state representation models
that are pretrained using social commonsense knowledge aggregated using
IR and text mining techniques. We employ the ensuing mental state embed-
dings in tandem with contextual semantic embeddings towards our primary
objective of identifying elements of high-level narrative structure – climax
and resolution. We also conduct a detailed analysis of the outcome and the
contribution of the protagonist’s psychological state trajectory for our prob-
lem at hand.
6.3 Dataset
As described in detail in Chapter 3, we construct a manually annotated cor-
pus, referred to as our STORIES dataset. This dataset contains a total of 2,382
Reddit personal narratives, comprising 42,614 sentences. Table 6.1 shows
the descriptive statistics of our dataset. With our annotation setup, we are
able to obtain a substantial inter-annotator agreement for both the categories
indicating the rise and fall of dramatic tension (climax and resolution, re-
spectively). Notably, the annotators can discern between the two interest
6.4. M-SENSE: Modeling Narrative Structure 133
Dataset Statistics
#Stories 2,382
#Total Sents. 42,614
#Climax Sents. 5,173
#Resolution Sents. 4,502
TABLE 6.1: Statistics of our annotated STORIES dataset.
categories despite the high cognitive load and complexity involved in ex-
tracting them from unstructured user-generated content. We will be using
this dataset for the study in this work.
6.4 M-SENSE: Modeling Narrative Structure
In this work, we explore different modeling and analysis methods for under-
standing narratives and automatically extracting text segments that act as
key elements of narrative structure, particularly climax and resolution. We
use the collected dataset to train and evaluate models to identify sentences in
a narrative that qualify as climax and resolution. The models are provided a
narrative text T with L sentences, T = [S1, S2, ..., SL], as input. Here, each sen-
tence Si contains Ni words {wi
1, wi
2, .., wi
Ni
} from vocabulary V. Towards auto-
matic detection of structural elements, we formulate it as a sentence labeling
task where the goal is to predict a label ŷi ∈ {None, Climax, Resolution} for
each sentence Si, based on the story context. Various modeling techniques
examined in this work involve processing narratives at the sentence level.
Beyond linguistic features extracted from narratives, we focus on a domi-
nant aspect in which a narrative is formed or presented, which accounts for
characters’ mental states – goals, intentions, actions, and emotions. Thus,
we leverage transfer learning from pretrained models trained to infer char-
acters’ mental states (specifically, intents and emotional reaction) from a nar-
rative. Combining the embeddings extracted from pretrained mental state
134 Chapter 6. Modeling Narrative Structure in Short Personal Narratives
S Enc de
Sen ence Enc de
In e ac i n La e
(b)
Cla ifica i n La e
F i n La e
NEMO
high school I e felt
for a school e ent or
March of this ear I e
Getting rejected e er
a job at the restaurant
orro I m so proud of
as amiss I got a te t
ankfull She s ine and
er message sa ing that
d turned true In a a
ill not quite o er it like
d ine I m e pecting to
l a lot better
rked ith her o er the
t ho life asn t orth
and as just gone I m
all don t kno hat to
us She ne er thought
struggling to get o er
T an f me -ba ed F i n
STORYENTENC
IEE-DEC
Enc de :
Dec de :
Kn ledge
En ichmen
M d le
En i -ba ed
Mem
In en /Em i n E lana i n
FIGURE 6.2: Illustration of our M-SENSE model. Note that
hi1 = hi; hi2 = ĥi; hi3 = h̃i relate to semantics (xSem), intents
(xIntent) and emotional reactions (xReact) of the ith sentence
respectively.
model with other semantic features may reap benefits from the relationship
between characters’ underlying psychological processes (or mental states)
and narrative structure [Rya91; Pal10] and prior training involving social
commonsense knowledge. Therefore, we investigate a multi-feature fusion-
based learning model, M-SENSE, that potentially encapsulates syntactic, se-
mantic, characters’ mental state features towards our overall goal of predict-
ing climax and resolution in short personal narratives. Below, we discuss the
model components in more detail.
Our M-SENSE model comprises of the following components:
• Ensemble Sentence Encoders, which utilizes multiple encoders to pro-
duce per-sentence linguistic and mental state embeddings.
• Fusion layer, which integrates the protagonist’s mental state informa-
tion with the extracted linguistic features from sentences.
6.4. M-SENSE: Modeling Narrative Structure 135
• Story Encoder, which maps the fused sentence encodings into a se-
quence of bidirectionally contextualized sentence embeddings. The in-
put to this component can be either a sequence of token or sentence em-
beddings, depending on the modeling choice. Considering the impor-
tance of the overall story context towards evaluating each sentence’s
role in the entire narrative, this component integrates the surround-
ing story context information for computing rich sentence-level embed-
dings.
• Interaction layer, which estimates state transition across sequential con-
text windows to identify the structure boundaries.
• Classification layer, which involves linear layers to calculate the label
probabilities eventually.
6.4.1 Ensemble Sentence Encoders
Several sentence encoding methods [Dev+18; Cer+18; PSM14] have been pro-
posed to tackle specific tasks or produce embeddings generalizable across
multiple NLP problems. In this work, we aim to exploit both linguistic and
cognitive or mental state features towards building an enhanced model for
narratives. The former is extracted using a general-purpose language repre-
sentation model usually trained on extensive text data (e.g., BERT, USE). In
contrast, we use a dedicated pretrained task-specific model for the latter.
Extracting Linguistic Representations
Pretrained general-purpose sentence encoders usually capture a hierarchy of
linguistic information such as low-level surface features, syntactic features,
and high-level semantic features. Given a narrative text with L sentences T =
[S1, S2, ..., SL], this component outputs hidden representations for sentences
Hsents = [h1, h2, ..., hL] using different encoding methods. We intuit that the
136 Chapter 6. Modeling Narrative Structure in Short Personal Narratives
choice of sentence encoding models and features extracted can significantly
impact the overall performance for the task at hand. Instead of training a
sentence encoder from scratch, we leverage pretrained models to produce
embeddings for sentences in the narrative. In our MSENSE model, we use a
token-level BERT-based sentence encoder.
Token-level BERT: Since BERT produces output vectors that are grounded
to tokens instead of sentences, we undertake an input processing step that in-
volves insertion of a special [CLS] token at the beginning of each sentence
and a [SEP] token at the end of each sentence in the input sequence. we feed
the entire narrative text T to the input processing step to get the following
sequence: {[CLS], w1
1, w1
2, .., w1
N1
, [SEP], [CLS], w2
1, w2
2, .., w2
N2
, [SEP], .., [SEP],
[CLS], wL
1 , wL
2 , .., wL
NL
, [SEP]}, where wi
j is the jth in ith sentence in the narra-
tive. The multiple [CLS] symbols will aggregate the features for sentences
taking the context into consideration. Next, we apply alternating segment
embeddings indicative of different sentences in our input textual narrative.
Given a narrative with four sentences, [S1, S2, S3, S4], we assign the segment
embeddings as [EA, EB, EA, EB]. Finally, this processed input is fed to the pre-
trained BERT model as:
H = [h1
[CLS], .., h1
N1
, h1
[SEP], .., hi
[CLS], .., hi
Ni
, .., hL
[SEP]] = BERT(T) (6.1)
The hidden representation of ith [CLS] token from the top BERT layer is
extracted as the semantic embedding of the ith sentence. However, we drop
the subscript [CLS] from hi
[CLS] and denote the output semantic embeddings
as:
HxSem
sents = [h1
, h2
, ..., hL
] (6.2)
In section 6.7, we compare the performance of token-level BERT with other
sentence encoding methods, including sentence-level BERT and USE [Cer+18],
that process each sentence independently.
6.4. M-SENSE: Modeling Narrative Structure 137
Incorporating Protagonist’s Mental Representation
Prior studies have explored how a story’s progression is as much a reflection
of a sequence of a protagonist’s motivation and emotional states as it is the
workings of an abstract grammar [Pal02; Moh13; AS05]. Thus, it is reason-
able to assess the role of cognitive tension that the characters grapple with
beyond linguistic patterns and compute the change in the protagonist’s psy-
chological states for automatically determining the structural components of
the narrative.
Following a recent work [VR21b; Ras+18c] that implements a NEMO3
model, a variant of a Transformer-based encoder-decoder architecture, to
embed and explain characters’ (or entities) mental states. We extract the em-
beddings of intents and emotional reactions of the protagonist for a given
sentence in the narrative conditioning on the prior story context. Figure
6.2 contains the overview of NEMO architecture also. The computation of
mental state embeddings are facilitated by a knowledge enrichment mod-
ule that consolidates commonsense knowledge about social interactions and
an external memory module that tracks entities’ mental states. The social
commonsense knowledge is aggregated using information retrieval and ex-
traction techniques. Using prior context (S<i), entity (ej) and mental state
attribute information (m ∈ {xIntent, xReact} representing intent and emo-
tional reaction respectively), we use the encoder, STORYENTENC(·), in this
trained model to obtain entity-aware mental state representation of the cur-
rent sentence Si. The encoding process in the NEMO model is given by:
(Ĥi
xIntent, H̃i
xReact) = STORYENTENC(Si, S<i, ej, m);
∀m ∈ {xIntent, xReact} (6.3)
3Narrative Entity Mental Model
138 Chapter 6. Modeling Narrative Structure in Short Personal Narratives
where ej ∈ E is the entity, (Ĥi
xIntent, H̃i
xReact) is the resulting entity-aware in-
tent and emotion representation of the ith-sentence given the story context.
In this work, we use the narrator (“I” or “self” in the personal narratives) as
the protagonist. We only utilize the hidden representations of the [CLS] to-
ken from both (Ĥi
xIntent, H̃i
xReact) for subsequent processing steps. We denote
these intent and emotion representation as:
Hxintent
sents = [ĥ1
, .., ĥL
] (6.4)
HxReact
sents = [h̃1
, .., h̃L
] (6.5)
6.4.2 Transformer-based Fusion Layer
Given sentence representations computed using multiple methods, we apply
a fusion strategy that weighs the relevance of each latent vector and derives a
unified sentence embedding for our classification task. Let hik; ∀k ∈ {1, ..., K}
denote different per-sentence latent vectors. In our case, K = 3 and hi1 =
hi; hi2 = ĥi; hi3 = h̃i are embeddings related to semantics (xSem), intents
(xIntent) and emotional reactions (xReact) of the ith sentence respectively.
Drawing ideas from the literature of multimodal analysis [UMS+20], we
treat the multiple latent vectors as a sequence of features by first concatenat-
ing them together. We introduce a special token [FUSE] 4 that accumulates
the latent features from different sentence encodings. The final hidden repre-
sentation of [FUSE] token obtained after feeding them to a Transformer layer
is the fused output sentence representation.
hi
f use = TF(.K
k=0 hik
) (6.6)
where TF refers to the transformer encoder layer and hi0 (i.e. when k = 0) is
set to the trainable [FUSE] vector.
4[FUSE] is similar to the commonly used [CLS] token.
6.4. M-SENSE: Modeling Narrative Structure 139
6.4.3 Story Encoder
Understanding key elements of the narrative structure requires aggregation
of different narrative-level features such as important events and characters
in the story, their relationships, the impact they have on characters’ mental
states, and their transitions, to name a few. Since we use pretrained mod-
els for embedding the sentences in the narrative, we introduce story encod-
ing layers dedicated to capture these narrative-level features by combining
relevance-weighted inter-sentence features bidirectionally. Given the sen-
tence embeddings obtained from the sentence encoder, Hsents = [h1, h2, ..., hL],
we compute contextualized sentence embedding ci; ∀i ∈ {1, 2, .., L} by con-
ditioning on the surrounding context sentences in the narrative. These con-
textualized embeddings will be eventually used for predicting the sentence
labels (Climax, Resolution, or None).
We apply Transformer layers on the top of the sentence representations to
extract narrative-level features focusing on the task of detecting elements of
high-level narrative structure. We refer it as Inter-sentence Transformer. Intu-
itively, Transformer layer involves the multi-head attention mechanism that:
(a) focuses on possibly different sentences in the narrative, and (b) produces
context-aware sentence embedding by combining the features across these
sentences to decide if the corresponding label should be assigned to the sen-
tence under consideration. This is given as:
Ĥl = LayerNorm(Ĉl−1 + MHA(Ĉl−1)
Ĉl = LayerNorm(Ĥl + FFL(Ĥl))
Csents = [c1, c2, ..., cL] = ĈnL
(6.7)
where Ĉ0 = PE(Hsents), PE refers to the positional encoding applied to inject
order information to the sentence vectors, Hsents contains the sequence of
sentence vectors output by our sentence encoder module, LayerNorm refers
140 Chapter 6. Modeling Narrative Structure in Short Personal Narratives
to layer normalization operation, MHA is the multi-head attention operation
and FFL is a feed-forward layer [Vas+17]. The superscript l indicates the
depth of the stacked Transformer layers. The output from the topmost layer,
l = nL, is our contextualized sentence embeddings Csents. In section 6.7.2, we
compare the relative advantage of using a Transformer-based story encoder
over an RNN-based encoding method.
6.4.4 Interaction layer
Inspired by traditional segmentation approaches [Hea97], prior works have
utilized interaction layer to determine topic boundaries or thematic units
in movie synopsis [PKL19], question-answering, and document matching
tasks, to list a few. Consistent with these studies, we reckon that the local
interaction information with the surrounding narrative context can be useful
to determine the boundaries of various elements of the narrative structure.
In this layer, we compute the transition of state across sentences by measur-
ing similarity in the embedding space between sequential context windows.
By choosing windows of size s, we compute the left (ci
le f t) and right (ci
right)
context information for the ith sentence by computing the mean sentence em-
bedding within that window. Features representing different similarity mea-
sures such as element-wise product, cosine similarity, and pairwise distance
are computed for both left and right mean context representation. The simi-
larity metrics are concatenated along with contextualized embeddings (sen-
tence, left & right context) to get interaction-feature enhanced context-aware
embeddings:
Esents = [e1
, e2
, ..., eL
] (6.8)
6.5. Zero-shot Approaches 141
6.4.5 Classification layer
We employ linear layers, fs, on the top of interaction layer outputs and maps
the enriched sentence embedding to a C-dimensional output. Here, C = 3 is
the number of classification labels. We apply a softmax activation to get the
probability distribution over the sentence labels/categories associated with
narrative structure. This step is given as:
ŷi = so f tmax(fs(ei
)) (6.9)
where fs involves linear layers that map the enriched sentence embed-
ding to a k-dimensional output in addition to straightforward methods like
element-wise multiplication, element-wise summation, and concatenation
with a linear layer for our task.
6.5 Zero-shot Approaches
In addition to our M-SENSE model and its variants, we experiment with
zero-shot methods that utilize either simple heuristics or suspense-based ap-
proaches to model narrative structure.
Heuristic-based Approaches
In addition to different modeling approaches, we experiment with simple
heuristics for automatically labeling the sentences in the story. This method
assumes that the title of the Reddit post provides the summary of the post
and hence, could refer to the MRE/climax of the narrative. We use a pre-
trained sentence embedding model and compute the semantic similarity be-
tween each sentence in the narrative and the original title of the Reddit post.
We calculate USE embeddings of sentences to identify the nearest neighbor
of the post title and label it as the climax. Next, we assign the last sentence
142 Chapter 6. Modeling Narrative Structure in Short Personal Narratives
as the resolution because it is more like for the cognitive tension to drop and
reach a resolution at the near end of the narrative.
Suspense-based Approaches
A recent work [WK20] has explored surprise and uncertainty reduction as a
measure of suspense in narratives by considering sentences as the primary
unit of processing. In our work, we mainly focus on surprise values based
on consequential state change in narratives. Intuitively, a large difference in
any particular state indicates increased surprise at that point in the narrative.
[EFK15]’s surprise is defined as the amount of change from the previous sen-
tence to the current sentence in the narrative. Peaks in such measures could
reflect potential events where the protagonist faces principal obstacles, and
these may act as the defining moments of narrative structure. Thus, we ex-
amine different sentence embedding techniques to compute state changes,
including change in the protagonist’s mental state representations in our ex-
periments to recognize suspenseful states. This will act as a relevant baseline
to determine the effectiveness of semantic and mental state features.
6.6 Training & Hyperparameters
We approach the narrative structure model as a sentence classification task.
We divide the collected data based on the number of narratives into the train,
validation, and test sets at 70-10-20 split. In our sentence labeling task, each
sentence will be accompanied by the entire narrative context. On the train-
ing set, we perform data augmentation by replacing sentences in narrative
context with their paraphrases. The paraphrases are generated using a back-
translation approach [Edu+18] based on pretrained English↔German trans-
lation model. We limit the number of such modified sentences to 20% of
the story length. We tune the hyperparameters using grid search, and the
6.7. Experiments 143
best configuration is obtained based on validation set performance. Our best
configuration consists of a two-layer story encoder (nL = 2) and a single
transformer-based fusion layer with 12 heads. We also added a dropout with
a rate of 0.2 to prevent overfitting. We optimize using Adam [KB14] at a
learning rate of α = 0.0001 and a batch size of 32 with PyTorch [Pas+19]
being our model implementation framework.
6.7 Experiments
We conduct experiments to study the following research questions:
RQ1: How does our model compare with other baselines for identifying
climax and resolution in short personal narratives?
RQ2: How do various model components contribute to the overall per-
formance? To what extent do mental state representations play a role in our
classification task?
6.7.1 Overall Predictive Performance (RQ1)
Baselines
We conduct experiments that evaluate our model compared to different prior
approaches [PKL19; WK20]. We compare our model with a set of carefully
selected zero-shot (Section 6.5) & supervised baselines, shown as follows.
• Random baseline, which assigns labels (Climax, Resolution or None)
to sentences randomly.
• Distribution baseline, which picks sentences that lie on the peaks of
the empirical distributions for climax and resolution in our training set
as explained in Section 3.2.2.
144 Chapter 6. Modeling Narrative Structure in Short Personal Narratives
• Heuristic baseline, which labels the sentences as climax or resolution
based on heuristics as in section 6.5. While we use the sentence that
is the closest semantic neighbor of the post title as the climax, the last
sentence in the narrative is labeled as the resolution.
• GloVeSim [PSM14], which measures the cosine similarity between the
mean GloVe word embeddings of two sentences. This estimates the
change features and acts as an alternative to Ely’s surprise measures.
• STORYENC [PKL19], which uses the hierarchical RNN based language
model to encode sentences in the story and eventually compute sus-
pense measures for our classification task.
• BERT [Dev+18], which embeds the narrative sentences as in section
6.4.1 and then suspense-based approach is used.
• USE [Cer+18], which encodes sentences and utilizes the resultant em-
beddings to compute suspense measures for our task at hand.
• STORYENTENC [VR21b], which encodes the sentences in the story from
the protagonist’s perspective. Here, we denote intent and emotional
reaction embeddings as (Eint = HxIntent
sents ) and (Eemo = HxReact
sents ) respec-
tively. We utilize these embeddings for measuring suspense and apply-
ing them for our classification task.
• CAM [PKL19], which consists of bidirectional LSTM model stacked on
the top of the sentence embeddings to obtain contextualized represen-
tations. CAM is the abbreviation for context-aware model.
• TAM [PKL19], which uses a RNN-based contextualized sentence en-
coder enriched with interaction layer to compute boundaries between
different topics or thematic units in stories. This model is referred to as
the topic-aware model (TAM).
6.7. Experiments 145
Models F1 ↑ D ↓
C R C R
Random baseline 0.196 0.143 29.05 30.57
Distribution baseline 0.274 0.315 15.79 14.42
Heuristic baseline 0.217 0.147 23.74 26.82
GloVeSim 0.312 0.344 12.06 11.65
Token-level BERT 0.408 0.441 9.37 8.09
Sentence-level BERT 0.352 0.366 10.88 9.73
Sentence-level USE 0.379 0.391 10.42 9.58
STORYENC 0.410 0.438 8.81 7.46
Eint 0.437 0.462 8.19 6.94
Eemo 0.429 0.475 8.43 6.67
TAM 0.565 0.609 5.90 5.02
CAM 0.578 0.604 6.58 5.44
M-SENSE 0.694 0.743 4.15 3.20
TABLE 6.2: Evaluation Results of different models for detecting
climax (C) and resolution (R) in short personal narratives. We
report F1 score per class & percent mean annotation distance
(D) for these models. We use ↑, ↓ to indicate if higher or lower
values mean better performance respectively.
• M-SENSE–FUSION, which is a variant of our M-SENSE model without
mental state embeddings. This means that we remove the components
– NEMO and Fusion layer in Figure 6.2.
• M-SENSE, which is our complete model incorporating protagonist’s
mental representation as described in section 6.4.
Results
Table 6.2 outlines the results of our evaluation. We report the performance
of simple baselines, of which the distribution baseline turns out to be the
strongest. Though heuristic baseline performs poorly, we find a marginal
performance improvement compared to a random baseline. This is reflected
more in the distance measure (%) D than the F1 score. This suggests that the
Reddit post title does contain some relevant signal to better predict the climax
146 Chapter 6. Modeling Narrative Structure in Short Personal Narratives
in the narrative. At the same time, the last sentence heuristic for resolution is
only as good as a random classifier.
Applying suspense-based approaches with different sentence embedding
methods yields relative improvement over the simple baselines in terms of
both the evaluation metrics. As expected, sentence-level BERT/USE performs
poorly than its token-level counterpart. We attribute this variation in per-
formance to the lack of any story context information for computing latent
embedding, thereby affecting the assessment of state changes in the narra-
tive. However, sentence-level USE’s ability to produce better similarity es-
timates gives it a slight advantage over sentence-level BERT. Notably, sen-
tence representations obtained from models trained on stories (STORYENC,
STORYENTENC) recorded comparable to improved results over other sen-
tence embedding methods. Strikingly, computing surprise using protagonist
mental state embeddings exhibits an overall enhanced classification capabil-
ity. We find that the intent embedding (Eint) helps achieve the best zero-shot
performance for detecting climax. Competitive outcome for resolution is ob-
tained using protagonist’s emotion representation (Eemo).
We compare our complete M-SENSE model with the best performing prior
models such as CAM, TAM [PKL19] applied for similar tasks. As we can see,
supervised fine-tuning approaches easily beat the earlier results obtained us-
ing zero-shot methods. Though CAM has better F1 score for climax predic-
tion, TAM outperforms CAM in terms of D for predicting both the climax and
resolution. Finally, our M-SENSE model achieves an absolute improvement
of ∼ 20.07% and ∼ 22% for climax and resolution prediction respectively.
The factors that aid us towards actualizing this performance include – (a)
integration of protagonist’s mental state features via fusion layers, and (b)
long-term story contextualization using modeling choices like Transformer-
based story encoder.
6.7. Experiments 147
Model Variants F1 ↑
C R
M-SENSE 0.688 0.738
Sentence Encoder Variants
w/ Sentence-level BERT 0.665 0.709
w/ Sentence-level USE 0.677 0.726
Story Encoder Variant
w/o Story Encoder 0.620 0.653
w/ Inter-Sentence RNN 0.659 0.705
Interaction Layer Variant
w/o Interaction Layer 0.654 0.716
Fusion Layer Variants
–w/o Fusion Layer 0.614 0.640
–w/o Eint 0.638 0.703
–w/o Eemo 0.652 0.687
TABLE 6.3: Ablation Results: We report F1 score per class
(Climax and Resolution) with non-default modeling choices for
individual components of our M-SENSE model.
6.7.2 Ablation Study (RQ2)
To evaluate each component’s contributions in our M-SENSE model, we con-
duct an ablation study using the validation set. For this study, we compare
our best performing M-SENSE model with alternative modeling choices for
each of the components. Table 6.3 shows the results of our study. We modify
one component at a time and report their corresponding performance using
F1 metric. This involves either replacing a component (denoted by “w/”)
or removing a component (denoted by “w/o” to refer without the compo-
nent). For eg. “w/ Sentence-level BERT” refers to replacing token-level BERT
in default M-SENSE model with sentence-level BERT as our sentence encoder;
“w/o Eemo” indicates the removal of protagonist’s emotion state embedding
from the fusion layer.
Choice of Sentence Encoder: From the results, it is clear that token-level
BERT generally performs better the sentence-level BERT variant. This is un-
surprising as the sentence-level approach produces embeddings without story
148 Chapter 6. Modeling Narrative Structure in Short Personal Narratives
context. Such an approach results in the loss of fine-grained inter-sentence
token dependencies that the token-level BERT can extract. Experiments also
suggest that sentence-level USE model trained on textual similarity tasks re-
sults in better F1 scores than the BERT counterpart.
Importance of Contextualization: Next, we evaluate the contribution of a
story encoder to our classification task. We observe that the performance
drops significantly (by ∼ 10% and ∼ 12% for the climax and resolution
prediction, respectively) without a story encoder. The importance of con-
textualizing the story sentences is established as we see a marked improve-
ment of ∼ 8% in the average overall performance with the introduction of
an inter-sentence RNN story encoding layer. Still, this performance lags be-
hind our default M-SENSE setting with the Transformer-based story encoding
layer. We find the story encoder relevant even if the inter-sentence depen-
dencies are captured using the token-level BERT model. We attribute this to
the task-specific inter-sentence relationships being unearthed as we fine-tune
our model.
Impact of Interaction Layer: The addition of an interaction layer yields an
average ∼ 4% gain in performance for identifying climax and resolution.
The advantage of introducing an interaction layer has been studied in prior
studies [Hea97; PKL19] and we find the performance improvement to be con-
gruous with these studies.
Influence of Mental State Embeddings: The purpose of a fusion layer is to in-
corporate sentence level embeddings capturing the protagonist’s intent and
emotional reactions. In this study, we examine the necessity of a fusion layer
and probe the influence of the protagonist’s mental state embeddings on our
classification task. Notably, the results in Table 6.3 validate the benefits of
introducing the fusion layer and demonstrate the relative performance gains
obtained with intent and emotion embeddings. In the absence of a fusion
6.7. Experiments 149
layer, we observe that the performance drop is ∼ 11% and ∼ 13% for predict-
ing climax and resolution, respectively. The loss of the protagonist’s intent
information impacts the climax prediction more. This is analogous to the ef-
fect emotion information has on resolution prediction. In Section 6.7.3, we
delve deeper to analyze their relative importance.
6.7.3 Analysis and Discussion
Effect of Story Length: We conduct experiments to analyze how different sen-
tence encoders and mental representation fusion impact the overall perfor-
mance. For this analysis, we compare different sentence encoders’ perfor-
mance with and without fusion layer for detecting climax in narratives with
a varying number of sentences (Story length). Figure 6.3 shows the results
of this analysis. We observe that the token-level BERT outperforms sentence-
level BERT and USE encoders for narratives containing up to 13 − 14 sen-
tences, but the performance gradually degrades beyond 14 sentences. Sentence-
level USE encoder produces a stable and relatively better outcomes for longer
narratives (story length > 14). With the introduction of mental state repre-
sentation through the fusion layer, the F1 score improved significantly irre-
spective of the sentence encoder used. However, we find that the token-level
BERT and USE enriched with mental state embeddings yielded a comparable
performance, with the former having a slight edge over the latter. Also, the
performance degradation of token-level BERT is mitigated as the fusion layer
is added, and this is reflected in the F1 score even for longer narratives. Thus,
this analysis revalidates the use of our modeling choices in our M-SENSE
model.
Error Analysis: In order to estimate why our model augmented with men-
tal state representation performs better, we conduct error analysis between
150 Chapter 6. Modeling Narrative Structure in Short Personal Narratives
FIGURE 6.3: Performance of sentence encoders for detecting
climax in story with varying length.
our full M-SENSE model and the model without mental representation fu-
sion (M-SENSE − Fusion). For those narratives where the latter model fails to
predict correctly, we gauge the patterns emerging out of the following analy-
sis: (a) Using VADER5 [HG14] a normalized, weighted composite sentiment
score is computed for each sentence in the narrative. Use typical threshold
values used in the literature, we categorize these sentences as positive, neu-
tral, or negative, and eliminate stories containing neutral sentences in the
neighborhood of ground truth sentences, and (b) Using state classification
[Ras+18c; VR21b], we assess Maslow’s motivation or intent categories asso-
ciated with sentences predicted as climax or resolution in the narrative and
analyze for any pattern related to ground truth climax/resolution sentences.
For predicting resolution, the M-SENSE − Fusion makes 28% more mistakes
than M-SENSE model for narratives with homogeneous endings (i.e., narra-
tives having the same sentiment sentences in the neighborhood of resolution
5https://github.com/cjhutto/vaderSentiment
6.8. Task: Modeling Movie Turning Points 151
closer to the end of the story). M-SENSE − Fusion model is unable to dis-
cern clearly and predicts a different sentence as resolution. Based on our
analysis (b), there is a clear pattern that M-SENSE gains significantly over the
M-SENSE − Fusion when the ground-truth climax sentences belong to “Es-
teem” and “Love/Belonging” categories.
Attention Analysis: We conduct attention analysis on those narratives con-
taining sentences belonging to “Esteem” and “Love/ Belonging” categories.
Specifically, we study the functioning of the Transformer-based Fusion layer
for aggregating multiple latent embeddings – Semantic (Sem), Intent (Int),
and Emotion (Emo). We then visualize the attention heatmaps from the fu-
sion layer corresponding to these predicted climax and resolution sentences
by computing the average attention score map over all heads. Figure 6.4
displays the visualized attention map for sample stories belonging to the
above-mentioned categories. Since [FUSE] is the aggregated output over
all the three latent embeddings. We note that the attention map has high
attention scores between intent (Int) and [FUSE] vectors for stories related
to “Esteem” motivation category, while more weight is assigned for emotion
(Emo) in samples associated with “Love/Belonging” category.
6.8 Task: Modeling Movie Turning Points
Given that our work is primarily focused on modeling narrative structure
in personal narratives, we analyze how we can apply such a model towards
identifying climax and resolution in movie plot synopsis. Recent work by
[PKL19] introduced a TRIPOD dataset containing a corpus of movie synopses
annotated with turning points (TPs). By testing our model on this dataset, we
evaluate our model’s performance on an out-of-domain dataset. The dataset
identified five major turning points in the movie synopses and screenplay,
referring to them as critical events that prevent the narrative from drifting
152 Chapter 6. Modeling Narrative Structure in Short Personal Narratives
I ve been a lonely person all through my life due to my
dysfunctional family. Though I ve a brother who lives close to
my place, I ve always assumed we are totally different people.
We don t connect very well at all. My life was a mess and
always craved for some emotional and moral support more
than financial. I fe dejec ed a d h i i g. S I
a e ed icide i g ee i g i . But now I look
back at it and I think suicide attempt did change life for the
better. M b he a ed e ha da a d he i be
f ie d ha I e hi bi . We ea i ed
i a e . And how both of us were going through similar
issues and being together was the best thing we could do to
each other. I just wish I had bonded with him earlier.
I’m a manager in the retail store I work in, but it’s more of an
assistant manager position. I’ve been working at the same place
for about a year. I actually left my job for 3 months to try a
different job and make some more money. That job was terrible,
and my current job welcomed me back with open arms. There
are 3 main managers. I’ve always looked up to them. Si ce e
f he ma age a m i g i a fe m h he e a
a e i g a d I g c m le el m i a ed b he le I e
bee ai i g ha d f he le a d achie e m l g e m
a ge My friends never believed in my capabilities. I wanted to
break my friends’ notion about my abilities. A d da I e hi
he b ll e e a d e ci ed ha I ill ake e a he
ma age f he e le I’m not sure how my friends will
feel but I’m not going to brag about it. I just bought a new house,
I’m happy it will make things a lot easier. I’m really excited for
the new job.
FIGURE 6.4: Attention analysis of two stories with climax and
resolution sentences related to Maslow’s categories – Esteem
(top) and Love/Belonging (bottom).
away. These five TPs are: Opportunity (TP1), Change of Plans (TP2), Point of
No Return (TP3), Major Setback (TP4), and Climax (TP5). By their definitions
for each of these categories [PKL19], TP4 and TP5 align clearly with our usage
of climax and resolution from prior narrative theories. Due to this alignment,
it is relevant to use our model to predict these two categories in the TRIPOD
dataset. However, we focus on the movie plot synopses in this work and use
the cast information collected from IMDb as a part of this dataset.
We first apply our MSENSE trained on our STORIES corpus directly and
evaluate its zero-shot performance. We refer to this as a zero-shot approach
given by (ZS) We assume the protagonist in the movie to be the top character
from the IMDb cast information. Though this may not always be true, it mea-
sures how our model fares on this dataset for predicting TP4 and TP5. Fur-
ther, we use sentence-level USE-based sentence encoder as some of the wiki
6.8. Task: Modeling Movie Turning Points 153
plot synopses are longer than what can be accommodated by our token-level
BERT model. Additionally, we also fine-tune our model with the training set
of the TRIPOD dataset. This is denoted by MSENSE(FT).
6.8.1 Results
We display our model’s performance compared to the best performing TAM
reported in the original work [PKL19]. The topic aware model TAM with TP
views implemented separate encoders for each of the categories and com-
puted different representations for the same sentences acting as different
views related t each TP. Similarly, TAM+Entities enriched the model with en-
tity information by applying co-reference resolution and obtain entity-specific
representations. We compare these models without MSENSE model in zero-
shot and supervised settings. Table 6.4 shows our model’s results compared
to the prior proposed approaches for modeling turning points in plot syn-
opses. We find that our model in zero-shot settings outperforms a super-
vised TAM+TP views model, though it falls slightly behind the best super-
vised model in terms of the mean annotation distance (%). We intuit the
advantage of training on short personal narratives to be providing us the
edge on this model. It could be a bigger challenge if we have to identify
other turning points in the story. Also, we restrict our model for predicting
only two of the five major turning point labels. Finally, our fine-tuned model
outperforms the best performing model, significantly reducing the mean an-
notation by an average of ∼ 20% on both the turning point labels. Thus, we
are able to achieve remarkable improvement on an out-of-domain dataset
even with assumptions on protagonist information. Therefore, we demon-
strate that our MSENSE model can predict climax and resolution in stories
beyond just personal narratives, albeit limited by story length at this point.
We believe that there is tremendous scope for drawing insights by analyzing
154 Chapter 6. Modeling Narrative Structure in Short Personal Narratives
Methods TP4 TP5
TAM+TP views 6.91 4.26
TAM+Entities 5.23 3.48
MSENSE(ZS) 6.62 4.54
MSENSE(FT) 4.17 2.38
TABLE 6.4: Results of evaluation on TRIPOD dataset. We re-
port Mean Annotation Distance (%) D results for identifying
TP4 and TP5 relevant to this work.
narratives across varied genres and performing interpretability assessments
on the characters’ mental states. However, we leave such an intricate piece
of comparative analyses as future work.
6.9 Conclusion
Modeling high-level narrative structure through our modeling framework
can facilitate future research towards nuanced discourse analysis and for-
mal representation necessary for narrative retrieval, automated reasoning, or
narrative generation. Towards this goal, we construct a dataset of personal
narratives from Reddit containing annotations of climax and resolution sen-
tences. Using our annotation setup, we are able to achieve a substantial inter-
annotator agreement for both categories indicating the rise and fall of dra-
matic tension. Next, we address the challenge of automatically identifying
these elements of narrative structure as a sentence labeling task. Understand-
ing and quantifying the role of shifts in protagonists’ psychological states and
their interplay with semantic features are central to our research. Therefore,
we introduce an end-to-end deep neural model, referred to as M-SENSE, that
learns to effectively integrate the protagonist’s psychological state features
with linguistic information towards improved modeling of narrative struc-
ture. We experimentally confirm that our model outperforms several zero-
shot and supervised baselines and benefits significantly from incorporating
6.9. Conclusion 155
the protagonist’s mental state representations. Our model is able to achieve
∼ 20% higher success in detecting climax and resolution in short personal
narratives than the previous methods. We believe that our work will advance
the research in understanding the larger dynamics of narrative communica-
tion and aid future efforts towards developing interesting AI tools that can
interact with human users through stories.
157
Chapter 7
Conclusion and Future Work
Stories have long been theorized to influence the human understanding of
the social world and promote social cognitive capabilities. Recently, there has
been a growing interest to conduct empirical research exploring the interplay
between narratives and mentalizing using a wide range of approaches. This
dissertation aims to investigate computational methods to leverage this in-
terdependence towards a grand challenge of endowing human-level social
skills to machines. By exploiting personal narratives produced by ordinary
people on social media, which act as a great source of commonsense knowl-
edge about social situations, we develop techniques that examine this mu-
tual influence by (a) learning aspects of mentalizing (motives and emotions)
through pragmatics-enriched social event embeddings and dynamic entity
state tracking modules; and (b) demonstrating improved narrative compre-
hension through models that effectively predict prominent elements of narra-
tive structure – climax and resolution using the mental state representations.
In the following sections, we delineate the key highlights of our contribu-
tions, along with the limitations of our work. Further, we lay down directions
for future work that could potentially address those limitations and assess
research areas where the models proposed in our work can offer a nudge
towards enhanced performance.
158 Chapter 7. Conclusion and Future Work
7.1 Contributions
The key contributions of the work include identification of key functional
modules that focus on leverage the relationship between mentalizing and
narrative comprehension to capture specific aspects of aspects of social com-
petence. Since we divide our work into three primary modular components,
we explain the contributions of each of these components and how they even-
tually add up to our overarching goal.
7.1.1 Learning Knowledge-Enriched Social Event Represen-
tation
Events are considered the focal points of situations conveyed in narratives
and connected in memory along various dimensions like time, space, char-
acters (or protagonist), causality, and intentionality. Specifically, the events
related to social situations demand an understanding beyond mere linguis-
tic structures. Therefore, we make efforts to incorporate pragmatic proper-
ties referring to the knowledge outside the explicitly stated content in the
event text. This knowledge is related to the human’s inferred implicit under-
standing of event actors’ intents, beliefs, and feelings or reactions. For this
purpose, we aggregated sentence-level implicit intent and emotion states us-
ing web-search-based data mining techniques. We identified the potential
issues with prior knowledge sources that replaced social role information
with ‘Person’ markers leading to a loss of information. Therefore, we alle-
viate this issue with our aggregated social commonsense knowledge asser-
tions (SB-SCK) that contain social role information in addition to the ap-
parent intent and emotional reaction expressions related to the event text.
Though the dataset is noisy, it provided ample opportunity to improve the
learning of our social event embeddings. Using multiple knowledge sources
like CONCEPTNET, ATOMIC and our very own SB-SCK, we sharpened the
7.1. Contributions 159
social event embeddings to move beyond mere linguistic structures and em-
bed information at syntactic, semantic, and pragmatic levels through the ad-
ditional knowledge we feed into the model. We implemented a fine-tuned
BERT-based model to disentangle pragmatic and non-pragmatic properties
and eventually encapsulate them into a unified social event representation.
By evaluating our work on a held-out test corpus of social events, we estab-
lished the advantages of using such a model over several other baselines.
Further, our experimental results showed improved performance on several
downstream tasks like event similarity (Accuracy: 71.23%), reasoning (Ac-
curacy: 67.9%), and paraphrase detection (Accuracy: 90.16%) tasks. These
outcomes provided the necessary empirical evidence for their applicability
in subsequent modeling challenges involving narratives and mentalizing in
this work.
7.1.2 Modeling Human Motives and Emotions from Personal
Narratives
Towards the goal of nurturing aspects of mentalizing abilities, we addressed
a subset of challenges related to the lack of annotated data that allows for
convincingly embedding and explaining characters’ mental states. Further,
we also investigated methods that can dynamically track mental states of
characters throughout the story. We constructed a weakly annotated corpus
of personal stories from Reddit using data mining and information extrac-
tion strategies to obtain expressions of motivation and emotional reactions.
We implemented a NEMO model, which is a variant of Transformer-based
architecture augmented with additional memory modules that can capture
sentence-level event pragmatics from our EVENTBERT and enable dynamic
entities’ mental state tracking.
160 Chapter 7. Conclusion and Future Work
We demonstrated our proposed method’s superior performance over sev-
eral baselines in mental state classification and generation tasks. Our com-
plete model achieved an absolute mean improvement of ∼ 8% and ∼ 11%
over a fine-tuned GPT-2 model using the embedding average metric of the
generated intent and emotion explanations respectively across two differ-
ent story datasets. With the help of pretraining, we observed that the low-
resource domains could benefit from the pretrianing of our model and trans-
fer the knowledge to stories in other disciplines. Even in mental state clas-
sification tasks, our model exhibited significant leads over prior approaches
with an F1 score of ∼ 0.72 and ∼ 0.71 for Maslow and Plutchik categories,
respectively. In order to evaluate the learned mental state embeddings, we
apply these embeddings on a downstream empathetic response generation
task model. Our mental state-enriched ensemble model with a relatively
lower number of parameters resulted in significant improvement in auto-
mated metrics in the response generation task. Thus, we successfully show
how narratives can be tapped in to construct models that showcase mental-
izing capability, albeit in a limited capacity of predicting motives and emo-
tional reactions only.
7.1.3 Modeling Narrative Structure in Short Personal Narra-
tives
Given the substantial outcomes obtained using our mental state representa-
tion and generation framework, we determine the applicability of these men-
tal representations for modeling high-level narrative structure in narratives.
This requires the processing of the entire narrative to identify the boundaries
of these structural components of the narrative. Through this work, we are
able to identify the climax and resolution in the stories though there is ample
scope for improvement. The vital contributions of this work lie both in the
7.1. Contributions 161
data and modeling aspects of the work. We created a resource for future re-
searchers containing reliable annotations of climax and resolution sentences
in personal narratives obtained from Reddit from the data perspective. Us-
ing our annotation setup, we accomplished substantial inter-annotator agree-
ment with Cohen’s κ = 0.651 and κ = 0.769 for climax and resolution, respec-
tively. The agreement/reliability scores indicate that our annotation setup
allows for a clear separation of major structural elements of the narrative,
capturing the dramatic rise and fall of the characters’ tension in the story.
Regarding the modeling aspect of our work, we tackle the challenges in-
volved by incorporating the protagonists’ psychological states and situating
them in the bidirectional story context. Using our M-SENSE model, the pro-
tagonist’s psychological state features are integrated with linguistic informa-
tion relying on embeddings obtained from pretrained language models. By
tracking the shifts in these mental states and applying multi-feature fusion
with linguistic features, we are able to achieve a per-class F1 score of 0.694
and 0.743 for climax and resolution, respectively in the sentence labeling
task. Since quantifying the role of shifts in protagonists’ psychological states
is critical to our research, we conducted an ablation study that validates the
benefits of introducing the fusion layer. The removal of the fusion layer led
to a performance drop of ∼ 11% and ∼ 13% for predicting climax and reso-
lution, respectively. The loss of the protagonist’s intent information impacts
the climax prediction more, while the effect of emotion is reflected on reso-
lution prediction. Compared to prior state-of-the-art methods, the average
performance jumped by ∼ 20% higher success in modeling these elements of
narrative structure in personal stories.
162 Chapter 7. Conclusion and Future Work
7.2 Limitations & Future Work
This section discusses the limitations of our current work and potential fu-
ture work that can promote dedicated efforts taking forward the ideas pre-
sented in this dissertation. Below we enlist the limitations and future work
related to each part of our work.
• Learning Knowledge-Enriched Social Event Representation:
– Several recent works [Liu+20; Shw+20] have shown the impor-
tance of high-quality symbolic knowledge to generalize on com-
monsense information. However, we aggregate noisy common-
sense knowledge data in our work. Though our models perform
well in the current settings, finding ways to address the noise can
help learn richer embeddings, thereby improving their utility in
other tasks. Exploring better ways of mining web data and identi-
fying cleaner resources can help handle this issue. The other way
is to draw ideas from several recent studies on denoising [Lew+19;
SJ19; Zho+19; SL21] and build robust models that can be resilient
to a certain level of noise in data.
– The social commonsense knowledge extracted using our method
contains search results from random websites and could poten-
tially have biases that humans propagate. Further, this data may
not reflect socio-cultural dependencies associated with events. The
motives and emotions related to specific actions and events could
vary across cultures, geographical locations, and societies. In or-
der to factor in those facets, we need to investigate methods [ATF20;
For+20] to integrate such knowledge and weigh them from the
perspective of inclusivity and applicability to data from those do-
mains.
7.2. Limitations & Future Work 163
– Though our current model works well on several downstream
tasks, it is worth evaluating our model in a different domain like
news stories to assess the adaptability and how much they apply
to such domains comprising of rapidly changing interpretations of
words depending on the values and ideologies of the event partic-
ipants.
• Modeling Human Motives and Emotions from Personal Narratives:
– As a part of tackling the challenges related to developing mental-
izing models, we focus on the characters’ motives and emotions
in this work. However, several other dimensions are left unex-
plored, such as beliefs, thoughts, desires, goals, etc. []. This re-
quires knowledge acquisition relevant to those dimensions and
assessing the interplay between them for constructing better men-
tal models of people.
– Our work is based on many models primarily suited for short per-
sonal narratives. It might be a challenge to apply our models to
long-format texts directly. Therefore, immediate future work is to
explore ways to extend our model or transfer the knowledge from
our model to longer text narratives.
– The disadvantage of not accommodating knowledge related to
socio-cultural norms is applicable for this work involving narra-
tives because the underlying meaning of the story and how peo-
ple react to them might be entirely dependent on the cultural con-
text. As a critical limitation and the necessity to overcome this
shortcoming, we highlight a growing concern towards building
fair and inclusive machine learning applications.
• Modeling Narrative Structure in Short Personal Narratives:
164 Chapter 7. Conclusion and Future Work
– In this work, we primarily focus on two prominent elements of
the narrative structure – climax and resolution. However, there is
a scope to extend our work to identify fine-grained categories of
narrative structure. There could be other types of stories that may
not have a central conflict but have some inherent structure. Our
work currently pays less attention to such types and the implicit
structure present in them.
– Exploring the protagonist’s psychological state is one of the sev-
eral dimensions employed for modeling narrative structures. It
will be interesting to delve deeper into modeling the relationships
between the characters in the mental state space and identifying
the causal patterns that lead to specific structures in narratives.
– Applicability to fictional narratives has not been investigated thor-
oughly in this work. Though it is beyond the scope of this work,
we see it as a reasonable next step to understand how our mental
state-enriched narrative structure models can detect structure in
fictional narratives.
Besides these shortcomings, the data and modeling resources produced
through this research have tremendous potential to be utilized in a wide va-
riety of applications. These resources can be directly beneficial to many tasks
such as narrative comprehension, retrieval, and generation [], empathetic di-
alogue generation, pattern analysis about human behavior in real-life phe-
nomena like elections, cyberbullying, online hate speech, fake news, or pro-
paganda analysis, to list a few.
7.3. Closing Remarks 165
7.3 Closing Remarks
In summary, our work sheds light on how we could leverage the mutual
influence of narratives and mentalizing towards furthering the research in
developing socially-aware AI systems. We have highlighted the strengths
of our proposed computational methods and provided empirical evidence
of their utility. Though we demonstrate improved performance on several
tasks related to reasoning about mental states and narrative comprehension,
we also expose the weaknesses of our research and identify several areas of
improvement in each of the problems we solve. It is essential to expand on
the ideas and resources produced through our research and recognize future
investigations amenable to achieve the grand challenge of endowing social
intelligence to machines. We hope that our work motivates a nuanced step
in that direction and offers critical resources as well as useful insights for
researchers embarking on the quest to build human-centric AI systems.
167
Bibliography
Abbott, H Porter (2020). The Cambridge introduction to narrative. Cambridge
University Press.
Abrams, Meyer Howard and Geoffrey Harpham (2014). A glossary of literary
terms. Nelson Education.
Acharya, Anurag, Kartik Talamadupula, and Mark A Finlayson (2020). “An
atlas of cultural commonsense for machine reasoning”. In: arXiv preprint
arXiv:2009.05664.
Adams, Catherine et al. (2005). “Pragmatic language impairment: case stud-
ies of social and pragmatic language therapy”. In: Child Language Teaching
and Therapy 21.3, pp. 227–250.
Alexander, Franz, Bernard Trans Glueck, and Bertram D Lewin (1935). “The
psychoanalysis of the total personality: The application of Freud’s theory
of the ego to the neuroses.” In:
Alm, Cecilia Ovesdotter and Richard Sproat (2005). “Emotional sequencing
and development in fairy tales”. In: International Conference on Affective
Computing and Intelligent Interaction. Springer, pp. 668–674.
Anderson, Anne, Simon C Garrod, and Anthony J Sanford (1983). “The acces-
sibility of pronominal antecedents as a function of episode shifts in nar-
rative text”. In: Quarterly Journal of Experimental Psychology 35.3, pp. 427–
440.
168 Bibliography
Angeli, Gabor, Melvin Jose Johnson Premkumar, and Christopher D Man-
ning (2015). “Leveraging linguistic structure for open domain informa-
tion extraction”. In: Proceedings of the 53rd Annual Meeting of the Associa-
tion for Computational Linguistics and the 7th International Joint Conference
on Natural Language Processing (Volume 1: Long Papers), pp. 344–354.
Aram, Dorit and Sigalit Aviram (2009). “Mothers’ storybook reading and
kindergartners’ socioemotional and literacy development”. In: Reading
Psychology 30.2, pp. 175–194.
Astington, Janet Wilde (2004). “Sometimes necessary, never sufficient: False-
belief understanding and social competence”. In: Individual differences in
theory of mind. Psychology Press, pp. 24–49.
Astington, Janet Wilde and Janette Pelletier. “Theory of mind, language, and
learning in the early years: Developmental origins of school readiness”.
In: The development of social cognition and communication (), pp. 205–230.
Badenes, Lid’on Villanueva, Rosa Ana Clemente Estevan, and Francisco J
Garc’ıa Bacete (2000). “Theory of mind and peer rejection at school”. In:
Social Development 9.3, pp. 271–283.
Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio (2014). “Neural
machine translation by jointly learning to align and translate”. In: arXiv
preprint arXiv:1409.0473.
Baker, Chris, Rebecca Saxe, and Joshua Tenenbaum (2011). “Bayesian theory
of mind: Modeling joint belief-desire attribution”. In: Proceedings of the
annual meeting of the cognitive science society. Vol. 33. 33.
Baker, Chris L, Rebecca Saxe, and Joshua B Tenenbaum (2009). “Action un-
derstanding as inverse planning”. In: Cognition 113.3, pp. 329–349.
Baker, Chris L et al. (2017). “Rational quantitative attribution of beliefs, de-
sires and percepts in human mentalizing”. In: Nature Human Behaviour
1.4, pp. 1–10.
Bibliography 169
Baker, Collin F, Charles J Fillmore, and John B Lowe (1998). “The berkeley
framenet project”. In: 36th Annual Meeting of the Association for Computa-
tional Linguistics and 17th International Conference on Computational Linguis-
tics, Volume 1, pp. 86–90.
Baldassano, Christopher, Uri Hasson, and Kenneth A Norman (2018). “Rep-
resentation of real-world event schemas during narrative perception”. In:
Journal of Neuroscience 38.45, pp. 9689–9699.
Balota, David A and Jennifer H Coane (2008). “Semantic memory”. In:
Bamberg, Michael (2012). “Narrative analysis.” In:
Bamman, David, Brendan OConnor, and Noah A Smith (2013). “Learning
latent personas of film characters”. In: Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguistics (Volume 1: Long Papers),
pp. 352–361.
Barthes, Roland (1966). “Introduction to the structural analysis of the narra-
tive”. In:
Barthes, Roland and Lionel Duisit (1975). “An introduction to the structural
analysis of narrative”. In: New literary history 6.2, pp. 237–272.
Bauminger, Nirit (2007). “Brief report: Group social-multimodal intervention
for HFASD”. In: Journal of autism and developmental disorders 37.8, pp. 1605–
1615.
Bauminger-Zviely, Nirit (2013). Social and academic abilities in children with
high-functioning autism spectrum disorders.
Bauminger-Zviely, Nirit et al. (2013). “Increasing social engagement in chil-
dren with high-functioning autism spectrum disorder using collaborative
technologies in the school environment”. In: Autism 17.3, pp. 317–339.
Beck, Julie (2015). “Lifes stories”. In: The Atlantic 8.
Berman, Ruth A and Dan Isaac Slobin (2013). Relating events in narrative: A
crosslinguistic developmental study. Psychology Press.
170 Bibliography
Boerma, Inouk E, Suzanne E Mol, and Jelle Jolles (2017). “The role of home
literacy environment, mentalizing, expressive verbal ability, and print ex-
posure in third and fourth graders reading comprehension”. In: Scientific
Studies of Reading 21.3, pp. 179–193.
Bosselut, Antoine and Yejin Choi (2019). “Dynamic knowledge graph con-
struction for zero-shot commonsense question answering”. In: arXiv preprint
arXiv:1911.03876.
Bosselut, Antoine et al. (2017). “Simulating action dynamics with neural pro-
cess networks”. In: arXiv preprint arXiv:1711.05313.
Bosselut, Antoine et al. (2019). “COMET: Commonsense transformers for au-
tomatic knowledge graph construction”. In: arXiv preprint arXiv:1906.05317.
Boyd, Ryan L, Kate G Blackburn, and James W Pennebaker (2020). “The nar-
rative arc: Revealing core narrative structures through text analysis”. In:
Science advances 6.32, eaba2196.
Bridewell, Will and Alistair Isaac (2011). “Recognizing deception: A model
of dynamic belief attribution”. In: 2011 AAAI Fall Symposium Series.
Brown, Steven (2020). “The Who System of the Human Brain: A System for
Social Cognition About the Self and Others”. In: Frontiers in Human Neu-
roscience 14, p. 224.
Brown, Steven et al. (2019). “Character mediation of story generation via pro-
tagonist insertion”. In: Journal of Cognitive Psychology 31.3, pp. 326–342.
Bruner, Jerome (1990). Acts of meaning. Harvard university press.
— (1991a). “Self-making and world-making”. In: Journal of aesthetic education
25.1, pp. 67–78.
— (1991b). “The narrative construction of reality”. In: Critical inquiry 18.1,
pp. 1–21.
Bruner, Jerome S (2009). Actual minds, possible worlds. Harvard university press.
Bibliography 171
Carnahan, Christina R, Pamela S Williamson, and Jennifer Christman (2011).
“Linking cognition and literacy in students with autism spectrum disor-
der”. In: Teaching Exceptional Children 43.6, pp. 54–62.
Carruthers, Peter and Peter K Smith (1996). Theories of theories of mind. Cam-
bridge University Press.
Cer, Daniel et al. (2018). “Universal sentence encoder”. In: arXiv preprint arXiv:1803.11175.
Ceran, Betul et al. (2012). “A semantic triplet based story classifier”. In: 2012
IEEE/ACM International Conference on Advances in Social Networks Analysis
and Mining. IEEE, pp. 573–580.
Chafe, W. (1980). “The Pear Stories: Cognitive, Cultural and Linguistic As-
pects of Narrative Production”. In:
Chambers, Nathanael and Dan Jurafsky (2008). “Unsupervised learning of
narrative event chains”. In: Proceedings of ACL-08: HLT, pp. 789–797.
Charman, Tony and Yael Shmueli-Goetz (1998). “The relationship between
theory of mind, language and narrative discourse: an experimental study.”
In: Cahiers de Psychologie Cognitive/Current Psychology of Cognition.
Chaturvedi, Snigdha, Dan Goldwasser, and Hal Daume III (2016). “Ask, and
shall you receive? understanding desire fulfillment in natural language
text”. In: Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 30.
1.
Chen, Jiaao, Jianshu Chen, and Zhou Yu (2019). “Incorporating structured
commonsense knowledge in story completion”. In: Proceedings of the AAAI
Conference on Artificial Intelligence. Vol. 33. 01, pp. 6244–6251.
Chen, Qian et al. (2016). “Enhanced lstm for natural language inference”. In:
arXiv preprint arXiv:1609.06038.
Chu, Eric, Prashanth Vijayaraghavan, and Deb Roy (2018). “Learning Per-
sonas from Dialogue with Attentive Memory Networks”. In: arXiv preprint
arXiv:1810.08717.
172 Bibliography
Chung, Yu-An, Hung-Yi Lee, and James Glass (2017). “Supervised and un-
supervised transfer learning for question answering”. In: arXiv preprint
arXiv:1711.05345.
Cohen, Jacob (1960). “A coefficient of agreement for nominal scales”. In: Ed-
ucational and psychological measurement 20.1, pp. 37–46.
Cutting, James E (2016). “Narrative theory and the dynamics of popular movies”.
In: Psychonomic bulletin & review 23.6, pp. 1713–1743.
Dawes, Robyn M (1999). “A message from psychologists to economists: mere
predictability doesnt matter like it should (without a good story appended
to it)”. In: Journal of Economic Behavior & Organization 39.1, pp. 29–40.
De Fina, Anna (2008). “Who Tells Which Story and Why? Micro and Macros
Contexts in Narrative”. In:
De Fina, Anna and Alexandra Georgakopoulou (2011). Analyzing narrative:
Discourse and sociolinguistic perspectives. Cambridge University Press.
Devlin, Jacob et al. (2018). “Bert: Pre-training of deep bidirectional transform-
ers for language understanding”. In: arXiv preprint arXiv:1810.04805.
Ding, Xiao et al. (2014). “Using structured events to predict stock price move-
ment: An empirical investigation”. In: Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing (EMNLP), pp. 1415–1425.
— (2015). “Deep learning for event-driven stock prediction”. In: Twenty-fourth
international joint conference on artificial intelligence.
— (2016). “Knowledge-driven event embedding for stock prediction”. In:
Proceedings of coling 2016, the 26th international conference on computational
linguistics: Technical papers, pp. 2133–2142.
Ding, Xiao et al. (2019). “Event Representation Learning Enhanced with Ex-
ternal Commonsense Knowledge”. In: arXiv preprint arXiv:1909.05190.
Dirkson, Anne, Suzan Verberne, and Wessel Kraaij (2019). “Narrative Detec-
tion in Online Patient Communities.” In: Text2Story@ ECIR, pp. 21–28.
Bibliography 173
Dore, Rebecca A et al. (2018). “Theory of mind: A hidden factor in reading
comprehension?” In: Educational Psychology Review 30.3, pp. 1067–1089.
Edunov, Sergey et al. (2018). “Understanding back-translation at scale”. In:
arXiv preprint arXiv:1808.09381.
Eisenberg, Joshua and Mark Finlayson (2017). “A simpler and more gener-
alizable story detector using verb and character features”. In: Proceedings
of the 2017 Conference on Empirical Methods in Natural Language Processing,
pp. 2708–2715.
Eisenberg, Nancy (2014). Altruistic emotion, cognition, and behavior (PLE: Emo-
tion). Psychology Press.
Elson, David K (2012a). “Detecting story analogies from annotations of time,
action and agency”. In: Proceedings of the LREC 2012 Workshop on Compu-
tational Models of Narrative, Istanbul, Turkey, pp. 91–99.
— (2012b). “Modeling narrative discourse”. PhD thesis. Columbia Univer-
sity.
Ely, Jeffrey, Alexander Frankel, and Emir Kamenica (2015). “Suspense and
surprise”. In: Journal of Political Economy 123.1, pp. 215–260.
Fahlman, Scott E (2011). “Using Scone’s multiple-context mechanism to em-
ulate human-like reasoning”. In: 2011 AAAI Fall Symposium Series.
Felbo, Bjarke et al. (2017). “Using millions of emoji occurrences to learn any-
domain representations for detecting sentiment, emotion and sarcasm”.
In: arXiv preprint arXiv:1708.00524.
Feldman, Joshua, Joe Davison, and Alexander M Rush (2019). “Common-
sense knowledge mining from pretrained models”. In: arXiv preprint arXiv:1909.00505.
Fern’andez, Camila (2013). “Mindful storytellers: Emerging pragmatics and
theory of mind development”. In: First Language 33.1, pp. 20–46.
Ferstl, Evelyn C et al. (2008). “The extended language network: a meta-analysis
of neuroimaging studies on text comprehension”. In: Human brain map-
ping 29.5, pp. 581–593.
174 Bibliography
Fichman, Sveta et al. (2017). “Story grammar elements and causal relations in
the narratives of Russian-Hebrew bilingual children with SLI and typical
language development”. In: Journal of Communication Disorders 69, pp. 72–
93.
Finlayson, Mark Alan (2016). “Inferring Propp’s functions from semantically
annotated text”. In: The Journal of American Folklore 129.511, pp. 55–77.
Finlayson, Mark Alan and Patrick Henry Winston (2006). “Analogical re-
trieval via intermediate features: The Goldilocks hypothesis”. In:
Finlayson, Mark Mark Alan (2012). “Learning narrative structure from anno-
tated folktales”. PhD thesis. Massachusetts Institute of Technology.
Fishbach, Ayelet and Melissa J Ferguson (2007). “The goal construct in social
psychology.” In:
Forbes, Maxwell et al. (2020). “Social chemistry 101: Learning to reason about
social and moral norms”. In: arXiv preprint arXiv:2011.00620.
Freytag, Gustav (1894). Die technik des dramas. S. Hirzel.
Friedrich, Lynette Kohn and Aletha Huston Stein (1973). “Aggressive and
prosocial television programs and the natural behavior of preschool chil-
dren”. In: Monographs of the Society for Research in Child Development, pp. 1–
64.
Gallese, Vittorio and Hannah Wojciehowski (2011). “How stories make us
feel: Toward an embodied narratology”. In: California Italian Studies 2.1.
Gaonkar, Radhika et al. (2020). “Modeling label semantics for predicting emo-
tional reactions”. In: arXiv preprint arXiv:2006.05489.
Garc’ıa-P’erez, Rosa M, R Peter Hobson, and Anthony Lee (2008). “Narrative
role-taking in autism”. In: Journal of Autism and Developmental Disorders
38.1, pp. 156–168.
Gernsbacher, Morton Ann (2013). Language comprehension as structure building.
Psychology Press.
Bibliography 175
Ghosh, Sayan et al. (2017). “Affect-lm: A neural language model for cus-
tomizable affective text generation”. In: arXiv preprint arXiv:1704.06851.
Goodwin, Travis et al. (2012). “UTDHLT: COPACETIC system for choosing
plausible alternatives”. In: * SEM 2012: The First Joint Conference on Lexi-
cal and Computational Semantics–Volume 1: Proceedings of the main conference
and the shared task, and Volume 2: Proceedings of the Sixth International Work-
shop on Semantic Evaluation (SemEval 2012), pp. 461–466.
Gordon, Andrew, Cosmin Bejan, and Kenji Sagae (2011). “Commonsense causal
reasoning using millions of personal stories”. In: Proceedings of the AAAI
Conference on Artificial Intelligence. Vol. 25. 1.
Gordon, Andrew and Reid Swanson (2009). “Identifying personal stories in
millions of weblog entries”. In:
Gordon, Andrew S et al. (2013). “Identifying Personal Narratives in Chinese
Weblog Posts.” In:
Gould, Evelyn et al. (2011). “Teaching children with autism a basic compo-
nent skill of perspective-taking”. In: Behavioral Interventions 26.1, pp. 50–
66.
Goyal, Amit, Ellen Riloff, and Hal Daum’e III (2010). “Automatically produc-
ing plot unit representations for narrative text”. In: Proceedings of the 2010
Conference on Empirical Methods in Natural Language Processing, pp. 77–86.
Goyal, Amit, Ellen Riloff, and Hal Daum’e III (2013). “A computational model
for plot units”. In: Computational Intelligence 29.3, pp. 466–488.
Graesser, Arthur C, Brent Olde, and Bianca Klettke. “How does the mind
construct and represent stories”. In: ().
Granroth-Wilding, Mark and Stephen Clark (2016). “What happens next?
event prediction using a compositional neural network model”. In: Thir-
tieth AAAI Conference on Artificial Intelligence.
Gray, Heather M, Kurt Gray, and Daniel M Wegner (2007). “Dimensions of
mind perception”. In: science 315.5812, pp. 619–619.
176 Bibliography
Greenberg, Daniel L and Mieke Verfaellie (2010). “Interdependence of episodic
and semantic memory: evidence from neuropsychology”. In: Journal of the
International Neuropsychological Society: JINS 16.5, p. 748.
Guajardo, Nicole R and Anne C Watson (2002). “Narrative discourse and
theory of mind development”. In: The Journal of Genetic Psychology 163.3,
pp. 305–325.
Gui, Lin et al. (2017). “A question answering approach to emotion cause ex-
traction”. In: arXiv preprint arXiv:1708.05482.
Hakemulder, Jèmeljan (2000). The moral laboratory: Experiments examining the
effects of reading literature on social perception and moral self-concept. Vol. 34.
John Benjamins Publishing.
Happ’e, Francesca GE (1994). “An advanced test of theory of mind: Under-
standing of story characters’ thoughts and feelings by able autistic, men-
tally handicapped, and normal children and adults”. In: Journal of autism
and Developmental disorders 24.2, pp. 129–154.
Hardalov, Momchil, Ivan Koychev, and Preslav Nakov (2018). “Towards au-
tomated customer support”. In: International Conference on Artificial Intel-
ligence: Methodology, Systems, and Applications. Springer, pp. 48–59.
Harrison, Brent and Mark O Riedl (2016). “Towards learning from stories: An
approach to interactive machine learning”. In: Workshops at the Thirtieth
AAAI Conference on Artificial Intelligence.
Hearst, Marti A (1997). “Text Tiling: Segmenting text into multi-paragraph
subtopic passages”. In: Computational linguistics 23.1, pp. 33–64.
Henaff, Mikael et al. (2016). “Tracking the world state with recurrent entity
networks”. In: arXiv preprint arXiv:1612.03969.
Hermann, Karl Moritz et al. (2015). “Teaching machines to read and compre-
hend”. In: Advances in neural information processing systems, pp. 1693–1701.
Hermans, Alexander, Lucas Beyer, and Bastian Leibe (2017). “In defense of
the triplet loss for person re-identification”. In: arXiv preprint arXiv:1703.07737.
Bibliography 177
Hogan, Patrick Colm (2003). The mind and its stories: Narrative universals and
human emotion. Cambridge University Press.
Hopper, Robert and Rita C Naremore (1978). Children’s speech: A practical in-
troduction to communication development. HarperCollins Publishers.
Hughes, Claire (1998). “Finding your marbles: Does preschoolers’ strategic
behavior predict later understanding of mind?” In: Developmental psychol-
ogy 34.6, p. 1326.
Hutto, Clayton and Eric Gilbert (2014). “Vader: A parsimonious rule-based
model for sentiment analysis of social media text”. In: Proceedings of the
International AAAI Conference on Web and Social Media. Vol. 8. 1.
Hutto, Daniel (2007). “The narrative practice hypothesis: origins and appli-
cations of folk psychology”. In:
Hutto, Daniel D (2012). Folk psychological narratives: The sociocultural basis of
understanding reasons. MIT press.
Imuta, Kana et al. (2016). “Theory of mind and prosocial behavior in child-
hood: A meta-analytic review.” In: Developmental psychology 52.8, p. 1192.
Iyyer, Mohit et al. (2018). “Adversarial example generation with syntactically
controlled paraphrase networks”. In: arXiv preprint arXiv:1804.06059.
Jenkins, Jennifer M and Janet Wilde Astington (2000). “Theory of mind and
social behavior: Causal models tested in a longitudinal study”. In: Merrill-
Palmer Quarterly (1982-), pp. 203–220.
Jhala, Arnav (2008). “Exploiting structure and conventions of movie scripts
for information retrieval and text mining”. In: Joint International Conference
on Interactive Digital Storytelling. Springer, pp. 210–213.
Ji, Yangfeng et al. (2017). “Dynamic entity representations in neural language
models”. In: arXiv preprint arXiv:1708.00781.
Jockers, Matthew L (2013). Macroanalysis: Digital methods and literary history.
University of Illinois Press.
178 Bibliography
Johnson, Stephen B et al. (2008). “An electronic health record based on struc-
tured narrative”. In: Journal of the American Medical Informatics Association
15.1, pp. 54–64.
Jorge, A et al. (2018). “First international workshop on narrative extraction
from texts (Text2Story 2018)”. In: ECIR, pp. 833–834.
Jorge, Al’ıpio M’ario et al. (2019). “The 2 nd International Workshop on Nar-
rative Extraction from Text: Text2Story 2019”. In: European Conference on
Information Retrieval. Springer, pp. 389–393.
Kaland, Nils et al. (2002). “A newadvanced’test of theory of mind: evidence
from children and adolescents with Asperger syndrome”. In: Journal of
child psychology and psychiatry 43.4, pp. 517–528.
Kimhi, Yael (2014). “Theory of mind abilities and deficits in autism spectrum
disorders”. In: Topics in Language Disorders 34.4, pp. 329–343.
Kingma, Diederik P and Jimmy Ba (2014). “Adam: A method for stochastic
optimization”. In: arXiv preprint arXiv:1412.6980.
Kintsch, Walter and Edith Greene (1978). “The role of culture-specific schemata
in the comprehension and recall of stories”. In: Discourse processes 1.1,
pp. 1–13.
Klin, Ami et al. (2002). “Visual fixation patterns during viewing of naturalis-
tic social situations as predictors of social competence in individuals with
autism”. In: Archives of general psychiatry 59.9, pp. 809–816.
Kociskỳ, Tom’as et al. (2018). “The narrativeqa reading comprehension chal-
lenge”. In: Transactions of the Association for Computational Linguistics 6,
pp. 317–328.
Koopman, Bevan, Liam Cripwell, and Guido Zuccon (2017). “Generating
clinical queries from patient narratives: a comparison between machines
and humans”. In: Proceedings of the 40th international ACM SIGIR conference
on Research and development in information retrieval, pp. 853–856.
Bibliography 179
Labov, William (1972). Language in the inner city: Studies in the Black English
vernacular. 3. University of Pennsylvania Press.
— (2001). Uncovering the event structure of a narrative. Georgetown University
Round Table.
— (2006). “Narrative pre-construction”. In: Narrative inquiry 16.1, pp. 37–45.
Labov, William and Joshua Waletzky (1997). “Narrative analysis: Oral ver-
sions of personal experience.” In:
Lan, Wuwei et al. (2017). “A continuously growing dataset of sentential para-
phrases”. In: arXiv preprint arXiv:1708.00391.
Lanctot, Marc et al. (2017). “A unified game-theoretic approach to multiagent
reinforcement learning”. In: Advances in Neural Information Processing Sys-
tems, pp. 4190–4203.
Lehnert, Wendy G (1981). “Plot units and narrative summarization”. In: Cog-
nitive science 5.4, pp. 293–331.
Lenat, Douglas B et al. (1990). “Cyc: toward programs with common sense”.
In: Communications of the ACM 33.8, pp. 30–49.
Lengua, Liliana J (2003). “Associations among emotionality, self-regulation,
adjustment problems, and positive adjustment in middle childhood”. In:
Journal of Applied Developmental Psychology 24.5, pp. 595–618.
Lerer, Adam and Alexander Peysakhovich (2018). “Learning social conven-
tions in markov games”. In: arXiv preprint arXiv:1806.10071.
Levi, Effi et al. (2020). “CompRes: A Dataset for Narrative Structure in News”.
In: arXiv preprint arXiv:2007.04874.
Lewis, Mike et al. (2019). “Bart: Denoising sequence-to-sequence pre-training
for natural language generation, translation, and comprehension”. In: arXiv
preprint arXiv:1910.13461.
Li, Boyang et al. (2013). “Story generation with crowdsourced plot graphs”.
In: Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 27. 1.
180 Bibliography
Li, Boyang et al. (2017). “Annotating high-level structures of short stories and
personal anecdotes”. In: arXiv preprint arXiv:1710.06917.
Li, Jiwei et al. (2016). “A persona-based neural conversation model”. In: arXiv
preprint arXiv:1603.06155.
Li, Zhongyang, Xiao Ding, and Ting Liu (2018a). “Constructing narrative
event evolutionary graph for script event prediction”. In: arXiv preprint
arXiv:1805.05081.
— (2018b). “Generating reasonable and diversified story ending using se-
quence to sequence model with adversarial training”. In: Proceedings of the
27th International Conference on Computational Linguistics, pp. 1033–1043.
— (2019). “Story ending prediction by transferable BERT”. In: arXiv preprint
arXiv:1905.07504.
Lind, Majse and Dorthe Kirkegaard Thomsen (2018). “Functions of personal
and vicarious life stories: Identity and empathy”. In: Memory 26.5, pp. 672–
682.
Liu, Chia-Wei et al. (2016). “How not to evaluate your dialogue system: An
empirical study of unsupervised evaluation metrics for dialogue response
generation”. In: arXiv preprint arXiv:1603.08023.
Liu, Hugo and Push Singh (2004). “ConceptNeta practical commonsense rea-
soning tool-kit”. In: BT technology journal 22.4, pp. 211–226.
Liu, Ye et al. (2020). “Commonsense Evidence Generation and Injection in
Reading Comprehension”. In: arXiv preprint arXiv:2005.05240.
MacKay, Tommy, Fiona Knott, and Aline-Wendy Dunlop (2007). “Develop-
ing social interaction and understanding in individuals with autism spec-
trum disorder: A groupwork intervention”. In: Journal of Intellectual and
Developmental Disability 32.4, pp. 279–290.
Magliano, Joseph et al. (2012). “Aging and perceived event structure as a
function of modality”. In: Aging, Neuropsychology, and Cognition 19.1-2,
pp. 264–282.
Bibliography 181
Magliano, Joseph P, Holly A Taylor, and Hyun-Jeong Joyce Kim (2005). “When
goals collide: Monitoring the goals of multiple characters”. In: Memory &
cognition 33.8, pp. 1357–1367.
Mann, William C and Sandra A Thompson (1988). Towards a functional theory
of text organization.
Manshadi, Mehdi, Reid Swanson, and Andrew S Gordon (2008). “Learning
a Probabilistic Model of Event Sequences from Internet Weblog Stories.”
In: FLAIRS Conference, pp. 159–164.
Mar, Raymond A (2011). “The neural bases of social cognition and story com-
prehension”. In: Annual review of psychology 62, pp. 103–134.
— (2018). “Evaluating whether stories can promote social cognition: Intro-
ducing the Social Processes and Content Entrained by Narrative (SPaCEN)
framework”. In: Discourse Processes 55.5-6, pp. 454–479.
Mar, Raymond A and Keith Oatley (2008). “The function of fiction is the ab-
straction and simulation of social experience”. In: Perspectives on psycho-
logical science 3.3, pp. 173–192.
Mar, Raymond A, Jennifer L Tackett, and Chris Moore (2010). “Exposure to
media and theory-of-mind development in preschoolers”. In: Cognitive
Development 25.1, pp. 69–78.
Mar, Raymond A et al. (2006). “Bookworms versus nerds: Exposure to fiction
versus non-fiction, divergent associations with social ability, and the sim-
ulation of fictional social worlds”. In: Journal of Research in Personality 40.5,
pp. 694–712.
Marchionini, Gary, Peter Liebscher, and Xia Lin (1991). “Authoring hyper-
documents: Designing for interaction”. In: Interfaces for Information Re-
trieval and Online Systems. Greenwood Press, New York, NY, pp. 119–131.
Mason, Robert A and Marcel Adam Just (2009). “The role of the theory-of-
mind cortical network in the comprehension of narratives”. In: Language
and Linguistics Compass 3.1, pp. 157–174.
182 Bibliography
McCabe, Allyssa, McCabe Allyssa, and Carole Peterson (1991). Developing
narrative structure. Psychology Press.
McKeough, Anne (1992). “A neo-structural analysis of childrens narrative
and its development”. In: The minds staircase: Exploring the conceptual un-
derpinnings of childrens thought and knowledge, pp. 171–188.
McNamara, Danielle S and Joe Magliano (2009). “Toward a comprehensive
model of comprehension”. In: Psychology of learning and motivation 51,
pp. 297–384.
McQuillan, Martin (2000). “Introduction: Aporias of writing: Narrative and
subjectivity”. In: The narrative reader, pp. 1–34.
Modi, Ashutosh (2016). “Event embeddings for semantic script modeling”.
In: Proceedings of The 20th SIGNLL Conference on Computational Natural Lan-
guage Learning, pp. 75–83.
Mohammad, Saif (2013). “From once upon a time to happily ever after: Track-
ing emotions in novels and fairy tales”. In: arXiv preprint arXiv:1309.5909.
Mostafazadeh, Nasrin et al. (2017). “Lsdsem 2017 shared task: The story cloze
test”. In: Proceedings of the 2nd Workshop on Linking Models of Lexical, Sen-
tential and Discourse-level Semantics, pp. 46–51.
Mumper, Micah L and Richard J Gerrig (2017). “Leisure reading and social
cognition: A meta-analysis.” In: Psychology of Aesthetics, Creativity, and the
Arts 11.1, p. 109.
Murray, Michael (2003). “Narrative psychology and narrative analysis.” In:
Nguyen, Dai Quoc et al. (June 2018). “A Novel Embedding Model for Knowl-
edge Base Completion Based on Convolutional Neural Network”. In: Pro-
ceedings of the 2018 Conference of the North American Chapter of the Associ-
ation for Computational Linguistics: Human Language Technologies, Volume
2 (Short Papers). New Orleans, Louisiana: Association for Computational
Linguistics, pp. 327–333. DOI: 10.18653/v1/N18-2053. URL: https://
www.aclweb.org/anthology/N18-2053.
Bibliography 183
Oatley, Keith (1995). “A taxonomy of the emotions of literary response and a
theory of identification in fictional narrative”. In: Poetics 23.1-2, pp. 53–74.
— (1999). “Why fiction may be twice as true as fact: Fiction as cognitive and
emotional simulation”. In: Review of general psychology 3.2, pp. 101–117.
Ouyang, Jessica and Kathleen McKeown (2015). “Modeling reportable events
as turning points in narrative”. In: Proceedings of the 2015 Conference on
Empirical Methods in Natural Language Processing, pp. 2149–2158.
Ouyang, Jessica and Kathy McKeown (2014). “Towards Automatic Detection
of Narrative Structure.” In: LREC, pp. 4624–4631.
ONeill, Brian and Mark Riedl (2011). “Toward a computational framework of
suspense and dramatic arc”. In: International Conference on Affective Com-
puting and Intelligent Interaction. Springer, pp. 246–255.
Palmer, Alan (2002). “The construction of fictional minds”. In: Narrative 10.1,
pp. 28–46.
— (2010). Social minds in the novel. The Ohio State University Press.
Palmer, Martha, Daniel Gildea, and Paul Kingsbury (2005). “The proposition
bank: An annotated corpus of semantic roles”. In: Computational linguistics
31.1, pp. 71–106.
Papalampidi, Pinelopi, Frank Keller, and Mirella Lapata (2019). “Movie Plot
Analysis via Turning Point Identification”. In: arXiv preprint arXiv:1908.10328.
Papalampidi, Pinelopi et al. (2020). “Screenplay Summarization Using Latent
Narrative Structure”. In: arXiv preprint arXiv:2004.12727.
Parsons, Lauren et al. (2017). “A systematic review of pragmatic language
interventions for children with autism spectrum disorder”. In: PloS one
12.4, e0172242.
Paszke, Adam et al. (2019). “Pytorch: An imperative style, high-performance
deep learning library”. In: Advances in neural information processing sys-
tems, pp. 8026–8037.
184 Bibliography
Paul, Debjit and Anette Frank (2019). “Ranking and selecting multi-hop knowl-
edge paths to better predict human needs”. In: arXiv preprint arXiv:1904.00676.
Paynter, Jessica and Candida C Peterson (2013). “Further evidence of benefits
of thought-bubble training for theory of mind development in children
with autism spectrum disorders”. In: Research in Autism Spectrum Disor-
ders 7.2, pp. 344–348.
Pennington, Jeffrey, Richard Socher, and Christopher D Manning (2014). “Glove:
Global vectors for word representation”. In: Proceedings of the 2014 confer-
ence on empirical methods in natural language processing (EMNLP), pp. 1532–
1543.
Perren, Sonja et al. (2007). “Pathways of behavioural and emotional symp-
toms in kindergarten children: What is the role of pro-social behaviour?”
In: European Child & Adolescent Psychiatry 16.4, pp. 209–214.
Pichotta, Karl and Raymond Mooney (2014). “Statistical script learning with
multi-argument events”. In: Proceedings of the 14th Conference of the Euro-
pean Chapter of the Association for Computational Linguistics, pp. 220–229.
Pino, Maria Chiara and Monica Mazza (2016). “The use of literary fiction to
promote mentalizing ability”. In: PloS one 11.8, e0160254.
Piper, Andrew (2018). “Fictionality”. In:
Polanyi, Livia (1981). “What stories can tell us about their teller’s world”. In:
Poetics Today 2.2, pp. 97–112.
Polkinghorne, Donald E (1988). Narrative knowing and the human sciences. Suny
Press.
Prasad, Rashmi et al. (2008). “The Penn Discourse TreeBank 2.0.” In: LREC.
Citeseer.
Prince, Gerald (2012). A grammar of stories: An introduction. Vol. 13. Walter de
Gruyter.
Propp, Vladimir (2010). Morphology of the Folktale. Vol. 9. University of Texas
Press.
Bibliography 185
Radford, Alec et al. (2018). “Improving language understanding by genera-
tive pre-training”. In:
Rahimtoroghi, Elahe et al. (2014). “Minimal narrative annotation schemes
and their applications”. In: 7th Workshop on Intelligent Narrative Technolo-
gies.
Rahimtoroghi, Elahe et al. (2017). “Modelling protagonist goals and desires
in first-person narrative”. In: arXiv preprint arXiv:1708.09040.
Rao, Anand S, Michael P Georgeff, et al. (1995). “BDI agents: from theory to
practice.” In: Icmas. Vol. 95, pp. 312–319.
Rashkin, Hannah et al. (2018a). “Event2mind: Commonsense inference on
events, intents, and reactions”. In: arXiv preprint arXiv:1805.06939.
Rashkin, Hannah et al. (2018b). “I know the feeling: Learning to converse
with empathy”. In:
Rashkin, Hannah et al. (2018c). “Modeling naive psychology of characters in
simple commonsense stories”. In: arXiv preprint arXiv:1805.06533.
Rashkin, Hannah et al. (2018d). “Towards empathetic open-domain conver-
sation models: A new benchmark and dataset”. In: arXiv preprint arXiv:1811.00207.
Riedl, Mark O and Robert Michael Young (2010). “Narrative planning: Bal-
ancing plot and character”. In: Journal of Artificial Intelligence Research 39,
pp. 217–268.
Rieffe, Carolien, Mark Meerum Terwogt, and Richard Cowan (2005). “Chil-
dren’s understanding of mental states as causes of emotions”. In: Infant
and Child Development: An International Journal of Research and Practice 14.3,
pp. 259–272.
Riessman, Catherine Kohler (1993). Narrative analysis. Vol. 30. Sage.
Roemmele, Melissa, Cosmin Adrian Bejan, and Andrew S Gordon (2011).
“Choice of Plausible Alternatives: An Evaluation of Commonsense Causal
Reasoning.” In: AAAI Spring Symposium: Logical Formalizations of Common-
sense Reasoning, pp. 90–95.
186 Bibliography
Rokach, Lior, Oded Maimon, and Mordechai Averbuch (2004). “Information
retrieval system for medical narrative reports”. In: International Conference
on Flexible Query Answering Systems. Springer, pp. 217–228.
Rumelhart, David E (1975). “Notes on a schema for stories”. In: Representation
and understanding. Elsevier, pp. 211–236.
Ryan, Marie-Laure (1986). “Embedded narratives and tellability”. In: Style,
pp. 319–340.
— (1991). Possible worlds, artificial intelligence, and narrative theory. Indiana
University Press.
Ryckman, Richard M (2004). “Theory of Personality”. In: USA. Michele Sordi.
Sap, Maarten et al. (2019a). “Atomic: An atlas of machine commonsense for
if-then reasoning”. In: Proceedings of the AAAI Conference on Artificial Intel-
ligence. Vol. 33, pp. 3027–3035.
Sap, Maarten et al. (2019b). “SocialIQA: Commonsense Reasoning about So-
cial Interactions”. In: arXiv preprint arXiv:1904.09728.
Saxe, Rebecca and Nancy Kanwisher (2003). “People thinking about thinking
people: the role of the temporo-parietal junction in theory of mind”. In:
Neuroimage 19.4, pp. 1835–1842.
Schafer, Stephen Brock (2016). Exploring the Collective Unconscious in the Age
of Digital Media. IGI Global.
Sennrich, Rico, Barry Haddow, and Alexandra Birch (2015). “Improving neu-
ral machine translation models with monolingual data”. In: arXiv preprint
arXiv:1511.06709.
Serban, Iulian Vlad et al. (2017). “A hierarchical latent variable encoder-decoder
model for generating dialogues”. In: Thirty-First AAAI Conference on Arti-
ficial Intelligence.
Sergio, Gwenaelle Cunha and Minho Lee (2021). “Stacked DeBERT: All at-
tention in incomplete data for text classification”. In: Neural Networks 136,
pp. 87–96.
Bibliography 187
Shamay-Tsoory, Simone G and Judith Aharon-Peretz (2007). “Dissociable pre-
frontal networks for cognitive and affective theory of mind: a lesion study”.
In: Neuropsychologia 45.13, pp. 3054–3067.
Shankar, Avi, Richard Elliott, and Christina Goulding (2001). “Understand-
ing consumption: Contributions from a narrative perspective”. In: Journal
of marketing Management 17.3-4, pp. 429–453.
Shwartz, Vered et al. (2020). “Unsupervised commonsense question answer-
ing with self-talk”. In: arXiv preprint arXiv:2004.05483.
Socher, Richard et al. (2013). “Reasoning with neural tensor networks for
knowledge base completion”. In: Advances in neural information processing
systems, pp. 926–934.
Somasundaran, Swapna, Josef Ruppenhofer, and Janyce Wiebe (2008). “Dis-
course level opinion relations: An annotation study”. In: Proceedings of the
9th SIGdial Workshop on Discourse and Dialogue, pp. 129–137.
Souri, Alireza, Shafigheh Hosseinpour, and Amir Masoud Rahmani (2018).
“Personality classification based on profiles of social networks users and
the five-factor model of personality”. In: Human-centric Computing and In-
formation Sciences 8.1, p. 24.
Speer, Robyn, Joshua Chin, and Catherine Havasi (2017). “Conceptnet 5.5:
An open multilingual graph of general knowledge”. In: Thirty-First AAAI
Conference on Artificial Intelligence.
Srivastava, Shashank, Snigdha Chaturvedi, and Tom Mitchell (2016). “Infer-
ring interpersonal relations in narrative summaries”. In: Thirtieth AAAI
Conference on Artificial Intelligence.
Stanovsky, Gabriel et al. (2018). “Supervised open information extraction”.
In: Proceedings of the 2018 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies, Vol-
ume 1 (Long Papers), pp. 885–895.
188 Bibliography
Stapleton, Karyn and John Wilson (2017). “Telling the story: Meaning making
in a community narrative”. In: Journal of Pragmatics 108, pp. 60–80.
Storm, William (2016). Dramaturgy and Dramatic Character. Cambridge Uni-
versity Press.
Suh, SY u and Tom Trabasso (1993). “Inferences during reading: Converging
evidence from discourse analysis, talk-aloud protocols, and recognition
priming”. In: Journal of memory and language 32.3, pp. 279–300.
Sun, Yifu and Haoming Jiang (2019). “Contextual Text Denoising with Masked
Language Models”. In: arXiv preprint arXiv:1910.14080.
Sun, Yixing (2007). “Using the organizational and narrative thread structures
in an e-book to support comprehension.” PhD thesis.
Suway, Jenna G et al. (2012). “The relations among theory of mind, behav-
ioral inhibition, and peer interactions in early childhood”. In: Social De-
velopment 21.2, pp. 331–342.
Swanson, Reid et al. (2014). “Identifying narrative clause types in personal
stories”. In: Proceedings of the 15th Annual Meeting of the Special Interest
Group on Discourse and Dialogue (SIGDIAL), pp. 171–180.
Tager-Flusberg, Helen and Kate Sullivan (1995). “Attributing mental states
to story characters: A comparison of narratives produced by autistic and
mentally retarded individuals”. In: Applied Psycholinguistics 16.3, pp. 241–
256.
Tambwekar, Pradyumna et al. (2018). “Controllable Neural Story Plot Gener-
ation via Reinforcement Learning”. In: arXiv preprint arXiv:1809.10736.
Tamir, Diana I and Mark A Thornton (2018). “Modeling the predictive social
mind”. In: Trends in cognitive sciences 22.3, pp. 201–212.
Tamir, Diana I et al. (2016a). “Neural evidence that three dimensions organize
mental state representation: Rationality, social impact, and valence”. In:
Proceedings of the National Academy of Sciences 113.1, pp. 194–199.
Bibliography 189
Tamir, Diana I et al. (2016b). “Reading fiction and reading minds: The role of
simulation in the default network”. In: Social cognitive and affective neuro-
science 11.2, pp. 215–224.
Thorne, Avril (2004). “Putting the person into social identity”. In: Human De-
velopment 47.6, pp. 361–365.
Thorne, Avril, Neill Korobov, and Elizabeth M Morgan (2007). “Channeling
identity: A study of storytelling in conversations between introverted and
extraverted friends”. In: Journal of research in personality 41.5, pp. 1008–
1031.
Thorne, Avril and Kate C McLean (2003). “Telling traumatic events in ado-
lescence: A study of master narrative positioning”. In: Connecting culture
and memory: The development of an autobiographical self, pp. 169–185.
Trabasso, Tom, Paul Van den Broek, and So Young Suh (1989). “Logical neces-
sity and transitivity of causal relations in stories”. In: Discourse processes
12.1, pp. 1–25.
Trabasso, Tom and Paul Van Den Broek (1985). “Causal thinking and the rep-
resentation of narrative events”. In: Journal of memory and language 24.5,
pp. 612–630.
Urooj, Aisha, Amir Mazaheri, Mubarak Shah, et al. (2020). “MMFT-BERT:
Multimodal Fusion Transformer with BERT Encodings for Visual Ques-
tion Answering”. In: Proceedings of the 2020 Conference on Empirical Meth-
ods in Natural Language Processing: Findings, pp. 4648–4660.
Valls-Vargas, Josep, Jichen Zhu, and Santiago Ontañ’on (2015). “Narrative
hermeneutic circle: Improving character role identification from natural
language text via feedback loops”. In: Twenty-Fourth International Joint
Conference on Artificial Intelligence.
Vaswani, Ashish et al. (2017). “Attention is all you need”. In: Advances in
neural information processing systems, pp. 5998–6008.
190 Bibliography
Vijayaraghavan, Prashanth, Eric Chu, and Deb Roy (2020). “DAPPER: Learn-
ing Domain-Adapted Persona Representation Using Pretrained BERT and
External Memory”. In: Proceedings of the 1st Conference of the Asia-Pacific
Chapter of the Association for Computational Linguistics and the 10th Interna-
tional Joint Conference on Natural Language Processing, pp. 643–652.
Vijayaraghavan, Prashanth and Deb Roy (2021a). “Lifelong Knowledge-Enriched
Social Event Representation Learning”. In: 16th European Chapter of the As-
sociation for Computational Linguistics (EACL 2021).
— (2021b). “Modeling Human Motives and Emotions from Personal Narra-
tives Using External Knowledge And Entity Tracking”. In: Proceedings of
The Web Conference 2021.
Weber, Noah, Niranjan Balasubramanian, and Nathanael Chambers (2018).
“Event representations with tensor-based compositions”. In: Thirty-Second
AAAI Conference on Artificial Intelligence.
Wellman, Henry M and Joan G Miller (2008). “Including deontic reasoning
as fundamental to theory of mind”. In: Human Development 51.2, pp. 105–
135.
Wieting, John and Kevin Gimpel (2017). “Paranmt-50m: Pushing the limits
of paraphrastic sentence embeddings with millions of machine transla-
tions”. In: arXiv preprint arXiv:1711.05732.
Wilmot, David and Frank Keller (2020). “Suspense in short stories is pre-
dicted by uncertainty reduction over neural story representation”. In: Pro-
ceedings of the 58th annual meeting of the association for computational linguis-
tics, pp. 1763–1788.
Winston, Patrick Henry (2014). The genesis story understanding and story telling
system a 21st century step toward artificial intelligence. Tech. rep. Center for
Brains, Minds and Machines (CBMM).
Wood, Barbara S (1976). “Children and communication: Verbal and nonver-
bal language development.” In:
Bibliography 191
Wyer Jr, Robert S (2014). Knowledge and Memory: The Real Story: Advances in
Social Cognition, Volume VIII. Psychology Press.
Xia, Yingce et al. (2017). “Deliberation networks: Sequence generation be-
yond one-pass decoding”. In: Advances in Neural Information Processing
Systems, pp. 1784–1794.
Xiong, Hao et al. (2019). “Modeling coherence for discourse neural machine
translation”. In: Proceedings of the AAAI Conference on Artificial Intelligence.
Vol. 33, pp. 7338–7345.
Yang, Zichao et al. (2016). “Hierarchical attention networks for document
classification”. In: Proceedings of the 2016 conference of the North American
chapter of the association for computational linguistics: human language tech-
nologies, pp. 1480–1489.
Yoshida, Wako, Ray J Dolan, and Karl J Friston (2008). “Game theory of
mind”. In: PLoS computational biology 4.12.
Yuan, Xingdi et al. (2017). “Machine comprehension by text-to-text neural
question generation”. In: arXiv preprint arXiv:1705.02012.
Zhang, Zhengyan et al. (2019). “ERNIE: Enhanced language representation
with informative entities”. In: arXiv preprint arXiv:1905.07129.
Zhou, Shuyan et al. (2019). “Improving robustness of neural machine trans-
lation with multi-task learning”. In: Proceedings of the Fourth Conference on
Machine Translation (Volume 2: Shared Task Papers, Day 1), pp. 565–571.
Zunshine, Lisa (2006). Why we read fiction: Theory of mind and the novel. Ohio
State University Press.
Zwaan, Rolf A (2004). “The immersed experiencer: Toward an embodied the-
ory of language comprehension”. In: Psychology of learning and motivation
44, pp. 35–62.
— (2016). “Situation models, mental simulations, and abstract concepts in
discourse comprehension”. In: Psychonomic bulletin & review 23.4, pp. 1028–
1034.
192 Bibliography
Zwaan, Rolf A et al. (1998). “Constructing multidimensional situation mod-
els during reading”. In: Scientific studies of reading 2.3, pp. 199–220.
